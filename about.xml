<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>BendThe-Curve</title>
<link>https://ram-polisetti.github.io/BendTheCurve/about.html</link>
<atom:link href="https://ram-polisetti.github.io/BendTheCurve/about.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://ram-polisetti.github.io/BendTheCurve/profile.jpg</url>
<title>BendThe-Curve</title>
<link>https://ram-polisetti.github.io/BendTheCurve/about.html</link>
</image>
<generator>quarto-1.5.57</generator>
<lastBuildDate>Wed, 20 Nov 2024 05:00:00 GMT</lastBuildDate>
<item>
  <title>Welcome to BendTheCurve</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/bend-the-curve-intro/</link>
  <description><![CDATA[ 





<section id="welcome-to-bendthecurve" class="level1">
<h1>Welcome to BendTheCurve</h1>
<p>I’m excited to introduce BendTheCurve, a platform dedicated to exploring and sharing insights about data science, machine learning, and their real-world applications. Here, we’ll dive deep into:</p>
<section id="what-to-expect" class="level2">
<h2 class="anchored" data-anchor-id="what-to-expect">What to Expect</h2>
<ul>
<li><strong>Data Science Insights</strong>: Regular posts about data analysis, visualization, and interpretation</li>
<li><strong>Machine Learning Deep Dives</strong>: Exploring both basic and advanced ML concepts</li>
<li><strong>Practical Tutorials</strong>: Hands-on guides and code examples</li>
<li><strong>Industry Applications</strong>: Real-world case studies and applications</li>
</ul>
</section>
<section id="join-the-journey" class="level2">
<h2 class="anchored" data-anchor-id="join-the-journey">Join the Journey</h2>
<p>Whether you’re a beginner in data science or an experienced practitioner, BendTheCurve aims to provide valuable content that helps you grow in your data science journey.</p>
<p>Stay tuned for upcoming posts!</p>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>welcome</category>
  <category>introduction</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/bend-the-curve-intro/</guid>
  <pubDate>Wed, 20 Nov 2024 05:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/bend-the-curve-intro/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Advanced Neural Network Architectures: A Technical Deep Dive</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/advanced-neural-architectures/</link>
  <description><![CDATA[ 





<section id="advanced-neural-network-architectures" class="level1">
<h1>Advanced Neural Network Architectures</h1>
<section id="self-attention-mechanisms" class="level2">
<h2 class="anchored" data-anchor-id="self-attention-mechanisms">Self-Attention Mechanisms</h2>
<section id="scaled-dot-product-attention" class="level3">
<h3 class="anchored" data-anchor-id="scaled-dot-product-attention">1. Scaled Dot-Product Attention</h3>
<p>The fundamental building block of modern architectures:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BAttention%7D(Q,%20K,%20V)%20=%20%5Ctext%7Bsoftmax%7D%5Cleft(%5Cfrac%7BQK%5ET%7D%7B%5Csqrt%7Bd_k%7D%7D%5Cright)V%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?Q%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bn%20%5Ctimes%20d_k%7D"> is the query matrix - <img src="https://latex.codecogs.com/png.latex?K%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20d_k%7D"> is the key matrix - <img src="https://latex.codecogs.com/png.latex?V%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20d_v%7D"> is the value matrix - <img src="https://latex.codecogs.com/png.latex?d_k"> is the dimension of keys - <img src="https://latex.codecogs.com/png.latex?%5Csqrt%7Bd_k%7D"> is the scaling factor</p>
</section>
<section id="multi-head-attention" class="level3">
<h3 class="anchored" data-anchor-id="multi-head-attention">2. Multi-Head Attention</h3>
<p>Parallel attention computations:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Ctext%7BMultiHead%7D(Q,%20K,%20V)%20&amp;=%20%5Ctext%7BConcat%7D(%5Ctext%7Bhead%7D_1,%20...,%20%5Ctext%7Bhead%7D_h)W%5EO%20%5C%5C%0A%5Ctext%7Bwhere%20head%7D_i%20&amp;=%20%5Ctext%7BAttention%7D(QW_i%5EQ,%20KW_i%5EK,%20VW_i%5EV)%0A%5Cend%7Baligned%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?W_i%5EQ%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bd_%7Bmodel%7D%20%5Ctimes%20d_k%7D"> - <img src="https://latex.codecogs.com/png.latex?W_i%5EK%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bd_%7Bmodel%7D%20%5Ctimes%20d_k%7D"> - <img src="https://latex.codecogs.com/png.latex?W_i%5EV%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bd_%7Bmodel%7D%20%5Ctimes%20d_v%7D"> - <img src="https://latex.codecogs.com/png.latex?W%5EO%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bhd_v%20%5Ctimes%20d_%7Bmodel%7D%7D"></p>
</section>
</section>
<section id="transformer-architecture" class="level2">
<h2 class="anchored" data-anchor-id="transformer-architecture">Transformer Architecture</h2>
<section id="encoder-block" class="level3">
<h3 class="anchored" data-anchor-id="encoder-block">1. Encoder Block</h3>
<p>Complete encoder block computation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Ctext%7BMultiHeadAttn%7D%20&amp;=%20%5Ctext%7BLayerNorm%7D(x%20+%20%5Ctext%7BMultiHead%7D(x,%20x,%20x))%20%5C%5C%0A%5Ctext%7BFFN%7D(x)%20&amp;=%20%5Ctext%7Bmax%7D(0,%20xW_1%20+%20b_1)W_2%20+%20b_2%20%5C%5C%0A%5Ctext%7BOutput%7D%20&amp;=%20%5Ctext%7BLayerNorm%7D(%5Ctext%7BMultiHeadAttn%7D%20+%20%5Ctext%7BFFN%7D(%5Ctext%7BMultiHeadAttn%7D))%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="positional-encoding" class="level3">
<h3 class="anchored" data-anchor-id="positional-encoding">2. Positional Encoding</h3>
<p>Sinusoidal position encoding:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0APE_%7B(pos,2i)%7D%20&amp;=%20%5Csin(pos/10000%5E%7B2i/d_%7Bmodel%7D%7D)%20%5C%5C%0APE_%7B(pos,2i+1)%7D%20&amp;=%20%5Ccos(pos/10000%5E%7B2i/d_%7Bmodel%7D%7D)%0A%5Cend%7Baligned%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?pos"> is the position - <img src="https://latex.codecogs.com/png.latex?i"> is the dimension</p>
</section>
</section>
<section id="modern-architectural-patterns" class="level2">
<h2 class="anchored" data-anchor-id="modern-architectural-patterns">Modern Architectural Patterns</h2>
<section id="residual-networks" class="level3">
<h3 class="anchored" data-anchor-id="residual-networks">1. Residual Networks</h3>
<p>ResNet block formulation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ay%20=%20F(x,%20%5C%7BW_i%5C%7D)%20+%20x%0A"></p>
<p>With pre-activation variant:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Ah%20&amp;=%20%5Ctext%7BReLU%7D(%5Ctext%7BBN%7D(x))%20%5C%5C%0Ay%20&amp;=%20W_2%5Ctext%7BReLU%7D(%5Ctext%7BBN%7D(W_1h))%20+%20x%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="dense-networks" class="level3">
<h3 class="anchored" data-anchor-id="dense-networks">2. Dense Networks</h3>
<p>DenseNet connectivity pattern:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_l%20=%20H_l(%5Bx_0,%20x_1,%20...,%20x_%7Bl-1%7D%5D)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?x_l"> is the output of layer <img src="https://latex.codecogs.com/png.latex?l"> - <img src="https://latex.codecogs.com/png.latex?H_l"> is a composite function - <img src="https://latex.codecogs.com/png.latex?%5B...%5D"> represents concatenation</p>
</section>
<section id="squeeze-and-excitation-networks" class="level3">
<h3 class="anchored" data-anchor-id="squeeze-and-excitation-networks">3. Squeeze-and-Excitation Networks</h3>
<p>Channel attention mechanism:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Az%20&amp;=%20F_%7Bsq%7D(u)%20=%20%5Cfrac%7B1%7D%7BH%20%5Ctimes%20W%7D%5Csum_%7Bi=1%7D%5EH%5Csum_%7Bj=1%7D%5EW%20u_c(i,j)%20%5C%5C%0As%20&amp;=%20F_%7Bex%7D(z)%20=%20%5Csigma(W_2%5Ctext%7BReLU%7D(W_1z))%0A%5Cend%7Baligned%7D%0A"></p>
</section>
</section>
<section id="advanced-attention-variants" class="level2">
<h2 class="anchored" data-anchor-id="advanced-attention-variants">Advanced Attention Variants</h2>
<section id="relative-position-attention" class="level3">
<h3 class="anchored" data-anchor-id="relative-position-attention">1. Relative Position Attention</h3>
<p>Position-aware attention scoring:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BAttention%7D(Q,%20K,%20V,%20R)%20=%20%5Ctext%7Bsoftmax%7D%5Cleft(%5Cfrac%7BQK%5ET%20+%20QR%5ET%7D%7B%5Csqrt%7Bd_k%7D%7D%5Cright)V%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?R"> is the relative position encoding matrix</p>
</section>
<section id="linear-attention" class="level3">
<h3 class="anchored" data-anchor-id="linear-attention">2. Linear Attention</h3>
<p>Efficient attention computation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BLinearAttention%7D(Q,%20K,%20V)%20=%20%5Cphi(Q)(%5Cphi(K)%5ETV)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cphi"> is a feature map (e.g., elu(x) + 1)</p>
</section>
<section id="sparse-attention" class="level3">
<h3 class="anchored" data-anchor-id="sparse-attention">3. Sparse Attention</h3>
<p>Structured sparsity pattern:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BSparseAttention%7D(Q,%20K,%20V)%20=%20%5Ctext%7Bsoftmax%7D%5Cleft(%5Cfrac%7BM%20%5Codot%20(QK%5ET)%7D%7B%5Csqrt%7Bd_k%7D%7D%5Cright)V%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?M"> is a binary mask matrix - <img src="https://latex.codecogs.com/png.latex?%5Codot"> is element-wise multiplication</p>
</section>
</section>
<section id="advanced-normalization-techniques" class="level2">
<h2 class="anchored" data-anchor-id="advanced-normalization-techniques">Advanced Normalization Techniques</h2>
<section id="layer-normalization" class="level3">
<h3 class="anchored" data-anchor-id="layer-normalization">1. Layer Normalization</h3>
<p>Computation across features:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BLN%7D(x)%20=%20%5Cgamma%20%5Codot%20%5Cfrac%7Bx%20-%20%5Cmu%7D%7B%5Csqrt%7B%5Csigma%5E2%20+%20%5Cepsilon%7D%7D%20+%20%5Cbeta%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cmu"> and <img src="https://latex.codecogs.com/png.latex?%5Csigma"> are computed across feature dimension</p>
</section>
<section id="group-normalization" class="level3">
<h3 class="anchored" data-anchor-id="group-normalization">2. Group Normalization</h3>
<p>Feature group normalization:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BGN%7D(x)%20=%20%5Cgamma%20%5Codot%20%5Cfrac%7Bx%20-%20%5Cmu_g%7D%7B%5Csqrt%7B%5Csigma_g%5E2%20+%20%5Cepsilon%7D%7D%20+%20%5Cbeta%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cmu_g"> and <img src="https://latex.codecogs.com/png.latex?%5Csigma_g"> are computed within groups</p>
</section>
</section>
<section id="advanced-activation-functions" class="level2">
<h2 class="anchored" data-anchor-id="advanced-activation-functions">Advanced Activation Functions</h2>
<section id="gelu-gaussian-error-linear-unit" class="level3">
<h3 class="anchored" data-anchor-id="gelu-gaussian-error-linear-unit">1. GELU (Gaussian Error Linear Unit)</h3>
<p>Smooth approximation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BGELU%7D(x)%20=%20x%5CPhi(x)%20=%20x%20%5Ccdot%20%5Cfrac%7B1%7D%7B2%7D%5Cleft%5B1%20+%20%5Ctext%7Berf%7D%5Cleft(%5Cfrac%7Bx%7D%7B%5Csqrt%7B2%7D%7D%5Cright)%5Cright%5D%0A"></p>
</section>
<section id="swish" class="level3">
<h3 class="anchored" data-anchor-id="swish">2. Swish</h3>
<p>Self-gated activation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BSwish%7D(x)%20=%20x%20%5Ccdot%20%5Csigma(%5Cbeta%20x)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Csigma"> is the sigmoid function - <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> is a learnable parameter</p>
</section>
</section>
<section id="architectural-optimization" class="level2">
<h2 class="anchored" data-anchor-id="architectural-optimization">Architectural Optimization</h2>
<section id="neural-architecture-search-nas" class="level3">
<h3 class="anchored" data-anchor-id="neural-architecture-search-nas">1. Neural Architecture Search (NAS)</h3>
<p>Optimization objective:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cmin_%7B%5Calpha%7D%20&amp;%20%5Cquad%20%5Cmathcal%7BL%7D_%7Bval%7D(w%5E*(%5Calpha),%20%5Calpha)%20%5C%5C%0A%5Ctext%7Bs.t.%7D%20&amp;%20%5Cquad%20w%5E*(%5Calpha)%20=%20%5Cargmin_w%20%5Cmathcal%7BL%7D_%7Btrain%7D(w,%20%5Calpha)%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="dynamic-routing" class="level3">
<h3 class="anchored" data-anchor-id="dynamic-routing">2. Dynamic Routing</h3>
<p>Routing probability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap_%7Bij%7D%20=%20%5Cfrac%7B%5Cexp(%5Chat%7Bu%7D_j%7Cu_i)%7D%7B%5Csum_k%20%5Cexp(%5Chat%7Bu%7D_k%7Cu_i)%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?u_i"> is the input capsule - <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bu%7D_j"> is the prediction vector</p>
</section>
</section>
<section id="implementation-considerations" class="level2">
<h2 class="anchored" data-anchor-id="implementation-considerations">Implementation Considerations</h2>
<section id="memory-efficiency" class="level3">
<h3 class="anchored" data-anchor-id="memory-efficiency">1. Memory Efficiency</h3>
<p>Gradient checkpointing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bmemory%7D%20=%20O(%5Csqrt%7BN%7D)%20%5Ctext%7B%20instead%20of%20%7D%20O(N)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?N"> is the number of layers</p>
</section>
<section id="computational-efficiency" class="level3">
<h3 class="anchored" data-anchor-id="computational-efficiency">2. Computational Efficiency</h3>
<p>Mixed precision training:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Ctext%7BFP16%20Forward%7D%20&amp;:%20y%20=%20%5Ctext%7Bcast%7D_%7B%5Ctext%7BFP16%7D%7D(Wx)%20%5C%5C%0A%5Ctext%7BFP32%20Master%7D%20&amp;:%20w_%7B%5Ctext%7Bmaster%7D%7D%20=%20w_%7B%5Ctext%7BFP32%7D%7D%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="training-stability" class="level3">
<h3 class="anchored" data-anchor-id="training-stability">3. Training Stability</h3>
<p>Gradient clipping with norm:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ag%20=%20%5Cmin%5Cleft(1,%20%5Cfrac%7B%5Ctheta%7D%7B%5C%7Cg%5C%7C%7D%5Cright)g%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is the clipping threshold - <img src="https://latex.codecogs.com/png.latex?g"> is the gradient</p>
</section>
</section>
<section id="advanced-training-techniques" class="level2">
<h2 class="anchored" data-anchor-id="advanced-training-techniques">Advanced Training Techniques</h2>
<section id="knowledge-distillation" class="level3">
<h3 class="anchored" data-anchor-id="knowledge-distillation">1. Knowledge Distillation</h3>
<p>Distillation objective:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D%20=%20%5Calpha%20T%5E2%20%5Ctext%7BKL%7D%5Cleft(%5Ctext%7Bsoftmax%7D%5Cleft(%5Cfrac%7Bz_t%7D%7BT%7D%5Cright),%20%5Ctext%7Bsoftmax%7D%5Cleft(%5Cfrac%7Bz_s%7D%7BT%7D%5Cright)%5Cright)%20+%20(1-%5Calpha)%5Cmathcal%7BL%7D_%7B%5Ctext%7BCE%7D%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?z_t"> and <img src="https://latex.codecogs.com/png.latex?z_s"> are teacher and student logits - <img src="https://latex.codecogs.com/png.latex?T"> is temperature - <img src="https://latex.codecogs.com/png.latex?%5Calpha"> is balancing factor</p>
</section>
<section id="progressive-training" class="level3">
<h3 class="anchored" data-anchor-id="progressive-training">2. Progressive Training</h3>
<p>Curriculum learning schedule:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clambda(t)%20=%20%5Cmin%5Cleft(1,%20%5Cfrac%7Bt%7D%7B%5Ctau%7D%5Cright)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?t"> is current step - <img src="https://latex.codecogs.com/png.latex?%5Ctau"> is ramp-up period</p>
</section>
</section>
<section id="performance-analysis" class="level2">
<h2 class="anchored" data-anchor-id="performance-analysis">Performance Analysis</h2>
<section id="theoretical-complexity" class="level3">
<h3 class="anchored" data-anchor-id="theoretical-complexity">1. Theoretical Complexity</h3>
<p>Attention complexity:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Ctext%7BSpace%7D%20&amp;:%20O(n%5E2d)%20%5C%5C%0A%5Ctext%7BTime%7D%20&amp;:%20O(n%5E2d)%0A%5Cend%7Baligned%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?n"> is sequence length - <img src="https://latex.codecogs.com/png.latex?d"> is hidden dimension</p>
</section>
<section id="information-flow" class="level3">
<h3 class="anchored" data-anchor-id="information-flow">2. Information Flow</h3>
<p>Maximum path length:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BPathLength%7D%20=%20%5Cbegin%7Bcases%7D%0AO(1)%20&amp;%20%5Ctext%7Bfor%20transformers%7D%20%5C%5C%0AO(n)%20&amp;%20%5Ctext%7Bfor%20RNNs%7D%0A%5Cend%7Bcases%7D%0A"></p>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="architecture-design" class="level3">
<h3 class="anchored" data-anchor-id="architecture-design">1. Architecture Design</h3>
<ol type="1">
<li>Residual Connections:
<ul>
<li>Use in deep networks</li>
<li>Maintain gradient flow</li>
<li>Enable deeper architectures</li>
</ul></li>
<li>Normalization:
<ul>
<li>Pre-normalization for stability</li>
<li>Layer normalization for transformers</li>
<li>Batch normalization for CNNs</li>
</ul></li>
<li>Attention Mechanisms:
<ul>
<li>Multi-head attention for diverse features</li>
<li>Relative position encoding for sequences</li>
<li>Sparse attention for long sequences</li>
</ul></li>
</ol>
</section>
<section id="training-strategy" class="level3">
<h3 class="anchored" data-anchor-id="training-strategy">2. Training Strategy</h3>
<ol type="1">
<li>Learning Rate:
<ul>
<li>Linear warmup</li>
<li>Cosine decay</li>
<li>Layer-wise learning rates</li>
</ul></li>
<li>Regularization:
<ul>
<li>Dropout in attention</li>
<li>Weight decay</li>
<li>Label smoothing</li>
</ul></li>
<li>Optimization:
<ul>
<li>Adam with weight decay</li>
<li>Gradient clipping</li>
<li>Mixed precision training</li>
</ul></li>
</ol>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Architecture:
<ul>
<li>“Attention Is All You Need” by Vaswani et al.</li>
<li>“Deep Residual Learning” by He et al.</li>
<li>“Densely Connected Networks” by Huang et al.</li>
</ul></li>
<li>Training:
<ul>
<li>“On Layer Normalization in the Transformer Architecture” by Xiong et al.</li>
<li>“Understanding the Difficulty of Training Deep Feedforward Neural Networks” by Glorot and Bengio</li>
<li>“Mixed Precision Training” by Micikevicius et al.</li>
</ul></li>
<li>Analysis:
<ul>
<li>“On the Relationship between Self-Attention and Convolutional Layers” by Cordonnier et al.</li>
<li>“The Transformer Family” by Tay et al.</li>
<li>“What Does BERT Look At?” by Clark et al.</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>deep-learning</category>
  <category>neural-networks</category>
  <category>architectures</category>
  <category>mathematics</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/advanced-neural-architectures/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/advanced-neural-architectures/neural_architectures.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Algorithmic Stability and Learning Theory</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/algorithmic-stability/</link>
  <description><![CDATA[ 





<section id="algorithmic-stability-and-learning-theory" class="level1">
<h1>Algorithmic Stability and Learning Theory</h1>
<section id="fundamental-concepts" class="level2">
<h2 class="anchored" data-anchor-id="fundamental-concepts">Fundamental Concepts</h2>
<section id="stability-definitions" class="level3">
<h3 class="anchored" data-anchor-id="stability-definitions">1. Stability Definitions</h3>
<p>Hypothesis stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cell(A_S,z)%20-%20%5Cell(A_%7BS%5Ei%7D,z)%7C%20%5Cleq%20%5Cbeta_m%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?A_S"> is algorithm output on dataset <img src="https://latex.codecogs.com/png.latex?S"> - <img src="https://latex.codecogs.com/png.latex?S%5Ei"> is dataset with i-th example replaced - <img src="https://latex.codecogs.com/png.latex?%5Cbeta_m"> is stability coefficient</p>
<p>Uniform stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csup_%7BS,z,i%7D%7C%5Cell(A_S,z)%20-%20%5Cell(A_%7BS%5Ei%7D,z)%7C%20%5Cleq%20%5Cbeta%0A"></p>
</section>
<section id="loss-stability" class="level3">
<h3 class="anchored" data-anchor-id="loss-stability">2. Loss Stability</h3>
<p>Point-wise loss stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cell(h_S,z)%20-%20%5Cell(h_%7BS%5Ei%7D,z)%7C%20%5Cleq%20%5Cbeta%0A"></p>
<p>Average loss stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbb%7BE%7D_%7Bz%20%5Csim%20%5Cmathcal%7BD%7D%7D%5B%5Cell(h_S,z)%20-%20%5Cell(h_%7BS%5Ei%7D,z)%5D%7C%20%5Cleq%20%5Cbeta%0A"></p>
</section>
<section id="generalization-bounds" class="level3">
<h3 class="anchored" data-anchor-id="generalization-bounds">3. Generalization Bounds</h3>
<p>McDiarmid’s inequality based bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%7CR(A_S)%20-%20%5Chat%7BR%7D_S(A_S)%7C%20%3E%20%5Cepsilon)%20%5Cleq%202%5Cexp(-%5Cfrac%7B2m%5Cepsilon%5E2%7D%7B(4%5Cbeta)%5E2%7D)%0A"></p>
<p>Expected generalization error:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbb%7BE%7D%5BR(A_S)%20-%20%5Chat%7BR%7D_S(A_S)%5D%7C%20%5Cleq%20%5Cbeta%0A"></p>
</section>
</section>
<section id="types-of-stability" class="level2">
<h2 class="anchored" data-anchor-id="types-of-stability">Types of Stability</h2>
<section id="strong-stability" class="level3">
<h3 class="anchored" data-anchor-id="strong-stability">1. Strong Stability</h3>
<p>Definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csup_%7BS,S':%20%7CS%20%5Ctriangle%20S'%7C%20=%202%7D%5C%7CA_S%20-%20A_%7BS'%7D%5C%7C%20%5Cleq%20%5Cbeta_m%0A"></p>
<p>Generalization bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%7CR(A_S)%20-%20%5Chat%7BR%7D_S(A_S)%7C%20%3E%20%5Cepsilon)%20%5Cleq%202%5Cexp(-%5Cfrac%7Bm%5Cepsilon%5E2%7D%7B2%5Cbeta_m%5E2%7D)%0A"></p>
</section>
<section id="cross-validation-stability" class="level3">
<h3 class="anchored" data-anchor-id="cross-validation-stability">2. Cross-Validation Stability</h3>
<p>Leave-one-out stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbb%7BE%7D_%7BS,z%7D%5B%5Cell(A_S,z)%20-%20%5Cell(A_%7BS%5E%7B-i%7D%7D,z)%5D%7C%20%5Cleq%20%5Cbeta_m%0A"></p>
<p>k-fold stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbb%7BE%7D_%7BS,z%7D%5B%5Cell(A_S,z)%20-%20%5Cell(A_%7BS_k%7D,z)%5D%7C%20%5Cleq%20%5Cbeta_m%0A"></p>
</section>
<section id="algorithmic-robustness" class="level3">
<h3 class="anchored" data-anchor-id="algorithmic-robustness">3. Algorithmic Robustness</h3>
<p><img src="https://latex.codecogs.com/png.latex?(K,%5Cepsilon(%5Ccdot))">-robustness:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP_%7BS,z%7D(%7C%5Cell(A_S,z)%20-%20%5Cell(A_S,z')%7C%20%3E%20%5Cepsilon(m))%20%5Cleq%20K/m%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?z,z'"> are in same partition - <img src="https://latex.codecogs.com/png.latex?K"> is number of partitions - <img src="https://latex.codecogs.com/png.latex?%5Cepsilon(m)"> is robustness parameter</p>
</section>
</section>
<section id="stability-analysis" class="level2">
<h2 class="anchored" data-anchor-id="stability-analysis">Stability Analysis</h2>
<section id="regularization-and-stability" class="level3">
<h3 class="anchored" data-anchor-id="regularization-and-stability">1. Regularization and Stability</h3>
<p>Tikhonov regularization:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AA_S%20=%20%5Carg%5Cmin_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%20%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi=1%7D%5Em%20%5Cell(h,z_i)%20+%20%5Clambda%5C%7Ch%5C%7C%5E2%0A"></p>
<p>Stability bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta%20%5Cleq%20%5Cfrac%7BL%5E2%7D%7B2m%5Clambda%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?L"> is Lipschitz constant - <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is regularization parameter</p>
</section>
<section id="gradient-methods" class="level3">
<h3 class="anchored" data-anchor-id="gradient-methods">2. Gradient Methods</h3>
<p>Gradient descent stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5C%7Cw_t%20-%20w_t'%5C%7C%20%5Cleq%20(1+%5Ceta%20L)%5Et%5C%7Cw_0%20-%20w_0'%5C%7C%0A"></p>
<p>SGD stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5B%5C%7Cw_t%20-%20w_t'%5C%7C%5E2%5D%20%5Cleq%20%5Cfrac%7B%5Ceta%5E2L%5E2%7D%7B2m%7D%0A"></p>
</section>
<section id="ensemble-methods" class="level3">
<h3 class="anchored" data-anchor-id="ensemble-methods">3. Ensemble Methods</h3>
<p>Bagging stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_%7B%5Ctext%7Bbag%7D%7D%20%5Cleq%20%5Cfrac%7B%5Cbeta%7D%7B%5Csqrt%7BB%7D%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?B"> is number of bootstrap samples - <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> is base learner stability</p>
</section>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">Applications</h2>
<section id="regularized-learning" class="level3">
<h3 class="anchored" data-anchor-id="regularized-learning">1. Regularized Learning</h3>
<p>Ridge regression stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_%7B%5Ctext%7Bridge%7D%7D%20%5Cleq%20%5Cfrac%7B4M%5E2%7D%7Bm%5Clambda%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?M"> is bound on features - <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is regularization</p>
</section>
<section id="online-learning" class="level3">
<h3 class="anchored" data-anchor-id="online-learning">2. Online Learning</h3>
<p>Online stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5B%5C%7Cw_t%20-%20w_t'%5C%7C%5D%20%5Cleq%20%5Cfrac%7B2G%7D%7B%5Clambda%5Csqrt%7Bt%7D%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?G"> is gradient bound - <img src="https://latex.codecogs.com/png.latex?t"> is iteration number</p>
</section>
<section id="deep-learning" class="level3">
<h3 class="anchored" data-anchor-id="deep-learning">3. Deep Learning</h3>
<p>Dropout stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_%7B%5Ctext%7Bdropout%7D%7D%20%5Cleq%20%5Cfrac%7Bp(1-p)L%5E2%7D%7Bm%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?p"> is dropout probability - <img src="https://latex.codecogs.com/png.latex?L"> is network Lipschitz constant</p>
</section>
</section>
<section id="advanced-topics" class="level2">
<h2 class="anchored" data-anchor-id="advanced-topics">Advanced Topics</h2>
<section id="local-stability" class="level3">
<h3 class="anchored" data-anchor-id="local-stability">1. Local Stability</h3>
<p>Definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cell(A_S,z)%20-%20%5Cell(A_%7BS%5Ei%7D,z)%7C%20%5Cleq%20%5Cbeta(z)%0A"></p>
<p>Adaptive bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%7CR(A_S)%20-%20%5Chat%7BR%7D_S(A_S)%7C%20%3E%20%5Cepsilon)%20%5Cleq%202%5Cexp(-%5Cfrac%7B2m%5Cepsilon%5E2%7D%7B%5Cmathbb%7BE%7D%5B%5Cbeta(Z)%5E2%5D%7D)%0A"></p>
</section>
<section id="distribution-stability" class="level3">
<h3 class="anchored" data-anchor-id="distribution-stability">2. Distribution Stability</h3>
<p>Definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5C%7C%5Cmathcal%7BD%7D_%7BA_S%7D%20-%20%5Cmathcal%7BD%7D_%7BA_%7BS%5Ei%7D%7D%5C%7C_1%20%5Cleq%20%5Cbeta%0A"></p>
<p>Generalization:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathbb%7BE%7D%5BR(A_S)%5D%20-%20%5Cmathbb%7BE%7D%5B%5Chat%7BR%7D_S(A_S)%5D%7C%20%5Cleq%20%5Cbeta%0A"></p>
</section>
<section id="algorithmic-privacy" class="level3">
<h3 class="anchored" data-anchor-id="algorithmic-privacy">3. Algorithmic Privacy</h3>
<p>Differential privacy:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(A_S%20%5Cin%20E)%20%5Cleq%20e%5E%5Cepsilon%20P(A_%7BS'%7D%20%5Cin%20E)%0A"></p>
<p>Privacy-stability relationship:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta%20%5Cleq%20%5Cepsilon%20L%0A"></p>
</section>
</section>
<section id="theoretical-results" class="level2">
<h2 class="anchored" data-anchor-id="theoretical-results">Theoretical Results</h2>
<section id="stability-hierarchy" class="level3">
<h3 class="anchored" data-anchor-id="stability-hierarchy">1. Stability Hierarchy</h3>
<p>Relationships:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BUniform%7D%20%5Cimplies%20%5Ctext%7BHypothesis%7D%20%5Cimplies%20%5Ctext%7BPoint-wise%7D%20%5Cimplies%20%5Ctext%7BAverage%7D%0A"></p>
<p>Equivalence conditions:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_%7B%5Ctext%7Buniform%7D%7D%20=%20%5Cbeta_%7B%5Ctext%7Bhypothesis%7D%7D%20%5Ciff%20%5Ctext%7Bconvex%20loss%7D%0A"></p>
</section>
<section id="lower-bounds" class="level3">
<h3 class="anchored" data-anchor-id="lower-bounds">2. Lower Bounds</h3>
<p>Minimal stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_m%20%5Cgeq%20%5COmega(%5Cfrac%7B1%7D%7B%5Csqrt%7Bm%7D%7D)%0A"></p>
<p>Optimal rates:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_m%20=%20%5CTheta(%5Cfrac%7B1%7D%7Bm%7D)%0A"></p>
</section>
<section id="composition-theorems" class="level3">
<h3 class="anchored" data-anchor-id="composition-theorems">3. Composition Theorems</h3>
<p>Serial composition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_%7BA%20%5Ccirc%20B%7D%20%5Cleq%20%5Cbeta_A%20+%20%5Cbeta_B%0A"></p>
<p>Parallel composition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbeta_%7B%5Ctext%7Bparallel%7D%7D%20%5Cleq%20%5Cmax_i%20%5Cbeta_i%0A"></p>
</section>
</section>
<section id="implementation-considerations" class="level2">
<h2 class="anchored" data-anchor-id="implementation-considerations">Implementation Considerations</h2>
<section id="algorithm-design" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-design">1. Algorithm Design</h3>
<ol type="1">
<li>Regularization:
<ul>
<li>Choose appropriate <img src="https://latex.codecogs.com/png.latex?%5Clambda"></li>
<li>Balance stability-accuracy</li>
<li>Adaptive regularization</li>
</ul></li>
<li>Optimization:
<ul>
<li>Step size selection</li>
<li>Batch size impact</li>
<li>Momentum effects</li>
</ul></li>
<li>Architecture:
<ul>
<li>Layer stability</li>
<li>Skip connections</li>
<li>Normalization impact</li>
</ul></li>
</ol>
</section>
<section id="stability-measures" class="level3">
<h3 class="anchored" data-anchor-id="stability-measures">2. Stability Measures</h3>
<ol type="1">
<li>Empirical Stability:
<ul>
<li>Leave-one-out estimates</li>
<li>Bootstrap estimates</li>
<li>Cross-validation</li>
</ul></li>
<li>Theoretical Bounds:
<ul>
<li>Lipschitz constants</li>
<li>Condition numbers</li>
<li>Spectral norms</li>
</ul></li>
<li>Monitoring:
<ul>
<li>Stability metrics</li>
<li>Generalization gaps</li>
<li>Validation curves</li>
</ul></li>
</ol>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="model-selection" class="level3">
<h3 class="anchored" data-anchor-id="model-selection">1. Model Selection</h3>
<ol type="1">
<li>Stability Analysis:
<ul>
<li>Cross-validation stability</li>
<li>Parameter sensitivity</li>
<li>Model robustness</li>
</ul></li>
<li>Regularization:
<ul>
<li>Multiple techniques</li>
<li>Adaptive schemes</li>
<li>Stability-based selection</li>
</ul></li>
<li>Validation:
<ul>
<li>Stability metrics</li>
<li>Generalization bounds</li>
<li>Robustness checks</li>
</ul></li>
</ol>
</section>
<section id="training-strategy" class="level3">
<h3 class="anchored" data-anchor-id="training-strategy">2. Training Strategy</h3>
<ol type="1">
<li>Optimization:
<ul>
<li>Stable algorithms</li>
<li>Adaptive methods</li>
<li>Early stopping</li>
</ul></li>
<li>Data Processing:
<ul>
<li>Robust preprocessing</li>
<li>Feature stability</li>
<li>Outlier handling</li>
</ul></li>
<li>Evaluation:
<ul>
<li>Stability measures</li>
<li>Confidence bounds</li>
<li>Sensitivity analysis</li>
</ul></li>
</ol>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Theory:
<ul>
<li>“Stability and Generalization” by Bousquet and Elisseeff</li>
<li>“Learning, Testing, and the Stability Approach” by Shalev-Shwartz et al.</li>
<li>“Stability and Learning Theory” by Mukherjee et al.</li>
</ul></li>
<li>Methods:
<ul>
<li>“Algorithmic Stability and Uniform Convergence” by Kearns and Ron</li>
<li>“Stability and Instance-Based Learning” by Devroye and Wagner</li>
<li>“Stable Learning Algorithms” by Kutin and Niyogi</li>
</ul></li>
<li>Applications:
<ul>
<li>“Stability in Machine Learning” by Hardt et al.</li>
<li>“Deep Learning and Stability” by Hardt and Ma</li>
<li>“Stability-Based Generalization Analysis” by Poggio et al.</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>theory</category>
  <category>mathematics</category>
  <category>stability</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/algorithmic-stability/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/algorithmic-stability/stability.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Causal Inference and Structural Learning</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/causal-inference/</link>
  <description><![CDATA[ 





<section id="causal-inference-and-structural-learning" class="level1">
<h1>Causal Inference and Structural Learning</h1>
<section id="structural-causal-models" class="level2">
<h2 class="anchored" data-anchor-id="structural-causal-models">Structural Causal Models</h2>
<section id="basic-framework" class="level3">
<h3 class="anchored" data-anchor-id="basic-framework">1. Basic Framework</h3>
<p>Definition of SCM:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AX_i%20&amp;=%20f_i(%5Ctext%7BPA%7D_i,%20U_i)%20%5C%5C%0AU_i%20&amp;%5Csim%20P(U_i)%0A%5Cend%7Baligned%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?X_i"> are endogenous variables - <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BPA%7D_i"> are parents of <img src="https://latex.codecogs.com/png.latex?X_i"> - <img src="https://latex.codecogs.com/png.latex?U_i"> are exogenous variables - <img src="https://latex.codecogs.com/png.latex?f_i"> are structural equations</p>
</section>
<section id="intervention-calculus" class="level3">
<h3 class="anchored" data-anchor-id="intervention-calculus">2. Intervention Calculus</h3>
<p>Do-operator formalization:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(Y%7C%5Ctext%7Bdo%7D(X=x))%20=%20%5Csum_z%20P(Y%7CX=x,Z=z)P(Z=z)%0A"></p>
<p>Backdoor adjustment:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(Y%7C%5Ctext%7Bdo%7D(X=x))%20=%20%5Csum_z%20P(Y%7CX=x,Z=z)P(Z=z)%0A"></p>
<p>Where Z satisfies the backdoor criterion.</p>
</section>
</section>
<section id="identification-methods" class="level2">
<h2 class="anchored" data-anchor-id="identification-methods">Identification Methods</h2>
<section id="backdoor-criterion" class="level3">
<h3 class="anchored" data-anchor-id="backdoor-criterion">1. Backdoor Criterion</h3>
<p>A set Z satisfies the backdoor criterion relative to (X,Y) if: 1. No node in Z is a descendant of X 2. Z blocks all backdoor paths from X to Y</p>
<p>Formal criterion:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(Y%7C%5Ctext%7Bdo%7D(X))%20=%20%5Csum_z%20P(Y%7CX,Z)P(Z)%0A"></p>
</section>
<section id="front-door-criterion" class="level3">
<h3 class="anchored" data-anchor-id="front-door-criterion">2. Front-door Criterion</h3>
<p>Three conditions: 1. M blocks all directed paths from X to Y 2. No unblocked backdoor path from X to M 3. All backdoor paths from M to Y are blocked by X</p>
<p>Formula:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(Y%7C%5Ctext%7Bdo%7D(X))%20=%20%5Csum_m%20P(m%7CX)%5Csum_%7Bx'%7DP(Y%7Cm,x')P(x')%0A"></p>
</section>
<section id="do-calculus-rules" class="level3">
<h3 class="anchored" data-anchor-id="do-calculus-rules">3. Do-Calculus Rules</h3>
<p>Rule 1 (Insertion/deletion of observations):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7C%5Ctext%7Bdo%7D(x),z,w)%20=%20P(y%7C%5Ctext%7Bdo%7D(x),w)%0A"></p>
<p>if (Y ⊥⊥ Z|X,W)<img src="https://latex.codecogs.com/png.latex?_%7BG_%7B%5Coverline%7BX%7D%7D%7D"></p>
<p>Rule 2 (Action/observation exchange):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7C%5Ctext%7Bdo%7D(x),%5Ctext%7Bdo%7D(z),w)%20=%20P(y%7C%5Ctext%7Bdo%7D(x),z,w)%0A"></p>
<p>if (Y ⊥⊥ Z|X,W)<img src="https://latex.codecogs.com/png.latex?_%7BG_%7B%5Coverline%7BX%7D%5Cunderline%7BZ%7D%7D%7D"></p>
<p>Rule 3 (Insertion/deletion of actions):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7C%5Ctext%7Bdo%7D(x),%5Ctext%7Bdo%7D(z),w)%20=%20P(y%7C%5Ctext%7Bdo%7D(x),w)%0A"></p>
<p>if (Y ⊥⊥ Z|X,W)<img src="https://latex.codecogs.com/png.latex?_%7BG_%7B%5Coverline%7BX%7D%5Coverline%7BZ(W)%7D%7D%7D"></p>
</section>
</section>
<section id="estimation-methods" class="level2">
<h2 class="anchored" data-anchor-id="estimation-methods">Estimation Methods</h2>
<section id="propensity-score-matching" class="level3">
<h3 class="anchored" data-anchor-id="propensity-score-matching">1. Propensity Score Matching</h3>
<p>Propensity score:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ae(X)%20=%20P(T=1%7CX)%0A"></p>
<p>Average Treatment Effect (ATE):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BATE%7D%20=%20%5Cmathbb%7BE%7D%5BY(1)%20-%20Y(0)%5D%20=%20%5Cmathbb%7BE%7D%5Cleft%5B%5Cfrac%7BTY%7D%7Be(X)%7D%20-%20%5Cfrac%7B(1-T)Y%7D%7B1-e(X)%7D%5Cright%5D%0A"></p>
</section>
<section id="instrumental-variables" class="level3">
<h3 class="anchored" data-anchor-id="instrumental-variables">2. Instrumental Variables</h3>
<p>Two-stage least squares (2SLS):</p>
<p>First stage: <img src="https://latex.codecogs.com/png.latex?%0AX%20=%20%5Cgamma_0%20+%20%5Cgamma_1Z%20+%20%5Ceta%0A"></p>
<p>Second stage: <img src="https://latex.codecogs.com/png.latex?%0AY%20=%20%5Cbeta_0%20+%20%5Cbeta_1%5Chat%7BX%7D%20+%20%5Cepsilon%0A"></p>
</section>
<section id="regression-discontinuity" class="level3">
<h3 class="anchored" data-anchor-id="regression-discontinuity">3. Regression Discontinuity</h3>
<p>Sharp RD estimator:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctau_%7BSRD%7D%20=%20%5Clim_%7Bx%20%5Cdownarrow%20c%7D%20%5Cmathbb%7BE%7D%5BY%7CX=x%5D%20-%20%5Clim_%7Bx%20%5Cuparrow%20c%7D%20%5Cmathbb%7BE%7D%5BY%7CX=x%5D%0A"></p>
<p>Fuzzy RD estimator:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctau_%7BFRD%7D%20=%20%5Cfrac%7B%5Clim_%7Bx%20%5Cdownarrow%20c%7D%20%5Cmathbb%7BE%7D%5BY%7CX=x%5D%20-%20%5Clim_%7Bx%20%5Cuparrow%20c%7D%20%5Cmathbb%7BE%7D%5BY%7CX=x%5D%7D%7B%5Clim_%7Bx%20%5Cdownarrow%20c%7D%20%5Cmathbb%7BE%7D%5BD%7CX=x%5D%20-%20%5Clim_%7Bx%20%5Cuparrow%20c%7D%20%5Cmathbb%7BE%7D%5BD%7CX=x%5D%7D%0A"></p>
</section>
</section>
<section id="structural-learning" class="level2">
<h2 class="anchored" data-anchor-id="structural-learning">Structural Learning</h2>
<section id="constraint-based-methods" class="level3">
<h3 class="anchored" data-anchor-id="constraint-based-methods">1. Constraint-Based Methods</h3>
<p>PC Algorithm steps: 1. Start with complete undirected graph 2. Remove edges based on conditional independence 3. Orient v-structures 4. Orient remaining edges</p>
<p>Independence test statistic:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cchi%5E2%20=%20n%5Csum_%7Bi,j%7D%20%5Cfrac%7B(O_%7Bij%7D%20-%20E_%7Bij%7D)%5E2%7D%7BE_%7Bij%7D%7D%0A"></p>
</section>
<section id="score-based-methods" class="level3">
<h3 class="anchored" data-anchor-id="score-based-methods">2. Score-Based Methods</h3>
<p>BIC score:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BBIC%7D(G)%20=%20%5Cell(D%7CG)%20-%20%5Cfrac%7B%5Clog%20n%7D%7B2%7D%7CG%7C%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cell(D%7CG)"> is log-likelihood - <img src="https://latex.codecogs.com/png.latex?%7CG%7C"> is model complexity - <img src="https://latex.codecogs.com/png.latex?n"> is sample size</p>
</section>
<section id="hybrid-methods" class="level3">
<h3 class="anchored" data-anchor-id="hybrid-methods">3. Hybrid Methods</h3>
<p>MMHC algorithm: 1. Learn skeleton using constraint-based method 2. Orient edges using score-based method</p>
<p>Score function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BScore%7D(G)%20=%20%5Ctext%7BBIC%7D(G)%20+%20%5Clambda%20%5Ctext%7BSparsity%7D(G)%0A"></p>
</section>
</section>
<section id="advanced-topics" class="level2">
<h2 class="anchored" data-anchor-id="advanced-topics">Advanced Topics</h2>
<section id="counterfactual-analysis" class="level3">
<h3 class="anchored" data-anchor-id="counterfactual-analysis">1. Counterfactual Analysis</h3>
<p>Fundamental problem of causal inference:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BACE%7D%20=%20%5Cmathbb%7BE%7D%5BY(1)%20-%20Y(0)%5D%0A"></p>
<p>But we only observe:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AY%20=%20TY(1)%20+%20(1-T)Y(0)%0A"></p>
</section>
<section id="mediation-analysis" class="level3">
<h3 class="anchored" data-anchor-id="mediation-analysis">2. Mediation Analysis</h3>
<p>Direct and indirect effects:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Ctext%7BNDE%7D%20&amp;=%20%5Cmathbb%7BE%7D%5BY(t,M(t'))%5D%20-%20%5Cmathbb%7BE%7D%5BY(t',M(t'))%5D%20%5C%5C%0A%5Ctext%7BNIE%7D%20&amp;=%20%5Cmathbb%7BE%7D%5BY(t,M(t))%5D%20-%20%5Cmathbb%7BE%7D%5BY(t,M(t'))%5D%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="time-varying-treatments" class="level3">
<h3 class="anchored" data-anchor-id="time-varying-treatments">3. Time-Varying Treatments</h3>
<p>G-computation formula:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5BY_%7B%5Cbar%7Ba%7D%7D%5D%20=%20%5Csum_%7B%5Cbar%7Bl%7D%7D%20%5Cprod_%7Bt=0%7D%5EK%20P(l_t%7Cl_%7Bt-1%7D,a_%7Bt-1%7D)P(y%7C%5Cbar%7Bl%7D,%5Cbar%7Ba%7D)%0A"></p>
</section>
</section>
<section id="implementation-considerations" class="level2">
<h2 class="anchored" data-anchor-id="implementation-considerations">Implementation Considerations</h2>
<section id="sensitivity-analysis" class="level3">
<h3 class="anchored" data-anchor-id="sensitivity-analysis">1. Sensitivity Analysis</h3>
<p>Rosenbaum bounds:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7B1%7D%7B%5CGamma%7D%20%5Cleq%20%5Cfrac%7BP(Z=1%7CX)P(Z=0%7CX')%7D%7BP(Z=0%7CX)P(Z=1%7CX')%7D%20%5Cleq%20%5CGamma%0A"></p>
</section>
<section id="missing-data" class="level3">
<h3 class="anchored" data-anchor-id="missing-data">2. Missing Data</h3>
<p>Multiple imputation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Ctheta%7D%20=%20%5Cfrac%7B1%7D%7BM%7D%5Csum_%7Bm=1%7D%5EM%20%5Chat%7B%5Ctheta%7D_m%0A"></p>
</section>
<section id="heterogeneous-effects" class="level3">
<h3 class="anchored" data-anchor-id="heterogeneous-effects">3. Heterogeneous Effects</h3>
<p>Conditional average treatment effect:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BCATE%7D(x)%20=%20%5Cmathbb%7BE%7D%5BY(1)%20-%20Y(0)%7CX=x%5D%0A"></p>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="study-design" class="level3">
<h3 class="anchored" data-anchor-id="study-design">1. Study Design</h3>
<ol type="1">
<li>Randomization:
<ul>
<li>Complete randomization</li>
<li>Stratified randomization</li>
<li>Cluster randomization</li>
</ul></li>
<li>Sample Size:
<ul>
<li>Power analysis</li>
<li>Effect size estimation</li>
<li>Variance components</li>
</ul></li>
<li>Measurement:
<ul>
<li>Reliability</li>
<li>Validity</li>
<li>Missing data handling</li>
</ul></li>
</ol>
</section>
<section id="analysis-strategy" class="level3">
<h3 class="anchored" data-anchor-id="analysis-strategy">2. Analysis Strategy</h3>
<ol type="1">
<li>Identification:
<ul>
<li>Check assumptions</li>
<li>Sensitivity analysis</li>
<li>Multiple methods</li>
</ul></li>
<li>Estimation:
<ul>
<li>Robust methods</li>
<li>Bootstrap</li>
<li>Cross-validation</li>
</ul></li>
<li>Interpretation:
<ul>
<li>Effect sizes</li>
<li>Confidence intervals</li>
<li>Multiple testing</li>
</ul></li>
</ol>
</section>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">Applications</h2>
<section id="economics" class="level3">
<h3 class="anchored" data-anchor-id="economics">1. Economics</h3>
<p>Program evaluation: - Treatment effects - Policy analysis - Market interventions</p>
</section>
<section id="healthcare" class="level3">
<h3 class="anchored" data-anchor-id="healthcare">2. Healthcare</h3>
<p>Clinical trials: - Drug efficacy - Treatment comparison - Side effects</p>
</section>
<section id="social-sciences" class="level3">
<h3 class="anchored" data-anchor-id="social-sciences">3. Social Sciences</h3>
<p>Policy research: - Educational interventions - Social programs - Behavioral studies</p>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Theory:
<ul>
<li>“Causality” by Pearl</li>
<li>“Causal Inference in Statistics” by Pearl et al.</li>
<li>“Elements of Causal Inference” by Peters et al.</li>
</ul></li>
<li>Methods:
<ul>
<li>“Mostly Harmless Econometrics” by Angrist and Pischke</li>
<li>“Counterfactuals and Causal Inference” by Morgan and Winship</li>
<li>“Causal Inference for Statistics” by Hernán and Robins</li>
</ul></li>
<li>Applications:
<ul>
<li>“Causal Machine Learning” by Athey and Imbens</li>
<li>“The Book of Why” by Pearl and Mackenzie</li>
<li>“Observation and Experiment” by Rosenbaum</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>causality</category>
  <category>statistics</category>
  <category>mathematics</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/causal-inference/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/causal-inference/causal_inference.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Computational Learning Theory</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/computational-learning-theory/</link>
  <description><![CDATA[ 





<section id="computational-learning-theory" class="level1">
<h1>Computational Learning Theory</h1>
<section id="complexity-measures" class="level2">
<h2 class="anchored" data-anchor-id="complexity-measures">Complexity Measures</h2>
<section id="sample-complexity" class="level3">
<h3 class="anchored" data-anchor-id="sample-complexity">1. Sample Complexity</h3>
<p>PAC learning bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Am%20%5Cgeq%20%5Cfrac%7B1%7D%7B%5Cepsilon%7D%5Cleft(%5Cln%7C%5Cmathcal%7BH%7D%7C%20+%20%5Cln%5Cfrac%7B1%7D%7B%5Cdelta%7D%5Cright)%0A"></p>
<p>VC dimension bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Am%20=%20O%5Cleft(%5Cfrac%7Bd%7D%7B%5Cepsilon%5E2%7D%5Cln%5Cfrac%7B1%7D%7B%5Cepsilon%7D%20+%20%5Cfrac%7B1%7D%7B%5Cepsilon%5E2%7D%5Cln%5Cfrac%7B1%7D%7B%5Cdelta%7D%5Cright)%0A"></p>
</section>
<section id="time-complexity" class="level3">
<h3 class="anchored" data-anchor-id="time-complexity">2. Time Complexity</h3>
<p>Learning algorithm runtime:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AT(m,n,%5Cepsilon,%5Cdelta)%20=%20%5Ctext%7Bpoly%7D(m,n,%5Cfrac%7B1%7D%7B%5Cepsilon%7D,%5Cfrac%7B1%7D%7B%5Cdelta%7D)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?m"> is sample size - <img src="https://latex.codecogs.com/png.latex?n"> is input dimension - <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> is accuracy - <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> is confidence</p>
</section>
<section id="space-complexity" class="level3">
<h3 class="anchored" data-anchor-id="space-complexity">3. Space Complexity</h3>
<p>Memory requirements:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS(m,n)%20=%20O(mn)%0A"></p>
<p>Streaming bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS%20=%20O(%5Clog%20m%20+%20%5Clog%20n)%0A"></p>
</section>
</section>
<section id="learnability-analysis" class="level2">
<h2 class="anchored" data-anchor-id="learnability-analysis">Learnability Analysis</h2>
<section id="efficient-learnability" class="level3">
<h3 class="anchored" data-anchor-id="efficient-learnability">1. Efficient Learnability</h3>
<p>Definition: - Polynomial sample complexity - Polynomial time complexity - Polynomial space complexity</p>
<p>Requirements:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Am%20&amp;=%20%5Ctext%7Bpoly%7D(n,%5Cfrac%7B1%7D%7B%5Cepsilon%7D,%5Cfrac%7B1%7D%7B%5Cdelta%7D)%20%5C%5C%0AT%20&amp;=%20%5Ctext%7Bpoly%7D(n,%5Cfrac%7B1%7D%7B%5Cepsilon%7D,%5Cfrac%7B1%7D%7B%5Cdelta%7D)%20%5C%5C%0AS%20&amp;=%20%5Ctext%7Bpoly%7D(n,%5Cfrac%7B1%7D%7B%5Cepsilon%7D,%5Cfrac%7B1%7D%7B%5Cdelta%7D)%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="hardness-results" class="level3">
<h3 class="anchored" data-anchor-id="hardness-results">2. Hardness Results</h3>
<p>Cryptographic assumptions:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP%20%5Cneq%20NP%20%5Cimplies%20%5Ctext%7BNot%20efficiently%20learnable%7D%0A"></p>
<p>Reduction techniques:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BProblem%20A%7D%20%5Cleq_p%20%5Ctext%7BProblem%20B%7D%0A"></p>
</section>
<section id="average-case-analysis" class="level3">
<h3 class="anchored" data-anchor-id="average-case-analysis">3. Average-Case Analysis</h3>
<p>Expected runtime:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5BT(X)%5D%20=%20%5Csum_%7Bx%7D%20T(x)P(x)%0A"></p>
<p>Smoothed analysis:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmax_%7B%5Ctext%7Binput%20%7D%20I%7D%20%5Cmathbb%7BE%7D_%7B%5Ctext%7Bnoise%20%7D%20%5Cxi%7D%5BT(I%20+%20%5Cxi)%5D%0A"></p>
</section>
</section>
<section id="learning-models" class="level2">
<h2 class="anchored" data-anchor-id="learning-models">Learning Models</h2>
<section id="query-learning" class="level3">
<h3 class="anchored" data-anchor-id="query-learning">1. Query Learning</h3>
<p>Membership queries:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BMQ%7D(x)%20=%20c(x)%0A"></p>
<p>Equivalence queries:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BEQ%7D(h)%20=%20%5Cbegin%7Bcases%7D%0A%5Ctext%7BYes%7D%20&amp;%20%5Ctext%7Bif%20%7D%20h%20%5Cequiv%20c%20%5C%5C%0Ax%20&amp;%20%5Ctext%7Bwhere%20%7D%20h(x)%20%5Cneq%20c(x)%0A%5Cend%7Bcases%7D%0A"></p>
</section>
<section id="online-learning" class="level3">
<h3 class="anchored" data-anchor-id="online-learning">2. Online Learning</h3>
<p>Mistake bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AM%20%5Cleq%20%5Ctext%7Bpoly%7D(n,%5Ctext%7Bsize%7D(c))%0A"></p>
<p>Halving algorithm:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cmathcal%7BH%7D_t%7C%20%5Cleq%20%7C%5Cmathcal%7BH%7D_0%7C/2%5Et%0A"></p>
</section>
<section id="active-learning" class="level3">
<h3 class="anchored" data-anchor-id="active-learning">3. Active Learning</h3>
<p>Label complexity:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5CLambda(%5Cepsilon,%5Cdelta)%20=%20O(%5Ctheta%20d%5Clog(1/%5Cepsilon)%5Clog(1/%5Cdelta))%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is disagreement coefficient - <img src="https://latex.codecogs.com/png.latex?d"> is VC dimension</p>
</section>
</section>
<section id="algorithmic-efficiency" class="level2">
<h2 class="anchored" data-anchor-id="algorithmic-efficiency">Algorithmic Efficiency</h2>
<section id="boosting-analysis" class="level3">
<h3 class="anchored" data-anchor-id="boosting-analysis">1. Boosting Analysis</h3>
<p>AdaBoost iterations:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AT%20=%20O%5Cleft(%5Cfrac%7B%5Clog(1/%5Cepsilon)%7D%7B%5Cgamma%5E2%7D%5Cright)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cgamma"> is edge over random</p>
</section>
<section id="kernel-methods" class="level3">
<h3 class="anchored" data-anchor-id="kernel-methods">2. Kernel Methods</h3>
<p>Kernel evaluation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AT%20=%20O(m%5E2n)%0A"></p>
<p>Nyström approximation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5C%7CK%20-%20%5Ctilde%7BK%7D%5C%7C_2%20%5Cleq%20%5Cepsilon%0A"></p>
</section>
<section id="neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="neural-networks">3. Neural Networks</h3>
<p>Backpropagation complexity:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AT%20=%20O(mnd)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?d"> is network depth</p>
</section>
</section>
<section id="computational-trade-offs" class="level2">
<h2 class="anchored" data-anchor-id="computational-trade-offs">Computational Trade-offs</h2>
<section id="time-space-trade-offs" class="level3">
<h3 class="anchored" data-anchor-id="time-space-trade-offs">1. Time-Space Trade-offs</h3>
<p>Memory-runtime relationship:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AT%20%5Ccdot%20S%20=%20%5COmega(n%5E2)%0A"></p>
<p>Streaming algorithms:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS%20%5Ccdot%20%5Ctext%7Bpasses%7D%20=%20%5COmega(n)%0A"></p>
</section>
<section id="sample-computation-trade-offs" class="level3">
<h3 class="anchored" data-anchor-id="sample-computation-trade-offs">2. Sample-Computation Trade-offs</h3>
<p>Active learning:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bqueries%7D%20%5Ccdot%20%5Ctext%7Bcomputation%7D%20=%20O(m%5Clog%20m)%0A"></p>
<p>Parallel speedup:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AT_p%20=%20%5Cfrac%7BT_1%7D%7Bp%7D%20+%20O(%5Clog%20p)%0A"></p>
</section>
<section id="accuracy-complexity-trade-offs" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-complexity-trade-offs">3. Accuracy-Complexity Trade-offs</h3>
<p>Approximation guarantee:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x)%20%5Cleq%20(1+%5Cepsilon)%5Ctext%7BOPT%7D%0A"></p>
<p>Runtime dependency:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AT%20=%20O(%5Ctext%7Bpoly%7D(n,1/%5Cepsilon))%0A"></p>
</section>
</section>
<section id="advanced-topics" class="level2">
<h2 class="anchored" data-anchor-id="advanced-topics">Advanced Topics</h2>
<section id="communication-complexity" class="level3">
<h3 class="anchored" data-anchor-id="communication-complexity">1. Communication Complexity</h3>
<p>Two-party protocol:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0ACC(f)%20=%20%5Cmin_P%20%5Cmax_%7Bx,y%7D%20%5Ctext%7Bbits%7D(P(x,y))%0A"></p>
<p>Lower bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0ACC(f)%20%5Cgeq%20%5Clog_2%20%5Ctext%7Brank%7D(M_f)%0A"></p>
</section>
<section id="circuit-complexity" class="level3">
<h3 class="anchored" data-anchor-id="circuit-complexity">2. Circuit Complexity</h3>
<p>Boolean circuit size:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bsize%7D(f)%20=%20%5Cmin_%7BC:%20C%20%5Ctext%7B%20computes%20%7D%20f%7D%20%5Ctext%7Bgates%7D(C)%0A"></p>
<p>Depth bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bdepth%7D(f)%20%5Cgeq%20%5Clog_2%20%5Ctext%7Bsensitivity%7D(f)%0A"></p>
</section>
<section id="information-complexity" class="level3">
<h3 class="anchored" data-anchor-id="information-complexity">3. Information Complexity</h3>
<p>Information cost:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AIC(P)%20=%20I(X;M%7CY)%20+%20I(Y;M%7CX)%0A"></p>
<p>Protocol compression:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7CP'%7C%20%5Cleq%20O(IC(P)%5Clog%7CP%7C)%0A"></p>
</section>
</section>
<section id="practical-implications" class="level2">
<h2 class="anchored" data-anchor-id="practical-implications">Practical Implications</h2>
<section id="algorithm-design" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-design">1. Algorithm Design</h3>
<ol type="1">
<li>Resource Constraints:
<ul>
<li>Time efficiency</li>
<li>Memory usage</li>
<li>Communication cost</li>
</ul></li>
<li>Scalability:
<ul>
<li>Input size</li>
<li>Dimensionality</li>
<li>Sample complexity</li>
</ul></li>
<li>Parallelization:
<ul>
<li>Task decomposition</li>
<li>Communication overhead</li>
<li>Load balancing</li>
</ul></li>
</ol>
</section>
<section id="system-implementation" class="level3">
<h3 class="anchored" data-anchor-id="system-implementation">2. System Implementation</h3>
<ol type="1">
<li>Architecture:
<ul>
<li>Processing units</li>
<li>Memory hierarchy</li>
<li>Network topology</li>
</ul></li>
<li>Optimization:
<ul>
<li>Caching strategies</li>
<li>Data structures</li>
<li>Algorithm selection</li>
</ul></li>
<li>Trade-offs:
<ul>
<li>Accuracy vs speed</li>
<li>Memory vs computation</li>
<li>Communication vs local processing</li>
</ul></li>
</ol>
</section>
</section>
<section id="theoretical-frameworks" class="level2">
<h2 class="anchored" data-anchor-id="theoretical-frameworks">Theoretical Frameworks</h2>
<section id="learning-with-errors" class="level3">
<h3 class="anchored" data-anchor-id="learning-with-errors">1. Learning with Errors</h3>
<p>LWE assumption:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A(A,As+e)%20%5Capprox_c%20(A,u)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?A"> is random matrix - <img src="https://latex.codecogs.com/png.latex?s"> is secret - <img src="https://latex.codecogs.com/png.latex?e"> is error - <img src="https://latex.codecogs.com/png.latex?u"> is uniform</p>
</section>
<section id="statistical-query-model" class="level3">
<h3 class="anchored" data-anchor-id="statistical-query-model">2. Statistical Query Model</h3>
<p>Query complexity:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BSQ-DIM%7D(%5Cmathcal%7BC%7D)%20=%20%5Cmin_%7BD%7D%20%5Cmax_%7Bf%20%5Cin%20%5Cmathcal%7BC%7D%7D%20%7C%5Clangle%20f,D%20%5Crangle%7C%0A"></p>
</section>
<section id="property-testing" class="level3">
<h3 class="anchored" data-anchor-id="property-testing">3. Property Testing</h3>
<p>Query complexity:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AQ(%5Cepsilon)%20=%20O(%5Cfrac%7B1%7D%7B%5Cepsilon%7D%5Clog%5Cfrac%7B1%7D%7B%5Cepsilon%7D)%0A"></p>
<p>Distance measure:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bdist%7D(f,g)%20=%20%5Ctext%7BPr%7D_%7Bx%7D%5Bf(x)%20%5Cneq%20g(x)%5D%0A"></p>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="algorithm-analysis" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-analysis">1. Algorithm Analysis</h3>
<ol type="1">
<li>Complexity Measures:
<ul>
<li>Asymptotic bounds</li>
<li>Average case</li>
<li>Worst case</li>
</ul></li>
<li>Resource Usage:
<ul>
<li>Memory footprint</li>
<li>CPU utilization</li>
<li>I/O operations</li>
</ul></li>
<li>Scalability:
<ul>
<li>Data size</li>
<li>Dimensionality</li>
<li>Parallelization</li>
</ul></li>
</ol>
</section>
<section id="implementation" class="level3">
<h3 class="anchored" data-anchor-id="implementation">2. Implementation</h3>
<ol type="1">
<li>Optimization:
<ul>
<li>Algorithm choice</li>
<li>Data structures</li>
<li>Memory management</li>
</ul></li>
<li>Trade-offs:
<ul>
<li>Time vs space</li>
<li>Accuracy vs speed</li>
<li>Communication vs computation</li>
</ul></li>
<li>Evaluation:
<ul>
<li>Benchmarking</li>
<li>Profiling</li>
<li>Performance analysis</li>
</ul></li>
</ol>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Theory:
<ul>
<li>“Foundations of Machine Learning” by Mohri et al.</li>
<li>“Understanding Machine Learning” by Shalev-Shwartz and Ben-David</li>
<li>“Computational Learning Theory” by Kearns and Vazirani</li>
</ul></li>
<li>Complexity:
<ul>
<li>“Computational Complexity” by Arora and Barak</li>
<li>“Communication Complexity” by Kushilevitz and Nisan</li>
<li>“The Nature of Computation” by Moore and Mertens</li>
</ul></li>
<li>Applications:
<ul>
<li>“Algorithmic Learning Theory” by Anthony and Biggs</li>
<li>“Learning with Kernels” by Schölkopf and Smola</li>
<li>“Theoretical Computer Science” by Hopcroft and Ullman</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>theory</category>
  <category>complexity</category>
  <category>algorithms</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/computational-learning-theory/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/computational-learning-theory/computational_theory.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Deep Learning: The Technology Behind AI’s Recent Breakthroughs</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/deep-learning-beginners/</link>
  <description><![CDATA[ 





<p>The first time I encountered deep learning, I was amazed by its ability to solve problems that seemed impossible just a few years ago. From beating world champions at complex games to generating art that could pass for human-made, deep learning has transformed the landscape of artificial intelligence. But what makes this technology so powerful, and how does it actually work?</p>
<section id="the-brain-inspired-technology" class="level2">
<h2 class="anchored" data-anchor-id="the-brain-inspired-technology">The Brain-Inspired Technology</h2>
<p>Imagine trying to teach a ### The Brain Connection Think of it like this: - Your brain has billions of neurons - Each neuron connects to thousands of others - They work together to process information - Deep learning mimics this structure</p>
</section>
<section id="neural-networks-explained" class="level2">
<h2 class="anchored" data-anchor-id="neural-networks-explained">Neural Networks Explained</h2>
<section id="the-basic-building-block-neurons" class="level3">
<h3 class="anchored" data-anchor-id="the-basic-building-block-neurons">1. The Basic Building Block: Neurons</h3>
<p>Imagine a neuron as a simple calculator that: - Takes in multiple numbers (inputs) - Multiplies each by a weight (importance) - Adds them all up - Decides whether to “fire” based on the sum</p>
<p>Example: - Inputs: [0.2, 0.7, 0.1] - Weights: [0.8, 0.3, 0.5] - Sum: (0.2 × 0.8) + (0.7 × 0.3) + (0.1 × 0.5) = 0.41 - Then decides whether to activate based on this sum</p>
</section>
<section id="layers-of-neurons" class="level3">
<h3 class="anchored" data-anchor-id="layers-of-neurons">2. Layers of Neurons</h3>
<p>Think of layers like assembly lines: 1. Input Layer - Receives raw data - Like our senses receiving information</p>
<ol start="2" type="1">
<li>Hidden Layers
<ul>
<li>Process information</li>
<li>Find patterns</li>
<li>Transform data</li>
</ul></li>
<li>Output Layer
<ul>
<li>Makes final decisions</li>
<li>Provides predictions</li>
</ul></li>
</ol>
</section>
</section>
<section id="how-neural-networks-learn" class="level2">
<h2 class="anchored" data-anchor-id="how-neural-networks-learn">How Neural Networks Learn</h2>
<section id="the-learning-process" class="level3">
<h3 class="anchored" data-anchor-id="the-learning-process">1. The Learning Process</h3>
<p>Like learning to ride a bike: 1. Try something 2. See how well it works 3. Adjust based on mistakes 4. Try again 5. Get better over time</p>
</section>
<section id="training-steps" class="level3">
<h3 class="anchored" data-anchor-id="training-steps">2. Training Steps</h3>
<ol type="1">
<li>Forward Pass:
<ul>
<li>Data flows through the network</li>
<li>Network makes a prediction</li>
<li>Like making a guess</li>
</ul></li>
<li>Error Calculation:
<ul>
<li>Compare prediction with truth</li>
<li>Calculate how wrong it was</li>
<li>Like measuring mistakes</li>
</ul></li>
<li>Backward Pass:
<ul>
<li>Adjust weights based on errors</li>
<li>Like learning from mistakes</li>
<li>Small improvements each time</li>
</ul></li>
</ol>
</section>
</section>
<section id="types-of-neural-networks" class="level2">
<h2 class="anchored" data-anchor-id="types-of-neural-networks">Types of Neural Networks</h2>
<section id="feedforward-networks" class="level3">
<h3 class="anchored" data-anchor-id="feedforward-networks">1. Feedforward Networks</h3>
<p>The simplest type: - Information flows one way - Good for basic patterns - Like classifying images - Example: Identifying numbers</p>
</section>
<section id="convolutional-networks-cnns" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-networks-cnns">2. Convolutional Networks (CNNs)</h3>
<p>Specialized for images: - Look at small parts at a time - Combine information - Find patterns in images - Example: Face recognition</p>
</section>
<section id="recurrent-networks-rnns" class="level3">
<h3 class="anchored" data-anchor-id="recurrent-networks-rnns">3. Recurrent Networks (RNNs)</h3>
<p>Good for sequences: - Remember previous information - Process data over time - Good for text and speech - Example: Translation</p>
</section>
</section>
<section id="common-applications" class="level2">
<h2 class="anchored" data-anchor-id="common-applications">Common Applications</h2>
<section id="computer-vision" class="level3">
<h3 class="anchored" data-anchor-id="computer-vision">1. Computer Vision</h3>
<p>What it can do: - Recognize objects - Detect faces - Read text - Find patterns in images</p>
<p>Real Examples: - Face ID on phones - Medical image analysis - Self-driving cars - Security cameras</p>
</section>
<section id="natural-language" class="level3">
<h3 class="anchored" data-anchor-id="natural-language">2. Natural Language</h3>
<p>Understanding text: - Translation - Summarization - Question answering - Text generation</p>
<p>Real Examples: - Google Translate - Chatbots - Voice assistants - Email filters</p>
</section>
<section id="speech-processing" class="level3">
<h3 class="anchored" data-anchor-id="speech-processing">3. Speech Processing</h3>
<p>Working with audio: - Speech recognition - Voice synthesis - Language translation - Music generation</p>
<p>Real Examples: - Siri/Alexa - Transcription services - Voice assistants - Music recommendations</p>
</section>
</section>
<section id="how-deep-learning-works" class="level2">
<h2 class="anchored" data-anchor-id="how-deep-learning-works">How Deep Learning Works</h2>
<section id="feature-learning" class="level3">
<h3 class="anchored" data-anchor-id="feature-learning">1. Feature Learning</h3>
<p>Automatic pattern finding: - Low-level features (edges, colors) - Mid-level features (shapes, textures) - High-level features (objects, concepts)</p>
<p>Example in Vision: 1. First layer sees edges 2. Next layer combines edges into shapes 3. Final layers recognize objects</p>
</section>
<section id="representation-learning" class="level3">
<h3 class="anchored" data-anchor-id="representation-learning">2. Representation Learning</h3>
<p>Building understanding: - Converts raw data to useful form - Learns important characteristics - Creates meaningful representations</p>
<p>Example in Text: 1. Words to numbers 2. Understanding context 3. Capturing meaning</p>
</section>
<section id="deep-learning-vs-traditional-ml" class="level3">
<h3 class="anchored" data-anchor-id="deep-learning-vs-traditional-ml">3. Deep Learning vs Traditional ML</h3>
<p>Key differences: - Automatic feature extraction - Multiple layers of processing - Better with large datasets - More complex patterns</p>
</section>
</section>
<section id="important-concepts" class="level2">
<h2 class="anchored" data-anchor-id="important-concepts">Important Concepts</h2>
<section id="training-data" class="level3">
<h3 class="anchored" data-anchor-id="training-data">1. Training Data</h3>
<p>What’s needed: - Large amounts of data - Good quality examples - Diverse cases - Clear labels (for supervised learning)</p>
</section>
<section id="computing-power" class="level3">
<h3 class="anchored" data-anchor-id="computing-power">2. Computing Power</h3>
<p>Requirements: - Powerful processors (GPUs) - Lots of memory - Long training times - Efficient algorithms</p>
</section>
<section id="model-architecture" class="level3">
<h3 class="anchored" data-anchor-id="model-architecture">3. Model Architecture</h3>
<p>Design choices: - Number of layers - Types of layers - Connection patterns - Activation functions</p>
</section>
</section>
<section id="common-challenges" class="level2">
<h2 class="anchored" data-anchor-id="common-challenges">Common Challenges</h2>
<section id="data-issues" class="level3">
<h3 class="anchored" data-anchor-id="data-issues">1. Data Issues</h3>
<p>Common problems: - Not enough data - Poor quality data - Biased data - Inconsistent labels</p>
</section>
<section id="training-problems" class="level3">
<h3 class="anchored" data-anchor-id="training-problems">2. Training Problems</h3>
<p>Typical issues: - Long training times - Unstable training - Overfitting - Resource limitations</p>
</section>
<section id="deployment-challenges" class="level3">
<h3 class="anchored" data-anchor-id="deployment-challenges">3. Deployment Challenges</h3>
<p>Real-world issues: - Model size - Computation needs - Integration - Maintenance</p>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="start-simple" class="level3">
<h3 class="anchored" data-anchor-id="start-simple">1. Start Simple</h3>
<p>Basic approach: - Use proven architectures - Start with small models - Understand the basics - Build complexity gradually</p>
</section>
<section id="data-preparation" class="level3">
<h3 class="anchored" data-anchor-id="data-preparation">2. Data Preparation</h3>
<p>Key steps: - Clean your data - Normalize inputs - Handle missing values - Balance datasets</p>
</section>
<section id="model-development" class="level3">
<h3 class="anchored" data-anchor-id="model-development">3. Model Development</h3>
<p>Good habits: - Start with baselines - Experiment systematically - Document everything - Test thoroughly</p>
</section>
</section>
<section id="getting-started" class="level2">
<h2 class="anchored" data-anchor-id="getting-started">Getting Started</h2>
<section id="prerequisites" class="level3">
<h3 class="anchored" data-anchor-id="prerequisites">1. Prerequisites</h3>
<p>What you need: - Python programming - Basic math - Machine learning basics - Development tools</p>
</section>
<section id="learning-path" class="level3">
<h3 class="anchored" data-anchor-id="learning-path">2. Learning Path</h3>
<p>Steps to follow: 1. Learn Python 2. Study ML basics 3. Understand neural networks 4. Practice with frameworks</p>
</section>
<section id="tools-and-frameworks" class="level3">
<h3 class="anchored" data-anchor-id="tools-and-frameworks">3. Tools and Frameworks</h3>
<p>Popular options: - PyTorch - TensorFlow - Keras - Fast.ai</p>
</section>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<section id="online-courses" class="level3">
<h3 class="anchored" data-anchor-id="online-courses">1. Online Courses</h3>
<p>Best options: - Fast.ai - Coursera Deep Learning - Stanford CS231n - Deep Learning.AI</p>
</section>
<section id="books" class="level3">
<h3 class="anchored" data-anchor-id="books">2. Books</h3>
<p>Recommended reading: - “Deep Learning with Python” - “Grokking Deep Learning” - “Deep Learning” by Goodfellow - “Neural Networks from Scratch”</p>
</section>
<section id="practice-resources" class="level3">
<h3 class="anchored" data-anchor-id="practice-resources">3. Practice Resources</h3>
<p>Where to practice: - Kaggle competitions - Google Colab - GitHub projects - Online tutorials</p>
<p>Remember: Deep learning is powerful but requires patience to learn. Start with simple concepts, practice regularly, and gradually tackle more complex topics. Focus on understanding rather than memorizing, and always experiment with code to reinforce your learning.</p>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>deep-learning</category>
  <category>neural-networks</category>
  <category>beginner</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/deep-learning-beginners/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/deep-learning-beginners/deep_learning.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Generative Models: Mathematical Foundations and Architectures</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/generative-models/</link>
  <description><![CDATA[ 





<section id="generative-models-mathematical-foundations" class="level1">
<h1>Generative Models: Mathematical Foundations</h1>
<section id="variational-autoencoders-vaes" class="level2">
<h2 class="anchored" data-anchor-id="variational-autoencoders-vaes">Variational Autoencoders (VAEs)</h2>
<section id="evidence-lower-bound-elbo" class="level3">
<h3 class="anchored" data-anchor-id="evidence-lower-bound-elbo">1. Evidence Lower Bound (ELBO)</h3>
<p>The VAE objective maximizes the ELBO:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(%5Ctheta,%20%5Cphi;%20x)%20=%20%5Cmathbb%7BE%7D_%7Bq_%5Cphi(z%7Cx)%7D%5B%5Clog%20p_%5Ctheta(x%7Cz)%5D%20-%20D_%7BKL%7D(q_%5Cphi(z%7Cx)%7C%7Cp(z))%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?q_%5Cphi(z%7Cx)"> is the encoder (inference model) - <img src="https://latex.codecogs.com/png.latex?p_%5Ctheta(x%7Cz)"> is the decoder (generative model) - <img src="https://latex.codecogs.com/png.latex?p(z)"> is the prior distribution - <img src="https://latex.codecogs.com/png.latex?D_%7BKL%7D"> is the Kullback-Leibler divergence</p>
</section>
<section id="reparameterization-trick" class="level3">
<h3 class="anchored" data-anchor-id="reparameterization-trick">2. Reparameterization Trick</h3>
<p>Enables backpropagation through sampling:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Az%20=%20%5Cmu_%5Cphi(x)%20+%20%5Csigma_%5Cphi(x)%20%5Codot%20%5Cepsilon,%20%5Cquad%20%5Cepsilon%20%5Csim%20%5Cmathcal%7BN%7D(0,%20I)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cmu_%5Cphi(x)"> is the mean encoder network - <img src="https://latex.codecogs.com/png.latex?%5Csigma_%5Cphi(x)"> is the standard deviation encoder network - <img src="https://latex.codecogs.com/png.latex?%5Codot"> denotes element-wise multiplication</p>
</section>
</section>
<section id="generative-adversarial-networks-gans" class="level2">
<h2 class="anchored" data-anchor-id="generative-adversarial-networks-gans">Generative Adversarial Networks (GANs)</h2>
<section id="minimax-objective" class="level3">
<h3 class="anchored" data-anchor-id="minimax-objective">1. Minimax Objective</h3>
<p>The original GAN formulation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_G%20%5Cmax_D%20V(D,G)%20=%20%5Cmathbb%7BE%7D_%7Bx%5Csim%20p_%7Bdata%7D%7D%5B%5Clog%20D(x)%5D%20+%20%5Cmathbb%7BE%7D_%7Bz%5Csim%20p_z%7D%5B%5Clog(1-D(G(z)))%5D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?G"> is the generator - <img src="https://latex.codecogs.com/png.latex?D"> is the discriminator - <img src="https://latex.codecogs.com/png.latex?p_%7Bdata%7D"> is the real data distribution - <img src="https://latex.codecogs.com/png.latex?p_z"> is the latent distribution</p>
</section>
<section id="wasserstein-distance" class="level3">
<h3 class="anchored" data-anchor-id="wasserstein-distance">2. Wasserstein Distance</h3>
<p>WGAN objective using Kantorovich-Rubinstein duality:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_G%20%5Cmax_%7BD%20%5Cin%20%5Cmathcal%7BF%7D_L%7D%20%5Cmathbb%7BE%7D_%7Bx%5Csim%20p_%7Bdata%7D%7D%5BD(x)%5D%20-%20%5Cmathbb%7BE%7D_%7Bz%5Csim%20p_z%7D%5BD(G(z))%5D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BF%7D_L"> is the set of 1-Lipschitz functions</p>
</section>
<section id="gradient-penalty" class="level3">
<h3 class="anchored" data-anchor-id="gradient-penalty">3. Gradient Penalty</h3>
<p>WGAN-GP regularization term:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clambda%20%5Cmathbb%7BE%7D_%7B%5Chat%7Bx%7D%5Csim%20p_%7B%5Chat%7Bx%7D%7D%7D%5B(%5C%7C%5Cnabla_%7B%5Chat%7Bx%7D%7DD(%5Chat%7Bx%7D)%5C%7C_2%20-%201)%5E2%5D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bx%7D"> is sampled along straight lines between real and generated samples - <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is the penalty coefficient</p>
</section>
</section>
<section id="diffusion-models" class="level2">
<h2 class="anchored" data-anchor-id="diffusion-models">Diffusion Models</h2>
<section id="forward-process" class="level3">
<h3 class="anchored" data-anchor-id="forward-process">1. Forward Process</h3>
<p>The forward diffusion process:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aq(x_t%7Cx_%7Bt-1%7D)%20=%20%5Cmathcal%7BN%7D(x_t;%20%5Csqrt%7B1-%5Cbeta_t%7Dx_%7Bt-1%7D,%20%5Cbeta_tI)%0A"></p>
<p>With closed form for arbitrary timestep:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aq(x_t%7Cx_0)%20=%20%5Cmathcal%7BN%7D(x_t;%20%5Csqrt%7B%5Cbar%7B%5Calpha%7D_t%7Dx_0,%20(1-%5Cbar%7B%5Calpha%7D_t)I)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cbeta_t"> is the noise schedule - <img src="https://latex.codecogs.com/png.latex?%5Calpha_t%20=%201-%5Cbeta_t"> - <img src="https://latex.codecogs.com/png.latex?%5Cbar%7B%5Calpha%7D_t%20=%20%5Cprod_%7Bs=1%7D%5Et%20%5Calpha_s"></p>
</section>
<section id="reverse-process" class="level3">
<h3 class="anchored" data-anchor-id="reverse-process">2. Reverse Process</h3>
<p>The reverse diffusion process:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap_%5Ctheta(x_%7Bt-1%7D%7Cx_t)%20=%20%5Cmathcal%7BN%7D(x_%7Bt-1%7D;%20%5Cmu_%5Ctheta(x_t,t),%20%5CSigma_%5Ctheta(x_t,t))%0A"></p>
<p>Training objective:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D%20=%20%5Cmathbb%7BE%7D_%7Bx_0,%5Cepsilon,t%7D%5Cleft%5B%5C%7C%5Cepsilon%20-%20%5Cepsilon_%5Ctheta(x_t,t)%5C%7C%5E2%5Cright%5D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cepsilon_%5Ctheta"> predicts the noise component - <img src="https://latex.codecogs.com/png.latex?x_t%20=%20%5Csqrt%7B%5Cbar%7B%5Calpha%7D_t%7Dx_0%20+%20%5Csqrt%7B1-%5Cbar%7B%5Calpha%7D_t%7D%5Cepsilon"></p>
</section>
</section>
<section id="advanced-architectures" class="level2">
<h2 class="anchored" data-anchor-id="advanced-architectures">Advanced Architectures</h2>
<section id="normalizing-flows" class="level3">
<h3 class="anchored" data-anchor-id="normalizing-flows">1. Normalizing Flows</h3>
<p>Change of variables formula:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clog%20p_X(x)%20=%20%5Clog%20p_Z(f%5E%7B-1%7D(x))%20+%20%5Clog%5Cleft%7C%5Cdet%5Cfrac%7B%5Cpartial%20f%5E%7B-1%7D%7D%7B%5Cpartial%20x%7D%5Cright%7C%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?f"> is an invertible transformation - <img src="https://latex.codecogs.com/png.latex?p_Z"> is a simple base distribution</p>
</section>
<section id="autoregressive-models" class="level3">
<h3 class="anchored" data-anchor-id="autoregressive-models">2. Autoregressive Models</h3>
<p>Factorized probability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(x)%20=%20%5Cprod_%7Bi=1%7D%5En%20p(x_i%7Cx_%7B%3Ci%7D)%0A"></p>
<p>With masked convolutions:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ay_i%20=%20%5Csum_%7Bj%20%5Cleq%20i%7D%20m_%7Bij%7D(w_%7Bij%7D%20%5Ccdot%20x_j)%0A"></p>
</section>
<section id="energy-based-models" class="level3">
<h3 class="anchored" data-anchor-id="energy-based-models">3. Energy-Based Models</h3>
<p>Probability density:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(x)%20=%20%5Cfrac%7B1%7D%7BZ%7De%5E%7B-E(x)%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?E(x)"> is the energy function - <img src="https://latex.codecogs.com/png.latex?Z%20=%20%5Cint%20e%5E%7B-E(x)%7Ddx"> is the partition function</p>
</section>
</section>
<section id="training-dynamics" class="level2">
<h2 class="anchored" data-anchor-id="training-dynamics">Training Dynamics</h2>
<section id="mode-collapse-in-gans" class="level3">
<h3 class="anchored" data-anchor-id="mode-collapse-in-gans">1. Mode Collapse in GANs</h3>
<p>Jensen-Shannon divergence:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AJSD(P%5C%7CQ)%20=%20%5Cfrac%7B1%7D%7B2%7DD_%7BKL%7D(P%5C%7C%5Cfrac%7BP+Q%7D%7B2%7D)%20+%20%5Cfrac%7B1%7D%7B2%7DD_%7BKL%7D(Q%5C%7C%5Cfrac%7BP+Q%7D%7B2%7D)%0A"></p>
</section>
<section id="vae-posterior-collapse" class="level3">
<h3 class="anchored" data-anchor-id="vae-posterior-collapse">2. VAE Posterior Collapse</h3>
<p>KL-divergence analysis:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AD_%7BKL%7D(q_%5Cphi(z%7Cx)%5C%7Cp(z))%20=%20%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bj=1%7D%5Ed(%5Csigma_j%5E2%20+%20%5Cmu_j%5E2%20-%20%5Clog%5Csigma_j%5E2%20-%201)%0A"></p>
</section>
<section id="diffusion-model-training" class="level3">
<h3 class="anchored" data-anchor-id="diffusion-model-training">3. Diffusion Model Training</h3>
<p>Denoising score matching:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla_x%20%5Clog%20p(x)%20=%20%5Cmathbb%7BE%7D_%7Bp(t%7Cx)%7D%5B%5Cnabla_x%20%5Clog%20p(x%7Cx_t)%5D%0A"></p>
</section>
</section>
<section id="advanced-training-techniques" class="level2">
<h2 class="anchored" data-anchor-id="advanced-training-techniques">Advanced Training Techniques</h2>
<section id="progressive-growing" class="level3">
<h3 class="anchored" data-anchor-id="progressive-growing">1. Progressive Growing</h3>
<p>Resolution-dependent loss:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D_%5Ctext%7Btotal%7D%20=%20%5Csum_%7Br%7D%20%5Calpha_r%20%5Cmathcal%7BL%7D_r%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?r"> is the resolution level - <img src="https://latex.codecogs.com/png.latex?%5Calpha_r"> is the weighting factor</p>
</section>
<section id="style-mixing" class="level3">
<h3 class="anchored" data-anchor-id="style-mixing">2. Style Mixing</h3>
<p>Style transfer in latent space:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw%20=%20%5Cmathcal%7BM%7D(z)%20=%20f(z%20+%20%5CDelta%20z)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BM%7D"> is the mapping network - <img src="https://latex.codecogs.com/png.latex?f"> is a non-linear transformation</p>
</section>
<section id="adaptive-instance-normalization-adain" class="level3">
<h3 class="anchored" data-anchor-id="adaptive-instance-normalization-adain">3. Adaptive Instance Normalization (AdaIN)</h3>
<p>Style transfer operation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BAdaIN%7D(x,y)%20=%20%5Csigma(y)%5Cleft(%5Cfrac%7Bx-%5Cmu(x)%7D%7B%5Csigma(x)%7D%5Cright)%20+%20%5Cmu(y)%0A"></p>
</section>
</section>
<section id="evaluation-metrics" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-metrics">Evaluation Metrics</h2>
<section id="inception-score" class="level3">
<h3 class="anchored" data-anchor-id="inception-score">1. Inception Score</h3>
<p>Measures quality and diversity:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AIS%20=%20%5Cexp(%5Cmathbb%7BE%7D_%7Bx%5Csim%20p_g%7D%5BD_%7BKL%7D(p(y%7Cx)%5C%7Cp(y))%5D)%0A"></p>
</section>
<section id="fréchet-inception-distance" class="level3">
<h3 class="anchored" data-anchor-id="fréchet-inception-distance">2. Fréchet Inception Distance</h3>
<p>Distribution similarity metric:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AFID%20=%20%5C%7C%5Cmu_r%20-%20%5Cmu_g%5C%7C%5E2%20+%20Tr(%5CSigma_r%20+%20%5CSigma_g%20-%202(%5CSigma_r%5CSigma_g)%5E%7B1/2%7D)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cmu_r,%20%5CSigma_r"> are real data statistics - <img src="https://latex.codecogs.com/png.latex?%5Cmu_g,%20%5CSigma_g"> are generated data statistics</p>
</section>
<section id="precision-and-recall" class="level3">
<h3 class="anchored" data-anchor-id="precision-and-recall">3. Precision and Recall</h3>
<p>Two-way evaluation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Ctext%7BPrecision%7D%20&amp;=%20%5Cmathbb%7BE%7D_%7Bx%5Csim%20p_g%7D%5B%5Cmax_%7By%5Csim%20p_r%7D%20s(x,y)%5D%20%5C%5C%0A%5Ctext%7BRecall%7D%20&amp;=%20%5Cmathbb%7BE%7D_%7By%5Csim%20p_r%7D%5B%5Cmax_%7Bx%5Csim%20p_g%7D%20s(x,y)%5D%0A%5Cend%7Baligned%7D%0A"></p>
</section>
</section>
<section id="implementation-considerations" class="level2">
<h2 class="anchored" data-anchor-id="implementation-considerations">Implementation Considerations</h2>
<section id="architectural-choices" class="level3">
<h3 class="anchored" data-anchor-id="architectural-choices">1. Architectural Choices</h3>
<ol type="1">
<li>Generator Design:
<ul>
<li>Transposed convolutions vs upsampling</li>
<li>Skip connections</li>
<li>Attention mechanisms</li>
</ul></li>
<li>Discriminator Design:
<ul>
<li>Spectral normalization</li>
<li>Residual blocks</li>
<li>Multi-scale discrimination</li>
</ul></li>
<li>Loss Functions:
<ul>
<li>Adversarial loss</li>
<li>Reconstruction loss</li>
<li>Perceptual loss</li>
</ul></li>
</ol>
</section>
<section id="training-stability" class="level3">
<h3 class="anchored" data-anchor-id="training-stability">2. Training Stability</h3>
<ol type="1">
<li>Gradient Penalties:
<ul>
<li>R1 regularization</li>
<li>Path length regularization</li>
<li>Consistency regularization</li>
</ul></li>
<li>Learning Rate:
<ul>
<li>Two time-scale update rule</li>
<li>Adaptive learning rates</li>
<li>Warmup scheduling</li>
</ul></li>
<li>Batch Size:
<ul>
<li>Gradient accumulation</li>
<li>Mixed precision training</li>
<li>Memory-efficient backprop</li>
</ul></li>
</ol>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="model-selection" class="level3">
<h3 class="anchored" data-anchor-id="model-selection">1. Model Selection</h3>
<ol type="1">
<li>VAEs for:
<ul>
<li>Structured latent spaces</li>
<li>Reconstruction tasks</li>
<li>Interpretable representations</li>
</ul></li>
<li>GANs for:
<ul>
<li>High-quality generation</li>
<li>Style transfer</li>
<li>Domain translation</li>
</ul></li>
<li>Diffusion Models for:
<ul>
<li>High-fidelity generation</li>
<li>Controlled generation</li>
<li>Robust training</li>
</ul></li>
</ol>
</section>
<section id="hyperparameter-tuning" class="level3">
<h3 class="anchored" data-anchor-id="hyperparameter-tuning">2. Hyperparameter Tuning</h3>
<ol type="1">
<li>Learning Rates:
<ul>
<li>Generator: 1e-4 to 1e-3</li>
<li>Discriminator: 2e-4 to 2e-3</li>
<li>VAE: 1e-3 to 1e-2</li>
</ul></li>
<li>Batch Sizes:
<ul>
<li>GANs: 32 to 128</li>
<li>VAEs: 64 to 256</li>
<li>Diffusion: 32 to 64</li>
</ul></li>
<li>Architecture:
<ul>
<li>Layer depth</li>
<li>Channel width</li>
<li>Attention layers</li>
</ul></li>
</ol>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Theory:
<ul>
<li>“Auto-Encoding Variational Bayes” by Kingma and Welling</li>
<li>“Generative Adversarial Networks” by Goodfellow et al.</li>
<li>“Denoising Diffusion Probabilistic Models” by Ho et al.</li>
</ul></li>
<li>Architecture:
<ul>
<li>“Progressive Growing of GANs” by Karras et al.</li>
<li>“StyleGAN” by Karras et al.</li>
<li>“Normalizing Flows” by Rezende and Mohamed</li>
</ul></li>
<li>Training:
<ul>
<li>“Improved Training of Wasserstein GANs” by Gulrajani et al.</li>
<li>“Large Scale GAN Training for High Fidelity Natural Image Synthesis” by Brock et al.</li>
<li>“Improved VQGAN for Image Generation” by Esser et al.</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>generative-models</category>
  <category>deep-learning</category>
  <category>mathematics</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/generative-models/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/generative-models/generative_models.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Information Theory in Machine Learning</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/information-theory-ml/</link>
  <description><![CDATA[ 





<section id="information-theory-in-machine-learning" class="level1">
<h1>Information Theory in Machine Learning</h1>
<section id="fundamental-concepts" class="level2">
<h2 class="anchored" data-anchor-id="fundamental-concepts">Fundamental Concepts</h2>
<section id="shannon-entropy" class="level3">
<h3 class="anchored" data-anchor-id="shannon-entropy">1. Shannon Entropy</h3>
<p>Self-information of an event:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AI(x)%20=%20-%5Clog_2%20p(x)%0A"></p>
<p>Entropy of a discrete distribution:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AH(X)%20=%20-%5Csum_%7Bx%20%5Cin%20%5Cmathcal%7BX%7D%7D%20p(x)%5Clog_2%20p(x)%0A"></p>
<p>Properties: 1. Non-negativity: <img src="https://latex.codecogs.com/png.latex?H(X)%20%5Cgeq%200"> 2. Maximum entropy: <img src="https://latex.codecogs.com/png.latex?H(X)%20%5Cleq%20%5Clog_2%7C%5Cmathcal%7BX%7D%7C"> 3. Chain rule: <img src="https://latex.codecogs.com/png.latex?H(X,Y)%20=%20H(X)%20+%20H(Y%7CX)"></p>
</section>
<section id="differential-entropy" class="level3">
<h3 class="anchored" data-anchor-id="differential-entropy">2. Differential Entropy</h3>
<p>For continuous distributions:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ah(X)%20=%20-%5Cint_%7B%5Cmathcal%7BX%7D%7D%20p(x)%5Clog%20p(x)dx%0A"></p>
<p>Gaussian distribution entropy:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ah(%5Cmathcal%7BN%7D(%5Cmu,%5Csigma%5E2))%20=%20%5Cfrac%7B1%7D%7B2%7D%5Clog_2(2%5Cpi%20e%5Csigma%5E2)%0A"></p>
</section>
<section id="mutual-information" class="level3">
<h3 class="anchored" data-anchor-id="mutual-information">3. Mutual Information</h3>
<p>Definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AI(X;Y)%20=%20%5Csum_%7Bx,y%7D%20p(x,y)%5Clog_2%5Cfrac%7Bp(x,y)%7D%7Bp(x)p(y)%7D%0A"></p>
<p>Alternative forms:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AI(X;Y)%20&amp;=%20H(X)%20-%20H(X%7CY)%20%5C%5C%0A&amp;=%20H(Y)%20-%20H(Y%7CX)%20%5C%5C%0A&amp;=%20H(X)%20+%20H(Y)%20-%20H(X,Y)%0A%5Cend%7Baligned%7D%0A"></p>
</section>
</section>
<section id="information-theoretic-measures" class="level2">
<h2 class="anchored" data-anchor-id="information-theoretic-measures">Information-Theoretic Measures</h2>
<section id="kullback-leibler-divergence" class="level3">
<h3 class="anchored" data-anchor-id="kullback-leibler-divergence">1. Kullback-Leibler Divergence</h3>
<p>Definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AD_%7BKL%7D(P%5C%7CQ)%20=%20%5Csum_%7Bx%7D%20P(x)%5Clog_2%5Cfrac%7BP(x)%7D%7BQ(x)%7D%0A"></p>
<p>Properties: 1. Non-negativity: <img src="https://latex.codecogs.com/png.latex?D_%7BKL%7D(P%5C%7CQ)%20%5Cgeq%200"> 2. <img src="https://latex.codecogs.com/png.latex?D_%7BKL%7D(P%5C%7CQ)%20=%200"> iff P = Q 3. Asymmetry: <img src="https://latex.codecogs.com/png.latex?D_%7BKL%7D(P%5C%7CQ)%20%5Cneq%20D_%7BKL%7D(Q%5C%7CP)"></p>
</section>
<section id="jensen-shannon-divergence" class="level3">
<h3 class="anchored" data-anchor-id="jensen-shannon-divergence">2. Jensen-Shannon Divergence</h3>
<p>Symmetric measure:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AJSD(P%5C%7CQ)%20=%20%5Cfrac%7B1%7D%7B2%7DD_%7BKL%7D(P%5C%7CM)%20+%20%5Cfrac%7B1%7D%7B2%7DD_%7BKL%7D(Q%5C%7CM)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?M%20=%20%5Cfrac%7B1%7D%7B2%7D(P%20+%20Q)"></p>
<p>Properties: 1. Symmetry: <img src="https://latex.codecogs.com/png.latex?JSD(P%5C%7CQ)%20=%20JSD(Q%5C%7CP)"> 2. Bounded: <img src="https://latex.codecogs.com/png.latex?0%20%5Cleq%20JSD(P%5C%7CQ)%20%5Cleq%201"> 3. Square root is a metric</p>
</section>
<section id="cross-entropy" class="level3">
<h3 class="anchored" data-anchor-id="cross-entropy">3. Cross-Entropy</h3>
<p>Definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AH(P,Q)%20=%20-%5Csum_%7Bx%7D%20P(x)%5Clog%20Q(x)%0A"></p>
<p>Relation to KL divergence:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AH(P,Q)%20=%20H(P)%20+%20D_%7BKL%7D(P%5C%7CQ)%0A"></p>
</section>
</section>
<section id="applications-in-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="applications-in-machine-learning">Applications in Machine Learning</h2>
<section id="maximum-entropy-principle" class="level3">
<h3 class="anchored" data-anchor-id="maximum-entropy-principle">1. Maximum Entropy Principle</h3>
<p>Objective function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmax_%7Bp%7D%20H(p)%20%5Ctext%7B%20subject%20to%20%7D%20%5Cmathbb%7BE%7D_p%5Bf_i%5D%20=%20%5Cmu_i%0A"></p>
<p>Solution form:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap%5E*(x)%20=%20%5Cfrac%7B1%7D%7BZ(%5Clambda)%7D%5Cexp%5Cleft(%5Csum_i%20%5Clambda_i%20f_i(x)%5Cright)%0A"></p>
</section>
<section id="information-bottleneck" class="level3">
<h3 class="anchored" data-anchor-id="information-bottleneck">2. Information Bottleneck</h3>
<p>Objective:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7Bp(t%7Cx)%7D%20I(X;T)%20-%20%5Cbeta%20I(T;Y)%0A"></p>
<p>Solution characterization:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(t%7Cx)%20=%20%5Cfrac%7Bp(t)%7D%7BZ(x,%5Cbeta)%7D%5Cexp%5Cleft(-%5Cbeta%20D_%7BKL%7D(p(y%7Cx)%5C%7Cp(y%7Ct))%5Cright)%0A"></p>
</section>
<section id="mutual-information-neural-estimation" class="level3">
<h3 class="anchored" data-anchor-id="mutual-information-neural-estimation">3. Mutual Information Neural Estimation</h3>
<p>MINE estimator:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AI_%5Ctheta(X,Y)%20=%20%5Csup_%7B%5Ctheta%20%5Cin%20%5CTheta%7D%20%5Cmathbb%7BE%7D_%7BP_%7BXY%7D%7D%5BT_%5Ctheta%5D%20-%20%5Clog%5Cmathbb%7BE%7D_%7BP_X%20%5Cotimes%20P_Y%7D%5Be%5E%7BT_%5Ctheta%7D%5D%0A"></p>
</section>
</section>
<section id="information-theory-in-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="information-theory-in-deep-learning">Information Theory in Deep Learning</h2>
<section id="information-plane-analysis" class="level3">
<h3 class="anchored" data-anchor-id="information-plane-analysis">1. Information Plane Analysis</h3>
<p>Layer-wise information:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AI(X;T_l)%20&amp;=%20%5Ctext%7BInformation%20about%20input%7D%20%5C%5C%0AI(T_l;Y)%20&amp;=%20%5Ctext%7BInformation%20about%20output%7D%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="variational-information-maximization" class="level3">
<h3 class="anchored" data-anchor-id="variational-information-maximization">2. Variational Information Maximization</h3>
<p>Lower bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AI(X;Y)%20%5Cgeq%20%5Cmathbb%7BE%7D_%7Bp(x,y)%7D%5B%5Clog%20q_%5Ctheta(y%7Cx)%5D%20+%20h(Y)%0A"></p>
</section>
<section id="information-dropout" class="level3">
<h3 class="anchored" data-anchor-id="information-dropout">3. Information Dropout</h3>
<p>Dropout probability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap(z%7Cx)%20=%20%5Cmathcal%7BN%7D(z%7C%5Cmu(x),%20%5Calpha(x)%5Csigma%5E2)%0A"></p>
<p>Cost function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D%20=%20%5Cmathbb%7BE%7D%5B%5Clog%20p(y%7Cz)%5D%20-%20%5Cbeta%20D_%7BKL%7D(p(z%7Cx)%5C%7Cr(z))%0A"></p>
</section>
</section>
<section id="advanced-applications" class="level2">
<h2 class="anchored" data-anchor-id="advanced-applications">Advanced Applications</h2>
<section id="generative-models" class="level3">
<h3 class="anchored" data-anchor-id="generative-models">1. Generative Models</h3>
<p>VAE ELBO:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D%20=%20%5Cmathbb%7BE%7D_%7Bq_%5Cphi(z%7Cx)%7D%5B%5Clog%20p_%5Ctheta(x%7Cz)%5D%20-%20D_%7BKL%7D(q_%5Cphi(z%7Cx)%5C%7Cp(z))%0A"></p>
<p>GAN objective:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_G%20%5Cmax_D%20V(D,G)%20=%20%5Cmathbb%7BE%7D_%7Bx%5Csim%20p_%7Bdata%7D%7D%5B%5Clog%20D(x)%5D%20+%20%5Cmathbb%7BE%7D_%7Bz%5Csim%20p_z%7D%5B%5Clog(1-D(G(z)))%5D%0A"></p>
</section>
<section id="representation-learning" class="level3">
<h3 class="anchored" data-anchor-id="representation-learning">2. Representation Learning</h3>
<p>InfoNCE loss:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D_N%20=%20-%5Cmathbb%7BE%7D%5Cleft%5B%5Clog%20%5Cfrac%7Be%5E%7Bf(x,y)/%5Ctau%7D%7D%7B%5Csum_%7Bi=1%7D%5EN%20e%5E%7Bf(x,y_i)/%5Ctau%7D%7D%5Cright%5D%0A"></p>
<p>Contrastive predictive coding:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D_%7BCPC%7D%20=%20-%5Csum_%7Bk=1%7D%5EK%20%5Cmathbb%7BE%7D%5Cleft%5B%5Clog%20%5Cfrac%7Be%5E%7Bf_k(c_t,x_%7Bt+k%7D)%7D%7D%7Be%5E%7Bf_k(c_t,x_%7Bt+k%7D)%7D%20+%20%5Csum_%7Bj=1%7D%5EN%20e%5E%7Bf_k(c_t,x_j)%7D%7D%5Cright%5D%0A"></p>
</section>
<section id="model-compression" class="level3">
<h3 class="anchored" data-anchor-id="model-compression">3. Model Compression</h3>
<p>Information bottleneck objective:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7Bp(t%7Cx)%7D%20I(X;T)%20%5Ctext%7B%20subject%20to%20%7D%20I(T;Y)%20%5Cgeq%20I_0%0A"></p>
<p>Rate-distortion theory:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR(D)%20=%20%5Cmin_%7Bp(t%7Cx):%20%5Cmathbb%7BE%7D%5Bd(X,T)%5D%20%5Cleq%20D%7D%20I(X;T)%0A"></p>
</section>
</section>
<section id="theoretical-insights" class="level2">
<h2 class="anchored" data-anchor-id="theoretical-insights">Theoretical Insights</h2>
<section id="learning-dynamics" class="level3">
<h3 class="anchored" data-anchor-id="learning-dynamics">1. Learning Dynamics</h3>
<p>Information dynamics:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cfrac%7Bd%7D%7Bdt%7DI(X;T_t)%20=%20%5Cmathbb%7BE%7D%5Cleft%5B%5Ctext%7Btr%7D%5Cleft(%5Cfrac%7B%5Cpartial%5E2%20I%7D%7B%5Cpartial%20T%5E2%7D%5Cfrac%7BdT%7D%7Bdt%7D%5Cfrac%7BdT%7D%7Bdt%7D%5ET%5Cright)%5Cright%5D%0A"></p>
</section>
<section id="generalization-bounds" class="level3">
<h3 class="anchored" data-anchor-id="generalization-bounds">2. Generalization Bounds</h3>
<p>PAC-Bayes bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bgen-error%7D%20%5Cleq%20%5Cfrac%7BD_%7BKL%7D(Q%5C%7CP)%20+%20%5Clog%5Cfrac%7B2%5Csqrt%7Bn%7D%7D%7B%5Cdelta%7D%7D%7B2n%7D%0A"></p>
</section>
<section id="optimization-perspective" class="level3">
<h3 class="anchored" data-anchor-id="optimization-perspective">3. Optimization Perspective</h3>
<p>Natural gradient:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cdot%7B%5Ctheta%7D%20=%20F%5E%7B-1%7D(%5Ctheta)%5Cnabla_%5Ctheta%20%5Cmathcal%7BL%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?F(%5Ctheta)"> is the Fisher information matrix</p>
</section>
</section>
<section id="implementation-considerations" class="level2">
<h2 class="anchored" data-anchor-id="implementation-considerations">Implementation Considerations</h2>
<section id="numerical-stability" class="level3">
<h3 class="anchored" data-anchor-id="numerical-stability">1. Numerical Stability</h3>
<p>Log-sum-exp trick:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clog%5Csum_i%20e%5E%7Bx_i%7D%20=%20a%20+%20%5Clog%5Csum_i%20e%5E%7Bx_i-a%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?a%20=%20%5Cmax_i%20x_i"></p>
</section>
<section id="estimation-methods" class="level3">
<h3 class="anchored" data-anchor-id="estimation-methods">2. Estimation Methods</h3>
<p>KDE entropy estimator:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BH%7D(X)%20=%20-%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5En%20%5Clog%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bj=1%7D%5En%20K_h(x_i-x_j)%0A"></p>
</section>
<section id="batch-processing" class="level3">
<h3 class="anchored" data-anchor-id="batch-processing">3. Batch Processing</h3>
<p>Mini-batch mutual information:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BI%7D(X;Y)%20=%20%5Cfrac%7B1%7D%7BB%7D%5Csum_%7Bi=1%7D%5EB%20%5Clog%5Cfrac%7Bp(x_i,y_i)%7D%7B%5Chat%7Bp%7D(x_i)%5Chat%7Bp%7D(y_i)%7D%0A"></p>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="model-design" class="level3">
<h3 class="anchored" data-anchor-id="model-design">1. Model Design</h3>
<ol type="1">
<li>Information Flow:
<ul>
<li>Monitor layer-wise information</li>
<li>Balance compression and preservation</li>
<li>Use information bottlenecks</li>
</ul></li>
<li>Architecture Choice:
<ul>
<li>Consider mutual information</li>
<li>Information capacity</li>
<li>Bottleneck dimensions</li>
</ul></li>
<li>Regularization:
<ul>
<li>Information dropout</li>
<li>Mutual information constraints</li>
<li>Entropy regularization</li>
</ul></li>
</ol>
</section>
<section id="training-strategy" class="level3">
<h3 class="anchored" data-anchor-id="training-strategy">2. Training Strategy</h3>
<ol type="1">
<li>Optimization:
<ul>
<li>Natural gradients</li>
<li>Information-based learning rates</li>
<li>Adaptive methods</li>
</ul></li>
<li>Monitoring:
<ul>
<li>Information plane dynamics</li>
<li>Compression metrics</li>
<li>Mutual information estimates</li>
</ul></li>
<li>Validation:
<ul>
<li>Cross-entropy</li>
<li>KL divergence</li>
<li>Information efficiency</li>
</ul></li>
</ol>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Theory:
<ul>
<li>“Elements of Information Theory” by Cover and Thomas</li>
<li>“Information Theory, Inference, and Learning Algorithms” by MacKay</li>
<li>“Deep Learning and the Information Bottleneck Principle” by Tishby and Zaslavsky</li>
</ul></li>
<li>Methods:
<ul>
<li>“Deep Learning with Information Theoretic Learning” by Principe</li>
<li>“Information Theory and Statistics” by Csiszár and Shields</li>
<li>“Information Theory and Machine Learning” by Amari</li>
</ul></li>
<li>Applications:
<ul>
<li>“Deep Learning” by Goodfellow et al.</li>
<li>“Pattern Recognition and Machine Learning” by Bishop</li>
<li>“Machine Learning: A Probabilistic Perspective” by Murphy</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>information-theory</category>
  <category>mathematics</category>
  <category>theory</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/information-theory-ml/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/information-theory-ml/information_theory.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Machine Learning: From Theory to Practice</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/ml-fundamentals-beginners/</link>
  <description><![CDATA[ 





<p>Have you ever wondered how Spotify seems to read your mind when recommending new songs? Or how your smartphone’s camera instantly knows when you’re smiling? These seemingly magical capabilities are powered by machine learning, and in this post, we’ll not only understand how they work but also build our own machine learning models from scratch.</p>
<section id="the-art-and-science-of-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="the-art-and-science-of-machine-learning">The Art and Science of Machine Learning</h2>
<p>Think about how you learned to recognize cats and dogs as a child. Nobody gave you a mathematical formula for “cat-ness” or “dog-ness.” Instead, you learned from examples. Machine learning works the same way - it’s about teaching computers to learn from experience rather than following explicit rules.</p>
<p>Let’s see this in action with a simple example:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.linear_model <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> LinearRegression</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a simple dataset about house prices</span></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Imagine: house size (sq ft) vs price ($)</span></span>
<span id="cb1-9">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb1-10">house_sizes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># House sizes from 1000 to 5000 sq ft</span></span>
<span id="cb1-11">house_prices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> house_sizes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Price formula with some noise</span></span>
<span id="cb1-12"></span>
<span id="cb1-13">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb1-14">plt.scatter(house_sizes, house_prices, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>)</span>
<span id="cb1-15">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'House Size (sq ft)'</span>)</span>
<span id="cb1-16">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Price ($K)'</span>)</span>
<span id="cb1-17">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'House Prices vs Size'</span>)</span>
<span id="cb1-18">plt.show()</span></code></pre></div>
<p>Just like you might intuitively understand that larger houses generally cost more, our machine learning model will learn this relationship from data. But unlike humans, it will learn the exact mathematical relationship.</p>
</section>
<section id="three-ways-machines-learn" class="level2">
<h2 class="anchored" data-anchor-id="three-ways-machines-learn">Three Ways Machines Learn</h2>
<section id="supervised-learning-learning-from-examples" class="level3">
<h3 class="anchored" data-anchor-id="supervised-learning-learning-from-examples">1. Supervised Learning: Learning from Examples</h3>
<p>Imagine teaching a child to identify fruits. You show them an apple and say “apple,” a banana and say “banana,” and so on. This is supervised learning - we provide both the question (input) and answer (output). Let’s build a simple supervised learning model:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare our housing data for machine learning</span></span>
<span id="cb2-2">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> house_sizes.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Features (input)</span></span>
<span id="cb2-3">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> house_prices  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Target (output)</span></span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split data into training and testing sets</span></span>
<span id="cb2-6">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb2-7"></span>
<span id="cb2-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create and train our model</span></span>
<span id="cb2-9">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> LinearRegression()</span>
<span id="cb2-10">model.fit(X_train, y_train)</span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make predictions</span></span>
<span id="cb2-13">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(X_test)</span>
<span id="cb2-14"></span>
<span id="cb2-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize results</span></span>
<span id="cb2-16">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb2-17">plt.scatter(X_train, y_train, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training Data'</span>)</span>
<span id="cb2-18">plt.plot(X_test, y_pred, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Model Predictions'</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb2-19">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'House Size (sq ft)'</span>)</span>
<span id="cb2-20">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Price ($K)'</span>)</span>
<span id="cb2-21">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'House Price Prediction Model'</span>)</span>
<span id="cb2-22">plt.legend()</span>
<span id="cb2-23">plt.show()</span>
<span id="cb2-24"></span>
<span id="cb2-25"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Model's prediction for a 2500 sq ft house: $</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>predict([[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2500</span>]])[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:,.2f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">K"</span>)</span></code></pre></div>
</section>
<section id="unsupervised-learning-finding-hidden-patterns" class="level3">
<h3 class="anchored" data-anchor-id="unsupervised-learning-finding-hidden-patterns">2. Unsupervised Learning: Finding Hidden Patterns</h3>
<p>Sometimes we want machines to find patterns on their own. This is like organizing your closet - you group similar items together without being told how to categorize them.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.cluster <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> KMeans</span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create data about customer shopping behavior</span></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Features: money spent vs number of items bought</span></span>
<span id="cb3-5">customer_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">300</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate random customer data</span></span>
<span id="cb3-6">customer_data[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># High spenders</span></span>
<span id="cb3-7">customer_data[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Budget shoppers</span></span>
<span id="cb3-8"></span>
<span id="cb3-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Apply clustering</span></span>
<span id="cb3-10">kmeans <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> KMeans(n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb3-11">clusters <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kmeans.fit_predict(customer_data)</span>
<span id="cb3-12"></span>
<span id="cb3-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize customer segments</span></span>
<span id="cb3-14">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb3-15">plt.scatter(customer_data[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], customer_data[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>clusters, cmap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'viridis'</span>)</span>
<span id="cb3-16">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Customer Segments Based on Shopping Behavior'</span>)</span>
<span id="cb3-17">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Money Spent'</span>)</span>
<span id="cb3-18">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Number of Items'</span>)</span>
<span id="cb3-19">plt.colorbar(label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Customer Segment'</span>)</span>
<span id="cb3-20">plt.show()</span></code></pre></div>
</section>
<section id="reinforcement-learning-learning-through-trial-and-error" class="level3">
<h3 class="anchored" data-anchor-id="reinforcement-learning-learning-through-trial-and-error">3. Reinforcement Learning: Learning through Trial and Error</h3>
<p>Think of teaching a dog new tricks. You reward good behavior and discourage bad behavior. Similarly, reinforcement learning is about learning optimal actions through rewards and penalties.</p>
</section>
</section>
<section id="the-machine-learning-pipeline-a-real-world-example" class="level2">
<h2 class="anchored" data-anchor-id="the-machine-learning-pipeline-a-real-world-example">The Machine Learning Pipeline: A Real-World Example</h2>
<p>Let’s walk through a complete machine learning project using real-world data:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.preprocessing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StandardScaler</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.ensemble <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomForestClassifier</span>
<span id="cb4-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> accuracy_score, classification_report</span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load and prepare data</span></span>
<span id="cb4-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> prepare_data(data):</span>
<span id="cb4-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Prepare data for modeling"""</span></span>
<span id="cb4-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Handle missing values</span></span>
<span id="cb4-9">    data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.fillna(data.mean())</span>
<span id="cb4-10">    </span>
<span id="cb4-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Scale features</span></span>
<span id="cb4-12">    scaler <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StandardScaler()</span>
<span id="cb4-13">    scaled_features <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scaler.fit_transform(data)</span>
<span id="cb4-14">    </span>
<span id="cb4-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> pd.DataFrame(scaled_features, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data.columns)</span>
<span id="cb4-16"></span>
<span id="cb4-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create example dataset</span></span>
<span id="cb4-18">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({</span>
<span id="cb4-19">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'age'</span>: np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">35</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>),</span>
<span id="cb4-20">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'income'</span>: np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>),</span>
<span id="cb4-21">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'credit_score'</span>: np.random.normal(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">700</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>)</span>
<span id="cb4-22">})</span>
<span id="cb4-23"></span>
<span id="cb4-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add target variable (loan approval)</span></span>
<span id="cb4-25">data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loan_approved'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'credit_score'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">700</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'income'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">45000</span>)</span>
<span id="cb4-26"></span>
<span id="cb4-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Prepare features and target</span></span>
<span id="cb4-28">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loan_approved'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-29">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'loan_approved'</span>]</span>
<span id="cb4-30"></span>
<span id="cb4-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Split and prepare data</span></span>
<span id="cb4-32">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb4-33">X_train_prepared <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prepare_data(X_train)</span>
<span id="cb4-34">X_test_prepared <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prepare_data(X_test)</span>
<span id="cb4-35"></span>
<span id="cb4-36"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train model</span></span>
<span id="cb4-37">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomForestClassifier(n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb4-38">model.fit(X_train_prepared, y_train)</span>
<span id="cb4-39"></span>
<span id="cb4-40"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make predictions</span></span>
<span id="cb4-41">y_pred <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(X_test_prepared)</span>
<span id="cb4-42"></span>
<span id="cb4-43"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Evaluate model</span></span>
<span id="cb4-44"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Model Performance:"</span>)</span>
<span id="cb4-45"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(classification_report(y_test, y_pred))</span>
<span id="cb4-46"></span>
<span id="cb4-47"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Feature importance</span></span>
<span id="cb4-48">feature_importance <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame({</span>
<span id="cb4-49">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'feature'</span>: X.columns,</span>
<span id="cb4-50">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'importance'</span>: model.feature_importances_</span>
<span id="cb4-51">}).sort_values(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'importance'</span>, ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb4-52"></span>
<span id="cb4-53">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb4-54">plt.bar(feature_importance[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'feature'</span>], feature_importance[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'importance'</span>])</span>
<span id="cb4-55">plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Feature Importance in Loan Approval'</span>)</span>
<span id="cb4-56">plt.xticks(rotation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">45</span>)</span>
<span id="cb4-57">plt.show()</span></code></pre></div>
</section>
<section id="common-challenges-and-solutions" class="level2">
<h2 class="anchored" data-anchor-id="common-challenges-and-solutions">Common Challenges and Solutions</h2>
<section id="overfitting-when-your-model-memorizes-instead-of-learning" class="level3">
<h3 class="anchored" data-anchor-id="overfitting-when-your-model-memorizes-instead-of-learning">1. Overfitting: When Your Model Memorizes Instead of Learning</h3>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> learning_curve</span>
<span id="cb5-2"></span>
<span id="cb5-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> plot_learning_curves(model, X, y):</span>
<span id="cb5-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Visualize model learning process"""</span></span>
<span id="cb5-5">    train_sizes, train_scores, val_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> learning_curve(</span>
<span id="cb5-6">        model, X, y, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, n_jobs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, </span>
<span id="cb5-7">        train_sizes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.linspace(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>))</span>
<span id="cb5-8">    </span>
<span id="cb5-9">    plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb5-10">    plt.plot(train_sizes, np.mean(train_scores, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training Score'</span>)</span>
<span id="cb5-11">    plt.plot(train_sizes, np.mean(val_scores, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Validation Score'</span>)</span>
<span id="cb5-12">    plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Training Examples'</span>)</span>
<span id="cb5-13">    plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Score'</span>)</span>
<span id="cb5-14">    plt.title(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Learning Curves: Diagnosing Overfitting'</span>)</span>
<span id="cb5-15">    plt.legend()</span>
<span id="cb5-16">    plt.grid(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb5-17">    plt.show()</span>
<span id="cb5-18"></span>
<span id="cb5-19">plot_learning_curves(RandomForestClassifier(), X_train_prepared, y_train)</span></code></pre></div>
</section>
</section>
<section id="best-practices-and-tips" class="level2">
<h2 class="anchored" data-anchor-id="best-practices-and-tips">Best Practices and Tips</h2>
<ol type="1">
<li>Start Simple
<ul>
<li>Begin with basic models</li>
<li>Understand your data thoroughly</li>
<li>Establish baseline performance</li>
</ul></li>
<li>Validate Properly
<ul>
<li>Use cross-validation</li>
<li>Test on unseen data</li>
<li>Monitor multiple metrics</li>
</ul></li>
<li>Iterate and Improve
<ul>
<li>Try different models</li>
<li>Tune hyperparameters</li>
<li>Engineer better features</li>
</ul></li>
</ol>
</section>
<section id="next-steps-in-your-ml-journey" class="level2">
<h2 class="anchored" data-anchor-id="next-steps-in-your-ml-journey">Next Steps in Your ML Journey</h2>
<p>The examples we’ve covered are just the beginning. Here are some directions to explore:</p>
<ol type="1">
<li>Advanced Techniques
<ul>
<li>Deep Learning</li>
<li>Natural Language Processing</li>
<li>Computer Vision</li>
</ul></li>
<li>Real-World Projects
<ul>
<li>Kaggle Competitions</li>
<li>Personal Projects</li>
<li>Open Source Contributions</li>
</ul></li>
<li>Best Practices
<ul>
<li>Model Deployment</li>
<li>MLOps</li>
<li>Ethical AI</li>
</ul></li>
</ol>
<p>Remember, machine learning is both an art and a science. The science comes from understanding the mathematical foundations, while the art lies in making the right choices about data preparation, feature engineering, and model selection. Keep experimenting, keep learning, and most importantly, enjoy the process of teaching machines to learn!</p>
</section>
<section id="resources-for-further-learning" class="level2">
<h2 class="anchored" data-anchor-id="resources-for-further-learning">Resources for Further Learning</h2>
<ol type="1">
<li>Online Courses
<ul>
<li>Fast.ai</li>
<li>Coursera Machine Learning</li>
<li>Google’s ML Crash Course</li>
</ul></li>
<li>Books
<ul>
<li>“Hands-On Machine Learning” by Aurélien Géron</li>
<li>“Python Machine Learning” by Sebastian Raschka</li>
<li>“Introduction to Statistical Learning” by James et al.</li>
</ul></li>
<li>Practice Platforms
<ul>
<li>Kaggle</li>
<li>Google Colab</li>
<li>GitHub Projects</li>
</ul></li>
</ol>
<p>The journey into machine learning is exciting and rewarding. Start with these fundamentals, practice regularly, and gradually tackle more complex problems. The field is constantly evolving, offering endless opportunities to learn and create amazing things!</p>



</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>fundamentals</category>
  <category>python</category>
  <category>hands-on</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/ml-fundamentals-beginners/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/ml-fundamentals-beginners/ml_fundamentals.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>ML Fundamentals: Understanding the Basics</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/ml-fundamentals/</link>
  <description><![CDATA[ 





<section id="understanding-machine-learning-fundamentals" class="level1">
<h1>Understanding Machine Learning Fundamentals</h1>
<p>Machine learning (ML) is a transformative field that enables computers to learn from data without being explicitly programmed. Before diving into specific algorithms or frameworks, it’s crucial to understand the fundamental concepts that form the foundation of machine learning.</p>
<section id="what-is-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="what-is-machine-learning">What is Machine Learning?</h2>
<p>Machine learning is a subset of artificial intelligence that focuses on developing systems that can learn and improve from experience. Instead of following explicit instructions, ML systems identify patterns in data to make decisions or predictions.</p>
<section id="key-characteristics-of-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="key-characteristics-of-machine-learning">Key Characteristics of Machine Learning:</h3>
<ol type="1">
<li><strong>Data-Driven</strong>: ML systems learn from examples rather than following predefined rules</li>
<li><strong>Pattern Recognition</strong>: They identify patterns and relationships in data</li>
<li><strong>Automation</strong>: They can automatically improve with more experience/data</li>
<li><strong>Generalization</strong>: They can handle new, unseen data based on learned patterns</li>
</ol>
</section>
</section>
<section id="types-of-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="types-of-machine-learning">Types of Machine Learning</h2>
<section id="supervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="supervised-learning">1. Supervised Learning</h3>
<ul>
<li>Learning from labeled data</li>
<li>Examples: Classification, Regression</li>
<li>Use cases: Spam detection, Price prediction, Image recognition</li>
</ul>
</section>
<section id="unsupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="unsupervised-learning">2. Unsupervised Learning</h3>
<ul>
<li>Learning from unlabeled data</li>
<li>Examples: Clustering, Dimensionality Reduction</li>
<li>Use cases: Customer segmentation, Feature learning</li>
</ul>
</section>
<section id="reinforcement-learning" class="level3">
<h3 class="anchored" data-anchor-id="reinforcement-learning">3. Reinforcement Learning</h3>
<ul>
<li>Learning through interaction with an environment</li>
<li>Examples: Game playing, Robot navigation</li>
<li>Use cases: Autonomous systems, Game AI</li>
</ul>
</section>
</section>
<section id="the-machine-learning-workflow" class="level2">
<h2 class="anchored" data-anchor-id="the-machine-learning-workflow">The Machine Learning Workflow</h2>
<p>Understanding the ML workflow is crucial for successful implementation:</p>
<ol type="1">
<li><strong>Problem Definition</strong>
<ul>
<li>Define objectives</li>
<li>Identify success metrics</li>
<li>Understand constraints</li>
</ul></li>
<li><strong>Data Collection</strong>
<ul>
<li>Gather relevant data</li>
<li>Ensure data quality</li>
<li>Consider data privacy and ethics</li>
</ul></li>
<li><strong>Data Preprocessing</strong>
<ul>
<li>Clean the data</li>
<li>Handle missing values</li>
<li>Format data appropriately</li>
</ul></li>
<li><strong>Feature Engineering</strong>
<ul>
<li>Select relevant features</li>
<li>Create new features</li>
<li>Transform existing features</li>
</ul></li>
<li><strong>Model Selection</strong>
<ul>
<li>Choose appropriate algorithms</li>
<li>Consider model complexity</li>
<li>Balance bias and variance</li>
</ul></li>
<li><strong>Model Training</strong>
<ul>
<li>Split data into training/validation sets</li>
<li>Train the model</li>
<li>Tune hyperparameters</li>
</ul></li>
<li><strong>Model Evaluation</strong>
<ul>
<li>Assess performance</li>
<li>Validate on test data</li>
<li>Consider business metrics</li>
</ul></li>
<li><strong>Deployment</strong>
<ul>
<li>Integrate with systems</li>
<li>Monitor performance</li>
<li>Maintain and update</li>
</ul></li>
</ol>
</section>
<section id="essential-terminology" class="level2">
<h2 class="anchored" data-anchor-id="essential-terminology">Essential Terminology</h2>
<section id="model-components" class="level3">
<h3 class="anchored" data-anchor-id="model-components">Model Components</h3>
<ul>
<li><strong>Features</strong>: Input variables used for prediction</li>
<li><strong>Labels</strong>: Target variables we’re trying to predict</li>
<li><strong>Parameters</strong>: Values learned during training</li>
<li><strong>Hyperparameters</strong>: Configuration values set before training</li>
</ul>
</section>
<section id="model-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation">Model Evaluation</h3>
<ul>
<li><strong>Bias</strong>: Model’s tendency to consistently miss the true relationship</li>
<li><strong>Variance</strong>: Model’s sensitivity to fluctuations in the training data</li>
<li><strong>Overfitting</strong>: Model learns noise in training data</li>
<li><strong>Underfitting</strong>: Model fails to capture underlying patterns</li>
</ul>
</section>
<section id="performance-metrics" class="level3">
<h3 class="anchored" data-anchor-id="performance-metrics">Performance Metrics</h3>
<ul>
<li><strong>Accuracy</strong>: Proportion of correct predictions</li>
<li><strong>Precision</strong>: Accuracy of positive predictions</li>
<li><strong>Recall</strong>: Ability to find all positive instances</li>
<li><strong>F1 Score</strong>: Harmonic mean of precision and recall</li>
</ul>
</section>
</section>
<section id="common-challenges-in-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="common-challenges-in-machine-learning">Common Challenges in Machine Learning</h2>
<ol type="1">
<li><strong>Data Quality Issues</strong>
<ul>
<li>Missing values</li>
<li>Noisy data</li>
<li>Inconsistent formatting</li>
</ul></li>
<li><strong>Feature Selection</strong>
<ul>
<li>Identifying relevant features</li>
<li>Handling high dimensionality</li>
<li>Creating meaningful features</li>
</ul></li>
<li><strong>Model Selection</strong>
<ul>
<li>Choosing appropriate algorithms</li>
<li>Balancing complexity and performance</li>
<li>Handling computational constraints</li>
</ul></li>
<li><strong>Overfitting and Underfitting</strong>
<ul>
<li>Finding the right model complexity</li>
<li>Gathering sufficient training data</li>
<li>Using appropriate regularization</li>
</ul></li>
</ol>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<ol type="1">
<li><strong>Start Simple</strong>
<ul>
<li>Begin with basic models</li>
<li>Establish baselines</li>
<li>Gradually increase complexity</li>
</ul></li>
<li><strong>Cross-Validation</strong>
<ul>
<li>Use multiple data splits</li>
<li>Validate model stability</li>
<li>Ensure generalization</li>
</ul></li>
<li><strong>Feature Engineering</strong>
<ul>
<li>Create meaningful features</li>
<li>Remove irrelevant features</li>
<li>Handle categorical variables appropriately</li>
</ul></li>
<li><strong>Model Evaluation</strong>
<ul>
<li>Use appropriate metrics</li>
<li>Consider business impact</li>
<li>Test on unseen data</li>
</ul></li>
</ol>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>Understanding these fundamentals is crucial before diving into specific algorithms or frameworks. In the next posts, we’ll explore:</p>
<ol type="1">
<li>Data Understanding and Preprocessing</li>
<li>Feature Engineering and Selection</li>
<li>Model Selection and Evaluation</li>
<li>Advanced Topics and Deep Learning</li>
</ol>
<p>Stay tuned for more detailed explorations of each topic!</p>
</section>
<section id="additional-resources" class="level2">
<h2 class="anchored" data-anchor-id="additional-resources">Additional Resources</h2>
<ol type="1">
<li>Books:
<ul>
<li>“Introduction to Machine Learning with Python” by Andreas Müller &amp; Sarah Guido</li>
<li>“The Hundred-Page Machine Learning Book” by Andriy Burkov</li>
</ul></li>
<li>Online Courses:
<ul>
<li>Andrew Ng’s Machine Learning Course on Coursera</li>
<li>Fast.ai’s Practical Deep Learning Course</li>
</ul></li>
<li>Websites:
<ul>
<li>Scikit-learn Documentation</li>
<li>Towards Data Science</li>
<li>Machine Learning Mastery</li>
</ul></li>
</ol>
<p>Remember: Building a strong foundation in these fundamentals is crucial for success in machine learning. Take time to understand these concepts thoroughly before moving on to more advanced topics.</p>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>fundamentals</category>
  <category>theory</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/ml-fundamentals/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/ml-fundamentals/ml_basics.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Machine Learning in Everyday Life: A Practical Guide</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/ml-in-everyday-life/</link>
  <description><![CDATA[ 





<section id="machine-learning-in-your-daily-life" class="level1">
<h1>Machine Learning in Your Daily Life</h1>
<p>You might not realize it, but machine learning is already a big part of your daily routine. From the moment you wake up until you go to bed, ML algorithms are working behind the scenes to make your life easier and more convenient.</p>
<section id="morning-routine-with-ml" class="level2">
<h2 class="anchored" data-anchor-id="morning-routine-with-ml">Morning Routine with ML</h2>
<section id="smart-home-devices" class="level3">
<h3 class="anchored" data-anchor-id="smart-home-devices">1. Smart Home Devices</h3>
<ul>
<li><strong>Smart Thermostats</strong>
<ul>
<li>Learn your temperature preferences</li>
<li>Adjust based on time of day</li>
<li>Save energy by predicting when you’re away</li>
<li>Example: Nest Learning Thermostat</li>
</ul></li>
<li><strong>Voice Assistants</strong>
<ul>
<li>Recognize your voice commands</li>
<li>Learn your accent and speaking patterns</li>
<li>Improve understanding over time</li>
<li>Examples: Alexa, Google Assistant, Siri</li>
</ul></li>
</ul>
</section>
<section id="smartphone-features" class="level3">
<h3 class="anchored" data-anchor-id="smartphone-features">2. Smartphone Features</h3>
<ul>
<li><strong>Face Recognition</strong>
<ul>
<li>Unlocks your phone securely</li>
<li>Adapts to changes in appearance</li>
<li>Works in different lighting conditions</li>
</ul></li>
<li><strong>Keyboard Predictions</strong>
<ul>
<li>Learns your typing patterns</li>
<li>Suggests words based on context</li>
<li>Adapts to your vocabulary</li>
</ul></li>
</ul>
</section>
</section>
<section id="during-your-commute" class="level2">
<h2 class="anchored" data-anchor-id="during-your-commute">During Your Commute</h2>
<section id="navigation-apps" class="level3">
<h3 class="anchored" data-anchor-id="navigation-apps">1. Navigation Apps</h3>
<ul>
<li><strong>Traffic Prediction</strong>
<ul>
<li>Analyzes historical traffic patterns</li>
<li>Predicts delays in real-time</li>
<li>Suggests faster routes</li>
<li>Example: Google Maps, Waze</li>
</ul></li>
</ul>
</section>
<section id="ride-sharing-services" class="level3">
<h3 class="anchored" data-anchor-id="ride-sharing-services">2. Ride-Sharing Services</h3>
<ul>
<li><strong>Price Optimization</strong>
<ul>
<li>Adjusts prices based on demand</li>
<li>Predicts busy periods</li>
<li>Matches drivers efficiently</li>
<li>Examples: Uber, Lyft</li>
</ul></li>
</ul>
</section>
</section>
<section id="at-work" class="level2">
<h2 class="anchored" data-anchor-id="at-work">At Work</h2>
<section id="email-management" class="level3">
<h3 class="anchored" data-anchor-id="email-management">1. Email Management</h3>
<ul>
<li><strong>Spam Filtering</strong>
<ul>
<li>Identifies unwanted emails</li>
<li>Learns from your actions</li>
<li>Adapts to new spam patterns</li>
</ul></li>
<li><strong>Smart Categorization</strong>
<ul>
<li>Sorts emails automatically</li>
<li>Prioritizes important messages</li>
<li>Suggests quick responses</li>
</ul></li>
</ul>
</section>
<section id="productivity-tools" class="level3">
<h3 class="anchored" data-anchor-id="productivity-tools">2. Productivity Tools</h3>
<ul>
<li><strong>Document Search</strong>
<ul>
<li>Understands natural language queries</li>
<li>Finds relevant files quickly</li>
<li>Improves with usage</li>
</ul></li>
<li><strong>Meeting Scheduling</strong>
<ul>
<li>Learns preferred meeting times</li>
<li>Suggests optimal slots</li>
<li>Considers participants’ schedules</li>
</ul></li>
</ul>
</section>
</section>
<section id="shopping-and-entertainment" class="level2">
<h2 class="anchored" data-anchor-id="shopping-and-entertainment">Shopping and Entertainment</h2>
<section id="online-shopping" class="level3">
<h3 class="anchored" data-anchor-id="online-shopping">1. Online Shopping</h3>
<ul>
<li><strong>Product Recommendations</strong>
<ul>
<li>Based on your browsing history</li>
<li>Similar items you might like</li>
<li>Personalized deals</li>
<li>Example: Amazon’s recommendations</li>
</ul></li>
<li><strong>Price Tracking</strong>
<ul>
<li>Predicts price changes</li>
<li>Alerts for best buying times</li>
<li>Finds similar products</li>
</ul></li>
</ul>
</section>
<section id="streaming-services" class="level3">
<h3 class="anchored" data-anchor-id="streaming-services">2. Streaming Services</h3>
<ul>
<li><strong>Content Recommendations</strong>
<ul>
<li>Learns your viewing preferences</li>
<li>Suggests new shows/movies</li>
<li>Personalizes homepage</li>
<li>Examples: Netflix, Spotify</li>
</ul></li>
</ul>
</section>
<section id="social-media" class="level3">
<h3 class="anchored" data-anchor-id="social-media">3. Social Media</h3>
<ul>
<li><strong>Feed Customization</strong>
<ul>
<li>Shows relevant content</li>
<li>Learns from your interactions</li>
<li>Filters unwanted content</li>
<li>Examples: Instagram, Facebook</li>
</ul></li>
</ul>
</section>
</section>
<section id="health-and-fitness" class="level2">
<h2 class="anchored" data-anchor-id="health-and-fitness">Health and Fitness</h2>
<section id="fitness-trackers" class="level3">
<h3 class="anchored" data-anchor-id="fitness-trackers">1. Fitness Trackers</h3>
<ul>
<li><strong>Activity Recognition</strong>
<ul>
<li>Identifies exercise types</li>
<li>Counts steps accurately</li>
<li>Monitors sleep patterns</li>
</ul></li>
<li><strong>Health Insights</strong>
<ul>
<li>Predicts fitness trends</li>
<li>Suggests workout improvements</li>
<li>Personalizes goals</li>
</ul></li>
</ul>
</section>
<section id="healthcare-apps" class="level3">
<h3 class="anchored" data-anchor-id="healthcare-apps">2. Healthcare Apps</h3>
<ul>
<li><strong>Symptom Checking</strong>
<ul>
<li>Analyzes symptoms</li>
<li>Suggests possible causes</li>
<li>Recommends actions</li>
</ul></li>
<li><strong>Mental Health Support</strong>
<ul>
<li>Mood tracking</li>
<li>Personalized recommendations</li>
<li>Early warning signs</li>
</ul></li>
</ul>
</section>
</section>
<section id="financial-services" class="level2">
<h2 class="anchored" data-anchor-id="financial-services">Financial Services</h2>
<section id="banking" class="level3">
<h3 class="anchored" data-anchor-id="banking">1. Banking</h3>
<ul>
<li><strong>Fraud Detection</strong>
<ul>
<li>Spots unusual transactions</li>
<li>Prevents unauthorized use</li>
<li>Learns spending patterns</li>
</ul></li>
<li><strong>Automated Banking</strong>
<ul>
<li>Smart ATMs</li>
<li>Chatbot customer service</li>
<li>Personalized financial advice</li>
</ul></li>
</ul>
</section>
<section id="personal-finance" class="level3">
<h3 class="anchored" data-anchor-id="personal-finance">2. Personal Finance</h3>
<ul>
<li><strong>Budget Apps</strong>
<ul>
<li>Categorize expenses</li>
<li>Predict future spending</li>
<li>Suggest savings opportunities</li>
</ul></li>
</ul>
</section>
</section>
<section id="how-ml-makes-these-possible" class="level2">
<h2 class="anchored" data-anchor-id="how-ml-makes-these-possible">How ML Makes These Possible</h2>
<section id="pattern-recognition" class="level3">
<h3 class="anchored" data-anchor-id="pattern-recognition">1. Pattern Recognition</h3>
<ul>
<li>Identifies regular behaviors</li>
<li>Spots unusual activities</li>
<li>Learns from historical data</li>
</ul>
</section>
<section id="personalization" class="level3">
<h3 class="anchored" data-anchor-id="personalization">2. Personalization</h3>
<ul>
<li>Adapts to individual preferences</li>
<li>Improves with more data</li>
<li>Creates unique experiences</li>
</ul>
</section>
<section id="prediction" class="level3">
<h3 class="anchored" data-anchor-id="prediction">3. Prediction</h3>
<ul>
<li>Anticipates needs</li>
<li>Forecasts events</li>
<li>Suggests actions</li>
</ul>
</section>
</section>
<section id="benefits-in-daily-life" class="level2">
<h2 class="anchored" data-anchor-id="benefits-in-daily-life">Benefits in Daily Life</h2>
<section id="time-saving" class="level3">
<h3 class="anchored" data-anchor-id="time-saving">1. Time Saving</h3>
<ul>
<li>Automates routine tasks</li>
<li>Provides quick answers</li>
<li>Reduces decision time</li>
</ul>
</section>
<section id="better-decisions" class="level3">
<h3 class="anchored" data-anchor-id="better-decisions">2. Better Decisions</h3>
<ul>
<li>More informed choices</li>
<li>Personalized recommendations</li>
<li>Data-driven insights</li>
</ul>
</section>
<section id="enhanced-experiences" class="level3">
<h3 class="anchored" data-anchor-id="enhanced-experiences">3. Enhanced Experiences</h3>
<ul>
<li>Customized content</li>
<li>Smoother interactions</li>
<li>Proactive assistance</li>
</ul>
</section>
</section>
<section id="privacy-considerations" class="level2">
<h2 class="anchored" data-anchor-id="privacy-considerations">Privacy Considerations</h2>
<section id="data-collection" class="level3">
<h3 class="anchored" data-anchor-id="data-collection">1. Data Collection</h3>
<ul>
<li>What data is collected</li>
<li>How it’s used</li>
<li>Storage security</li>
</ul>
</section>
<section id="user-control" class="level3">
<h3 class="anchored" data-anchor-id="user-control">2. User Control</h3>
<ul>
<li>Privacy settings</li>
<li>Opt-out options</li>
<li>Data access rights</li>
</ul>
</section>
<section id="best-practices" class="level3">
<h3 class="anchored" data-anchor-id="best-practices">3. Best Practices</h3>
<ul>
<li>Review app permissions</li>
<li>Regular privacy checks</li>
<li>Understand data usage</li>
</ul>
</section>
</section>
<section id="future-trends" class="level2">
<h2 class="anchored" data-anchor-id="future-trends">Future Trends</h2>
<section id="more-personalization" class="level3">
<h3 class="anchored" data-anchor-id="more-personalization">1. More Personalization</h3>
<ul>
<li>Deeper understanding</li>
<li>Better predictions</li>
<li>Tailored experiences</li>
</ul>
</section>
<section id="improved-integration" class="level3">
<h3 class="anchored" data-anchor-id="improved-integration">2. Improved Integration</h3>
<ul>
<li>Seamless connections</li>
<li>Cross-device harmony</li>
<li>Unified experiences</li>
</ul>
</section>
<section id="enhanced-privacy" class="level3">
<h3 class="anchored" data-anchor-id="enhanced-privacy">3. Enhanced Privacy</h3>
<ul>
<li>Better data protection</li>
<li>More user control</li>
<li>Transparent practices</li>
</ul>
</section>
</section>
<section id="making-the-most-of-ml" class="level2">
<h2 class="anchored" data-anchor-id="making-the-most-of-ml">Making the Most of ML</h2>
<section id="be-aware" class="level3">
<h3 class="anchored" data-anchor-id="be-aware">1. Be Aware</h3>
<ul>
<li>Notice ML in daily life</li>
<li>Understand basic concepts</li>
<li>Stay informed of changes</li>
</ul>
</section>
<section id="use-features-wisely" class="level3">
<h3 class="anchored" data-anchor-id="use-features-wisely">2. Use Features Wisely</h3>
<ul>
<li>Enable helpful features</li>
<li>Maintain privacy</li>
<li>Provide feedback</li>
</ul>
</section>
<section id="stay-safe" class="level3">
<h3 class="anchored" data-anchor-id="stay-safe">3. Stay Safe</h3>
<ul>
<li>Review settings regularly</li>
<li>Understand data sharing</li>
<li>Make informed choices</li>
</ul>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Machine learning is: 1. Already part of daily life 2. Making things easier 3. Constantly improving 4. Working behind the scenes</p>
<p>Remember: - ML is a tool to help you - You control how to use it - Balance convenience and privacy - Stay informed about changes</p>
</section>
<section id="additional-resources" class="level2">
<h2 class="anchored" data-anchor-id="additional-resources">Additional Resources</h2>
<ol type="1">
<li>For Learning More:
<ul>
<li>“AI Basics” courses on Coursera</li>
<li>YouTube channels about technology</li>
<li>Tech news websites</li>
</ul></li>
<li>For Privacy:
<ul>
<li>Privacy setting guides</li>
<li>Data protection websites</li>
<li>Security best practices</li>
</ul></li>
<li>For Updates:
<ul>
<li>Technology blogs</li>
<li>ML news websites</li>
<li>Company update pages</li>
</ul></li>
</ol>
<p>Remember: Machine learning is here to help make your life easier, but it’s important to use it wisely and stay informed about how it affects your daily activities.</p>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>applications</category>
  <category>real-world</category>
  <category>beginner</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/ml-in-everyday-life/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/ml-in-everyday-life/ml_everyday.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Machine Learning Theory: Mathematical Foundations</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/ml-theory-foundations/</link>
  <description><![CDATA[ 





<section id="machine-learning-theory-mathematical-foundations" class="level1">
<h1>Machine Learning Theory: Mathematical Foundations</h1>
<section id="statistical-learning-theory" class="level2">
<h2 class="anchored" data-anchor-id="statistical-learning-theory">Statistical Learning Theory</h2>
<section id="learning-framework" class="level3">
<h3 class="anchored" data-anchor-id="learning-framework">1. Learning Framework</h3>
<p>Risk minimization:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR(f)%20=%20%5Cmathbb%7BE%7D_%7B(X,Y)%5Csim%20P%7D%5BL(f(X),Y)%5D%0A"></p>
<p>Empirical risk:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BR%7D_n(f)%20=%20%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5En%20L(f(x_i),y_i)%0A"></p>
</section>
<section id="generalization-bounds" class="level3">
<h3 class="anchored" data-anchor-id="generalization-bounds">2. Generalization Bounds</h3>
<p>Hoeffding’s inequality:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%7C%5Chat%7BR%7D_n(f)%20-%20R(f)%7C%20%3E%20%5Cepsilon)%20%5Cleq%202%5Cexp(-2n%5Cepsilon%5E2)%0A"></p>
<p>Union bound for finite hypothesis class:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Csup_%7Bf%20%5Cin%20%5Cmathcal%7BF%7D%7D%7C%5Chat%7BR%7D_n(f)%20-%20R(f)%7C%20%3E%20%5Cepsilon)%20%5Cleq%202%7C%5Cmathcal%7BF%7D%7C%5Cexp(-2n%5Cepsilon%5E2)%0A"></p>
</section>
<section id="vc-theory" class="level3">
<h3 class="anchored" data-anchor-id="vc-theory">3. VC Theory</h3>
<p>VC dimension definition: - Maximum number of points that can be shattered - Growth function: <img src="https://latex.codecogs.com/png.latex?%5CPi_%7B%5Cmathcal%7BF%7D%7D(n)"> - Sauer’s Lemma: <img src="https://latex.codecogs.com/png.latex?%5CPi_%7B%5Cmathcal%7BF%7D%7D(n)%20%5Cleq%20%5Csum_%7Bi=0%7D%5Ed%20%5Cbinom%7Bn%7D%7Bi%7D"></p>
<p>VC generalization bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Csup_%7Bf%20%5Cin%20%5Cmathcal%7BF%7D%7D%7C%5Chat%7BR%7D_n(f)%20-%20R(f)%7C%20%3E%20%5Cepsilon)%20%5Cleq%208%5CPi_%7B%5Cmathcal%7BF%7D%7D(2n)%5Cexp(-n%5Cepsilon%5E2/32)%0A"></p>
</section>
</section>
<section id="optimization-theory" class="level2">
<h2 class="anchored" data-anchor-id="optimization-theory">Optimization Theory</h2>
<section id="convex-optimization" class="level3">
<h3 class="anchored" data-anchor-id="convex-optimization">1. Convex Optimization</h3>
<p>First-order condition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(y)%20%5Cgeq%20f(x)%20+%20%5Cnabla%20f(x)%5ET(y-x)%0A"></p>
<p>Second-order condition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla%5E2%20f(x)%20%5Csucceq%200%0A"></p>
</section>
<section id="strong-convexity" class="level3">
<h3 class="anchored" data-anchor-id="strong-convexity">2. Strong Convexity</h3>
<p>Definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(y)%20%5Cgeq%20f(x)%20+%20%5Cnabla%20f(x)%5ET(y-x)%20+%20%5Cfrac%7B%5Cmu%7D%7B2%7D%5C%7Cy-x%5C%7C%5E2%0A"></p>
<p>Convergence rate:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x_k)%20-%20f(x%5E*)%20%5Cleq%20(1-%5Cfrac%7B%5Cmu%7D%7BL%7D)%5Ek%5Bf(x_0)%20-%20f(x%5E*)%5D%0A"></p>
</section>
<section id="smoothness" class="level3">
<h3 class="anchored" data-anchor-id="smoothness">3. Smoothness</h3>
<p>L-smoothness condition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5C%7C%5Cnabla%20f(x)%20-%20%5Cnabla%20f(y)%5C%7C%20%5Cleq%20L%5C%7Cx-y%5C%7C%0A"></p>
<p>Gradient descent convergence:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x_k)%20-%20f(x%5E*)%20%5Cleq%20%5Cfrac%7B2L%5C%7Cx_0-x%5E*%5C%7C%5E2%7D%7Bk+4%7D%0A"></p>
</section>
</section>
<section id="information-theory-in-learning" class="level2">
<h2 class="anchored" data-anchor-id="information-theory-in-learning">Information Theory in Learning</h2>
<section id="entropy-and-mutual-information" class="level3">
<h3 class="anchored" data-anchor-id="entropy-and-mutual-information">1. Entropy and Mutual Information</h3>
<p>Entropy:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AH(X)%20=%20-%5Csum_%7Bx%7D%20P(x)%5Clog%20P(x)%0A"></p>
<p>Mutual information:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AI(X;Y)%20=%20H(X)%20-%20H(X%7CY)%20=%20H(Y)%20-%20H(Y%7CX)%0A"></p>
</section>
<section id="information-bottleneck" class="level3">
<h3 class="anchored" data-anchor-id="information-bottleneck">2. Information Bottleneck</h3>
<p>Objective:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7BP(T%7CX)%7D%20I(X;T)%20-%20%5Cbeta%20I(T;Y)%0A"></p>
<p>Solution characterization:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(t%7Cx)%20=%20%5Cfrac%7BP(t)%7D%7BZ(x,%5Cbeta)%7D%5Cexp(-%5Cbeta%20D_%7BKL%7D(P(Y%7Cx)%5C%7CP(Y%7Ct)))%0A"></p>
</section>
<section id="pac-bayes-theory" class="level3">
<h3 class="anchored" data-anchor-id="pac-bayes-theory">3. PAC-Bayes Theory</h3>
<p>PAC-Bayes bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(R(Q)%20%5Cleq%20%5Chat%7BR%7D(Q)%20+%20%5Csqrt%7B%5Cfrac%7BD_%7BKL%7D(Q%5C%7CP)%20+%20%5Cln%5Cfrac%7B2%5Csqrt%7Bn%7D%7D%7B%5Cdelta%7D%7D%7B2n%7D%7D)%20%5Cgeq%201-%5Cdelta%0A"></p>
</section>
</section>
<section id="learning-theory-bounds" class="level2">
<h2 class="anchored" data-anchor-id="learning-theory-bounds">Learning Theory Bounds</h2>
<section id="rademacher-complexity" class="level3">
<h3 class="anchored" data-anchor-id="rademacher-complexity">1. Rademacher Complexity</h3>
<p>Definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathfrak%7BR%7D_n(%5Cmathcal%7BF%7D)%20=%20%5Cmathbb%7BE%7D_%7B%5Csigma,S%7D%5B%5Csup_%7Bf%20%5Cin%20%5Cmathcal%7BF%7D%7D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5En%20%5Csigma_i%20f(x_i)%5D%0A"></p>
<p>Generalization bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Csup_%7Bf%20%5Cin%20%5Cmathcal%7BF%7D%7D%7CR(f)%20-%20%5Chat%7BR%7D_n(f)%7C%20%5Cleq%202%5Cmathfrak%7BR%7D_n(%5Cmathcal%7BF%7D)%20+%20%5Csqrt%7B%5Cfrac%7B%5Cln(2/%5Cdelta)%7D%7B2n%7D%7D)%20%5Cgeq%201-%5Cdelta%0A"></p>
</section>
<section id="covering-numbers" class="level3">
<h3 class="anchored" data-anchor-id="covering-numbers">2. Covering Numbers</h3>
<p>Definition: - <img src="https://latex.codecogs.com/png.latex?%5Cepsilon">-cover of <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BF%7D"> - Metric entropy: <img src="https://latex.codecogs.com/png.latex?%5Cln%20N(%5Cepsilon,%5Cmathcal%7BF%7D,L_2)"></p>
<p>Dudley’s entropy integral:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathfrak%7BR%7D_n(%5Cmathcal%7BF%7D)%20%5Cleq%20%5Cfrac%7B12%7D%7B%5Csqrt%7Bn%7D%7D%5Cint_0%5E%5Cinfty%20%5Csqrt%7B%5Cln%20N(%5Cepsilon,%5Cmathcal%7BF%7D,L_2)%7Dd%5Cepsilon%0A"></p>
</section>
<section id="stability-theory" class="level3">
<h3 class="anchored" data-anchor-id="stability-theory">3. Stability Theory</h3>
<p>Algorithmic stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cell(A_S,z)%20-%20%5Cell(A_%7BS%5Ei%7D,z)%7C%20%5Cleq%20%5Cbeta%0A"></p>
<p>Generalization bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%7CR(A_S)%20-%20%5Chat%7BR%7D_n(A_S)%7C%20%3E%20%5Cepsilon)%20%5Cleq%202%5Cexp(-2n%5Cepsilon%5E2/%5Cbeta%5E2)%0A"></p>
</section>
</section>
<section id="optimization-convergence" class="level2">
<h2 class="anchored" data-anchor-id="optimization-convergence">Optimization Convergence</h2>
<section id="first-order-methods" class="level3">
<h3 class="anchored" data-anchor-id="first-order-methods">1. First-Order Methods</h3>
<p>Gradient descent:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_%7Bk+1%7D%20=%20x_k%20-%20%5Ceta_k%5Cnabla%20f(x_k)%0A"></p>
<p>Convergence rate (convex):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x_k)%20-%20f(x%5E*)%20%5Cleq%20%5Cfrac%7B%5C%7Cx_0-x%5E*%5C%7C%5E2%7D%7B2%5Ceta%20k%7D%0A"></p>
</section>
<section id="stochastic-methods" class="level3">
<h3 class="anchored" data-anchor-id="stochastic-methods">2. Stochastic Methods</h3>
<p>SGD update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_%7Bk+1%7D%20=%20x_k%20-%20%5Ceta_k%5Cnabla%20f_%7Bi_k%7D(x_k)%0A"></p>
<p>Convergence rate:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5Bf(x_k)%20-%20f(x%5E*)%5D%20%5Cleq%20%5Cfrac%7BL%5C%7Cx_0-x%5E*%5C%7C%5E2%7D%7B2k%7D%20+%20%5Cfrac%7BL%5Csigma%5E2%7D%7B2%7D%5Csum_%7Bt=1%7D%5Ek%20%5Ceta_t%5E2%0A"></p>
</section>
<section id="accelerated-methods" class="level3">
<h3 class="anchored" data-anchor-id="accelerated-methods">3. Accelerated Methods</h3>
<p>Nesterov’s method:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Ay_k%20&amp;=%20x_k%20+%20%5Cbeta_k(x_k%20-%20x_%7Bk-1%7D)%20%5C%5C%0Ax_%7Bk+1%7D%20&amp;=%20y_k%20-%20%5Ceta_k%5Cnabla%20f(y_k)%0A%5Cend%7Baligned%7D%0A"></p>
<p>Convergence rate:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x_k)%20-%20f(x%5E*)%20%5Cleq%20%5Cfrac%7B4L%5C%7Cx_0-x%5E*%5C%7C%5E2%7D%7B(k+2)%5E2%7D%0A"></p>
</section>
</section>
<section id="advanced-topics" class="level2">
<h2 class="anchored" data-anchor-id="advanced-topics">Advanced Topics</h2>
<section id="online-learning" class="level3">
<h3 class="anchored" data-anchor-id="online-learning">1. Online Learning</h3>
<p>Regret bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20=%20%5Csum_%7Bt=1%7D%5ET%20%5Cell_t(x_t)%20-%20%5Cmin_%7Bx%20%5Cin%20%5Cmathcal%7BX%7D%7D%5Csum_%7Bt=1%7D%5ET%20%5Cell_t(x)%0A"></p>
<p>Online gradient descent:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%20%5Cfrac%7BD%5E2%7D%7B2%5Ceta%7D%20+%20%5Cfrac%7B%5Ceta%20G%5E2T%7D%7B2%7D%0A"></p>
</section>
<section id="multi-armed-bandits" class="level3">
<h3 class="anchored" data-anchor-id="multi-armed-bandits">2. Multi-Armed Bandits</h3>
<p>UCB algorithm:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BUCB%7D_i(t)%20=%20%5Chat%7B%5Cmu%7D_i(t)%20+%20%5Csqrt%7B%5Cfrac%7B2%5Cln%20t%7D%7BN_i(t)%7D%7D%0A"></p>
<p>Regret bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%20%5Csum_%7Bi:%5CDelta_i%3E0%7D%20%5Cfrac%7B8%5Cln%20T%7D%7B%5CDelta_i%7D%20+%20(1+%5Cfrac%7B%5Cpi%5E2%7D%7B3%7D)%5Csum_%7Bi=1%7D%5EK%20%5CDelta_i%0A"></p>
</section>
<section id="active-learning" class="level3">
<h3 class="anchored" data-anchor-id="active-learning">3. Active Learning</h3>
<p>Disagreement coefficient:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta%20=%20%5Csup_%7Br%3E0%7D%20%5Cfrac%7B%5Ctext%7BP%7D(DIS(B(h%5E*,r)))%7D%7Br%7D%0A"></p>
<p>Label complexity:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctilde%7BO%7D(%5Ctheta%20d%5Clog(1/%5Cepsilon))%0A"></p>
</section>
</section>
<section id="theoretical-frameworks" class="level2">
<h2 class="anchored" data-anchor-id="theoretical-frameworks">Theoretical Frameworks</h2>
<section id="margin-theory" class="level3">
<h3 class="anchored" data-anchor-id="margin-theory">1. Margin Theory</h3>
<p>Margin bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(R(f)%20%5Cleq%20%5Chat%7BR%7D_%5Cgamma(f)%20+%20O(%5Csqrt%7B%5Cfrac%7Bd%5Clog(1/%5Cgamma)%7D%7Bn%5Cgamma%5E2%7D%7D))%20%5Cgeq%201-%5Cdelta%0A"></p>
</section>
<section id="kernel-methods" class="level3">
<h3 class="anchored" data-anchor-id="kernel-methods">2. Kernel Methods</h3>
<p>Representer theorem:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af%5E*(x)%20=%20%5Csum_%7Bi=1%7D%5En%20%5Calpha_i%20K(x,x_i)%0A"></p>
<p>RKHS norm:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5C%7Cf%5C%7C_%7B%5Cmathcal%7BH%7D%7D%5E2%20=%20%5Csum_%7Bi,j=1%7D%5En%20%5Calpha_i%5Calpha_j%20K(x_i,x_j)%0A"></p>
</section>
<section id="boosting-theory" class="level3">
<h3 class="anchored" data-anchor-id="boosting-theory">3. Boosting Theory</h3>
<p>AdaBoost bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7BR%7D(H_T)%20%5Cleq%20%5Cexp(-2%5Csum_%7Bt=1%7D%5ET(%5Cfrac%7B1%7D%7B2%7D-%5Cgamma_t)%5E2)%0A"></p>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="model-selection" class="level3">
<h3 class="anchored" data-anchor-id="model-selection">1. Model Selection</h3>
<ol type="1">
<li>Bias-Variance Trade-off:
<ul>
<li>Empirical risk minimization</li>
<li>Structural risk minimization</li>
<li>Cross-validation bounds</li>
</ul></li>
<li>Regularization:
<ul>
<li>L1/L2 regularization theory</li>
<li>Early stopping</li>
<li>Model averaging</li>
</ul></li>
<li>Validation:
<ul>
<li>Hold-out bounds</li>
<li>Bootstrap theory</li>
<li>Cross-validation theory</li>
</ul></li>
</ol>
</section>
<section id="algorithm-design" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-design">2. Algorithm Design</h3>
<ol type="1">
<li>Optimization:
<ul>
<li>Convergence analysis</li>
<li>Step size selection</li>
<li>Momentum methods</li>
</ul></li>
<li>Architecture:
<ul>
<li>Depth vs width theory</li>
<li>Universal approximation</li>
<li>Expressivity bounds</li>
</ul></li>
<li>Learning:
<ul>
<li>Sample complexity</li>
<li>Computational complexity</li>
<li>Statistical efficiency</li>
</ul></li>
</ol>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Theory:
<ul>
<li>“Foundations of Machine Learning” by Mohri et al.</li>
<li>“Understanding Machine Learning” by Shalev-Shwartz and Ben-David</li>
<li>“Statistical Learning Theory” by Vapnik</li>
</ul></li>
<li>Optimization:
<ul>
<li>“Convex Optimization” by Boyd and Vandenberghe</li>
<li>“Introductory Lectures on Convex Optimization” by Nesterov</li>
<li>“Optimization Methods for Large-Scale Machine Learning” by Bottou et al.</li>
</ul></li>
<li>Advanced Topics:
<ul>
<li>“Theory of Classification” by Devroye et al.</li>
<li>“Information Theory, Inference, and Learning Algorithms” by MacKay</li>
<li>“Theoretical Foundations of Deep Learning” by Vidal et al.</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>theory</category>
  <category>mathematics</category>
  <category>statistics</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/ml-theory-foundations/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/ml-theory-foundations/ml_theory.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Online Learning and Regret Minimization</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/online-learning/</link>
  <description><![CDATA[ 





<section id="online-learning-and-regret-minimization" class="level1">
<h1>Online Learning and Regret Minimization</h1>
<section id="fundamental-concepts" class="level2">
<h2 class="anchored" data-anchor-id="fundamental-concepts">Fundamental Concepts</h2>
<section id="online-learning-protocol" class="level3">
<h3 class="anchored" data-anchor-id="online-learning-protocol">1. Online Learning Protocol</h3>
<p>Learning process: 1. Receive instance <img src="https://latex.codecogs.com/png.latex?x_t"> 2. Predict <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D_t"> 3. Observe true outcome <img src="https://latex.codecogs.com/png.latex?y_t"> 4. Suffer loss <img src="https://latex.codecogs.com/png.latex?%5Cell(%7B%5Chat%7By%7D_t,%20y_t%7D)"> 5. Update model</p>
<p>Regret definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20=%20%5Csum_%7Bt=1%7D%5ET%20%5Cell(h_t(x_t),%20y_t)%20-%20%5Cmin_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%5Csum_%7Bt=1%7D%5ET%20%5Cell(h(x_t),%20y_t)%0A"></p>
</section>
<section id="types-of-regret" class="level3">
<h3 class="anchored" data-anchor-id="types-of-regret">2. Types of Regret</h3>
<p>External regret:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%5E%7B%5Ctext%7Bext%7D%7D%20=%20%5Cmathbb%7BE%7D%5Cleft%5B%5Csum_%7Bt=1%7D%5ET%20%5Cell_t(a_t)%5Cright%5D%20-%20%5Cmin_%7Ba%20%5Cin%20%5Cmathcal%7BA%7D%7D%5Cmathbb%7BE%7D%5Cleft%5B%5Csum_%7Bt=1%7D%5ET%20%5Cell_t(a)%5Cright%5D%0A"></p>
<p>Internal/swap regret:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%5E%7B%5Ctext%7Bint%7D%7D%20=%20%5Cmathbb%7BE%7D%5Cleft%5B%5Csum_%7Bt=1%7D%5ET%20%5Cell_t(a_t)%5Cright%5D%20-%20%5Cmin_%7B%5Cphi:%20%5Cmathcal%7BA%7D%20%5Cto%20%5Cmathcal%7BA%7D%7D%5Cmathbb%7BE%7D%5Cleft%5B%5Csum_%7Bt=1%7D%5ET%20%5Cell_t(%5Cphi(a_t))%5Cright%5D%0A"></p>
</section>
<section id="performance-measures" class="level3">
<h3 class="anchored" data-anchor-id="performance-measures">3. Performance Measures</h3>
<p>Average regret:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbar%7BR%7D_T%20=%20%5Cfrac%7BR_T%7D%7BT%7D%0A"></p>
<p>Competitive ratio:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0ACR_T%20=%20%5Cfrac%7B%5Csum_%7Bt=1%7D%5ET%20%5Cell_t(a_t)%7D%7B%5Cmin_%7Ba%20%5Cin%20%5Cmathcal%7BA%7D%7D%5Csum_%7Bt=1%7D%5ET%20%5Cell_t(a)%7D%0A"></p>
</section>
</section>
<section id="online-convex-optimization" class="level2">
<h2 class="anchored" data-anchor-id="online-convex-optimization">Online Convex Optimization</h2>
<section id="online-gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="online-gradient-descent">1. Online Gradient Descent</h3>
<p>Update rule:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw_%7Bt+1%7D%20=%20%5CPi_%7B%5Cmathcal%7BW%7D%7D(w_t%20-%20%5Ceta_t%20%5Cnabla%20%5Cell_t(w_t))%0A"></p>
<p>Regret bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%20%5Cfrac%7BD%5E2%7D%7B2%5Ceta%7D%20+%20%5Cfrac%7B%5Ceta%20G%5E2T%7D%7B2%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?D"> is diameter of feasible set - <img src="https://latex.codecogs.com/png.latex?G"> is gradient bound - <img src="https://latex.codecogs.com/png.latex?%5Ceta"> is learning rate</p>
</section>
<section id="follow-the-regularized-leader" class="level3">
<h3 class="anchored" data-anchor-id="follow-the-regularized-leader">2. Follow The Regularized Leader</h3>
<p>FTRL update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw_%7Bt+1%7D%20=%20%5Carg%5Cmin_%7Bw%20%5Cin%20%5Cmathcal%7BW%7D%7D%5C%7B%5Ceta%5Csum_%7Bs=1%7D%5Et%20%5Cell_s(w)%20+%20R(w)%5C%7D%0A"></p>
<p>Regret bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%20%5Cfrac%7BR(w%5E*)%7D%7B%5Ceta%7D%20+%20%5Cfrac%7B%5Ceta%20G%5E2T%7D%7B2%7D%0A"></p>
</section>
<section id="mirror-descent" class="level3">
<h3 class="anchored" data-anchor-id="mirror-descent">3. Mirror Descent</h3>
<p>Update rule:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla%20%5Cpsi(w_%7Bt+1%7D)%20=%20%5Cnabla%20%5Cpsi(w_t)%20-%20%5Ceta_t%20%5Cnabla%20%5Cell_t(w_t)%0A"></p>
<p>Regret bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%20%5Cfrac%7BD_%5Cpsi(w%5E*%5C%7Cw_1)%7D%7B%5Ceta%7D%20+%20%5Cfrac%7B%5Ceta%20G%5E2T%7D%7B2%7D%0A"></p>
</section>
</section>
<section id="multi-armed-bandits" class="level2">
<h2 class="anchored" data-anchor-id="multi-armed-bandits">Multi-Armed Bandits</h2>
<section id="ucb-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="ucb-algorithm">1. UCB Algorithm</h3>
<p>UCB index:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AUCB_i(t)%20=%20%5Chat%7B%5Cmu%7D_i(t)%20+%20%5Csqrt%7B%5Cfrac%7B2%5Cln%20t%7D%7BN_i(t)%7D%7D%0A"></p>
<p>Regret bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%20%5Csum_%7Bi:%5CDelta_i%3E0%7D%5Cleft(%5Cfrac%7B8%5Cln%20T%7D%7B%5CDelta_i%7D%20+%20(1+%5Cpi%5E2/3)%5CDelta_i%5Cright)%0A"></p>
</section>
<section id="thompson-sampling" class="level3">
<h3 class="anchored" data-anchor-id="thompson-sampling">2. Thompson Sampling</h3>
<p>Posterior sampling:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_i(t)%20%5Csim%20Beta(%5Calpha_i(t),%20%5Cbeta_i(t))%0A"></p>
<p>Regret bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%20O(%5Csqrt%7BKT%5Cln%20T%7D)%0A"></p>
</section>
<section id="exp3-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="exp3-algorithm">3. Exp3 Algorithm</h3>
<p>Probability update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap_i(t)%20=%20%5Cfrac%7B(1-%5Cgamma)%5Cexp(%5Ceta%20G_i(t))%7D%7B%5Csum_%7Bj=1%7D%5EK%20%5Cexp(%5Ceta%20G_j(t))%7D%20+%20%5Cfrac%7B%5Cgamma%7D%7BK%7D%0A"></p>
<p>Regret bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%202%5Csqrt%7BKT%5Cln%20K%7D%0A"></p>
</section>
</section>
<section id="expert-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="expert-algorithms">Expert Algorithms</h2>
<section id="weighted-majority" class="level3">
<h3 class="anchored" data-anchor-id="weighted-majority">1. Weighted Majority</h3>
<p>Weight update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw_i(t+1)%20=%20w_i(t)(1-%5Ceta)%5E%7B%5Cell_i(t)%7D%0A"></p>
<p>Regret bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%20%5Csqrt%7BT%5Cln%20N%7D%0A"></p>
</section>
<section id="hedge-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="hedge-algorithm">2. Hedge Algorithm</h3>
<p>Probability update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap_i(t+1)%20=%20%5Cfrac%7B%5Cexp(-%5Ceta%20L_i(t))%7D%7B%5Csum_%7Bj=1%7D%5EN%20%5Cexp(-%5Ceta%20L_j(t))%7D%0A"></p>
<p>Regret bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%20%5Csqrt%7B2T%5Cln%20N%7D%0A"></p>
</section>
<section id="adahedge" class="level3">
<h3 class="anchored" data-anchor-id="adahedge">3. AdaHedge</h3>
<p>Adaptive learning rate:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ceta_t%20=%20%5Cfrac%7B%5Cln%20N%7D%7BV_t%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?V_t"> is cumulative variance - <img src="https://latex.codecogs.com/png.latex?N"> is number of experts</p>
</section>
</section>
<section id="advanced-topics" class="level2">
<h2 class="anchored" data-anchor-id="advanced-topics">Advanced Topics</h2>
<section id="adaptive-algorithms" class="level3">
<h3 class="anchored" data-anchor-id="adaptive-algorithms">1. Adaptive Algorithms</h3>
<p>AdaGrad update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw_%7Bt+1,i%7D%20=%20w_%7Bt,i%7D%20-%20%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Csum_%7Bs=1%7D%5Et%20g_%7Bs,i%7D%5E2%7D%7Dg_%7Bt,i%7D%0A"></p>
<p>Regret bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%20O(%5Csqrt%7BT%7D%5C%7Cw%5E*%5C%7C_2%5Csqrt%7B%5Csum_%7Bi=1%7D%5Ed%5Csum_%7Bt=1%7D%5ET%20g_%7Bt,i%7D%5E2%7D)%0A"></p>
</section>
<section id="second-order-methods" class="level3">
<h3 class="anchored" data-anchor-id="second-order-methods">2. Second-Order Methods</h3>
<p>ONS update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw_%7Bt+1%7D%20=%20w_t%20-%20%5Ceta%20A_t%5E%7B-1%7D%5Cnabla%20%5Cell_t(w_t)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?A_t%20=%20%5Csum_%7Bs=1%7D%5Et%20%5Cnabla%20%5Cell_s(w_s)%5Cnabla%20%5Cell_s(w_s)%5ET"></p>
</section>
<section id="parameter-free-methods" class="level3">
<h3 class="anchored" data-anchor-id="parameter-free-methods">3. Parameter-Free Methods</h3>
<p>MetaGrad update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw_%7Bt+1%7D%20=%20w_t%20-%20%5Ceta_t%20H_t%5E%7B-1/2%7D%5Cnabla%20%5Cell_t(w_t)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?H_t"> is preconditioner matrix</p>
</section>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">Applications</h2>
<section id="portfolio-selection" class="level3">
<h3 class="anchored" data-anchor-id="portfolio-selection">1. Portfolio Selection</h3>
<p>Objective:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmax_%7Bw%20%5Cin%20%5CDelta_n%7D%20%5Csum_%7Bt=1%7D%5ET%20%5Clog(w%5ET%20r_t)%0A"></p>
<p>Universal portfolio:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw_%7Bt+1%7D%20=%20%5Cint_%7B%5CDelta_n%7D%20w%20P_t(w)dw%0A"></p>
</section>
<section id="online-routing" class="level3">
<h3 class="anchored" data-anchor-id="online-routing">2. Online Routing</h3>
<p>Flow update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af_%7Bt+1%7D(e)%20=%20f_t(e)%5Cexp(-%5Ceta%20%5Cell_t(e))%0A"></p>
<p>Path selection:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(p)%20=%20%5Cfrac%7B%5Cprod_%7Be%20%5Cin%20p%7Df_t(e)%7D%7B%5Csum_%7Bp'%20%5Cin%20%5Cmathcal%7BP%7D%7D%5Cprod_%7Be%20%5Cin%20p'%7Df_t(e)%7D%0A"></p>
</section>
<section id="online-classification" class="level3">
<h3 class="anchored" data-anchor-id="online-classification">3. Online Classification</h3>
<p>Perceptron update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aw_%7Bt+1%7D%20=%20w_t%20+%20y_tx_t%5Cmathbb%7B1%7D%5By_tw_t%5ETx_t%20%5Cleq%200%5D%0A"></p>
<p>Mistake bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AM%20%5Cleq%20%5Cleft(%5Cfrac%7BR%7D%7B%5Cgamma%7D%5Cright)%5E2%0A"></p>
</section>
</section>
<section id="theoretical-results" class="level2">
<h2 class="anchored" data-anchor-id="theoretical-results">Theoretical Results</h2>
<section id="lower-bounds" class="level3">
<h3 class="anchored" data-anchor-id="lower-bounds">1. Lower Bounds</h3>
<p>Minimax regret:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7B%5Ctext%7BALG%7D%7D%5Cmax_%7B%5Ctext%7BADV%7D%7D%20R_T%20=%20%5COmega(%5Csqrt%7BT%7D)%0A"></p>
<p>Expert setting:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20=%20%5COmega(%5Csqrt%7BT%5Cln%20N%7D)%0A"></p>
</section>
<section id="information-theory" class="level3">
<h3 class="anchored" data-anchor-id="information-theory">2. Information Theory</h3>
<p>Redundancy bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%20%5Cfrac%7BKL(P%5C%7CQ)%20+%20%5Cln(1/%5Cdelta)%7D%7B%5Ceta%7D%20+%20%5Cfrac%7B%5Ceta%20T%7D%7B8%7D%0A"></p>
</section>
<section id="game-theory" class="level3">
<h3 class="anchored" data-anchor-id="game-theory">3. Game Theory</h3>
<p>Nash equilibrium:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmax_P%20%5Cmin_Q%20%5Cmathbb%7BE%7D_%7Bp%20%5Csim%20P,%20q%20%5Csim%20Q%7D%5BM(p,q)%5D%20=%20%5Cmin_Q%20%5Cmax_P%20%5Cmathbb%7BE%7D_%7Bp%20%5Csim%20P,%20q%20%5Csim%20Q%7D%5BM(p,q)%5D%0A"></p>
</section>
</section>
<section id="implementation-considerations" class="level2">
<h2 class="anchored" data-anchor-id="implementation-considerations">Implementation Considerations</h2>
<section id="algorithm-selection" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-selection">1. Algorithm Selection</h3>
<ol type="1">
<li>Problem Structure:
<ul>
<li>Convexity</li>
<li>Smoothness</li>
<li>Sparsity</li>
</ul></li>
<li>Computational Constraints:
<ul>
<li>Memory limits</li>
<li>Update time</li>
<li>Parallelization</li>
</ul></li>
<li>Performance Requirements:
<ul>
<li>Regret bounds</li>
<li>Adaptation speed</li>
<li>Robustness</li>
</ul></li>
</ol>
</section>
<section id="parameter-tuning" class="level3">
<h3 class="anchored" data-anchor-id="parameter-tuning">2. Parameter Tuning</h3>
<ol type="1">
<li>Learning Rates:
<ul>
<li>Fixed vs adaptive</li>
<li>Schedule design</li>
<li>Initialization</li>
</ul></li>
<li>Exploration:
<ul>
<li>Exploration rate</li>
<li>Decay schedule</li>
<li>Adaptive schemes</li>
</ul></li>
<li>Regularization:
<ul>
<li>Strength</li>
<li>Type selection</li>
<li>Adaptation</li>
</ul></li>
</ol>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="algorithm-design" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-design">1. Algorithm Design</h3>
<ol type="1">
<li>Robustness:
<ul>
<li>Adversarial scenarios</li>
<li>Noise handling</li>
<li>Distribution shifts</li>
</ul></li>
<li>Efficiency:
<ul>
<li>Memory usage</li>
<li>Update complexity</li>
<li>Parallelization</li>
</ul></li>
<li>Adaptivity:
<ul>
<li>Parameter tuning</li>
<li>Distribution changes</li>
<li>Model selection</li>
</ul></li>
</ol>
</section>
<section id="implementation" class="level3">
<h3 class="anchored" data-anchor-id="implementation">2. Implementation</h3>
<ol type="1">
<li>Data Handling:
<ul>
<li>Streaming processing</li>
<li>Feature extraction</li>
<li>Preprocessing</li>
</ul></li>
<li>Monitoring:
<ul>
<li>Regret tracking</li>
<li>Performance metrics</li>
<li>Resource usage</li>
</ul></li>
<li>Deployment:
<ul>
<li>System integration</li>
<li>Error handling</li>
<li>Scaling strategy</li>
</ul></li>
</ol>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Theory:
<ul>
<li>“Introduction to Online Convex Optimization” by Hazan</li>
<li>“Bandit Algorithms” by Lattimore and Szepesvári</li>
<li>“Prediction, Learning, and Games” by Cesa-Bianchi and Lugosi</li>
</ul></li>
<li>Methods:
<ul>
<li>“Online Learning and Online Convex Optimization” by Shalev-Shwartz</li>
<li>“A Modern Introduction to Online Learning” by Orabona</li>
<li>“Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems” by Bubeck and Cesa-Bianchi</li>
</ul></li>
<li>Applications:
<ul>
<li>“Online Portfolio Selection” by Li and Hoi</li>
<li>“Online Learning in Routing Games” by Roughgarden</li>
<li>“Online Methods in Machine Learning” by Bottou</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>theory</category>
  <category>mathematics</category>
  <category>online-learning</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/online-learning/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/online-learning/online_learning.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Optimization Algorithms in Machine Learning: A Deep Dive</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/optimization-algorithms/</link>
  <description><![CDATA[ 





<section id="optimization-algorithms-in-machine-learning" class="level1">
<h1>Optimization Algorithms in Machine Learning</h1>
<section id="mathematical-foundations" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-foundations">Mathematical Foundations</h2>
<section id="objective-functions" class="level3">
<h3 class="anchored" data-anchor-id="objective-functions">1. Objective Functions</h3>
<p>The core of optimization in machine learning is minimizing (or maximizing) an objective function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmin_%7B%5Ctheta%7D%20J(%5Ctheta)%20=%20%5Cfrac%7B1%7D%7BN%7D%20%5Csum_%7Bi=1%7D%5EN%20L(f_%5Ctheta(x_i),%20y_i)%20+%20%5Clambda%20R(%5Ctheta)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?J(%5Ctheta)"> is the objective function - <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> represents model parameters - <img src="https://latex.codecogs.com/png.latex?L"> is the loss function - <img src="https://latex.codecogs.com/png.latex?f_%5Ctheta"> is the model prediction - <img src="https://latex.codecogs.com/png.latex?R(%5Ctheta)"> is the regularization term - <img src="https://latex.codecogs.com/png.latex?%5Clambda"> is the regularization strength</p>
</section>
<section id="gradient-descent-fundamentals" class="level3">
<h3 class="anchored" data-anchor-id="gradient-descent-fundamentals">2. Gradient Descent Fundamentals</h3>
<p>The basic update rule for gradient descent:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_%7Bt+1%7D%20=%20%5Ctheta_t%20-%20%5Ceta%20%5Cnabla_%5Ctheta%20J(%5Ctheta_t)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Ctheta_t"> is the parameter at iteration t - <img src="https://latex.codecogs.com/png.latex?%5Ceta"> is the learning rate - <img src="https://latex.codecogs.com/png.latex?%5Cnabla_%5Ctheta%20J(%5Ctheta_t)"> is the gradient of the objective function</p>
</section>
<section id="convergence-analysis" class="level3">
<h3 class="anchored" data-anchor-id="convergence-analysis">3. Convergence Analysis</h3>
<p>For convex functions, gradient descent converges at rate:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AJ(%5Ctheta_t)%20-%20J(%5Ctheta%5E*)%20%5Cleq%20%5Cfrac%7B%5C%7C%5Ctheta_0%20-%20%5Ctheta%5E*%5C%7C%5E2%7D%7B2%5Ceta%20t%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Ctheta%5E*"> is the optimal parameter - <img src="https://latex.codecogs.com/png.latex?%5Ctheta_0"> is the initial parameter - <img src="https://latex.codecogs.com/png.latex?t"> is the number of iterations</p>
</section>
</section>
<section id="first-order-methods" class="level2">
<h2 class="anchored" data-anchor-id="first-order-methods">First-Order Methods</h2>
<section id="stochastic-gradient-descent-sgd" class="level3">
<h3 class="anchored" data-anchor-id="stochastic-gradient-descent-sgd">1. Stochastic Gradient Descent (SGD)</h3>
<p>Update rule:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_%7Bt+1%7D%20=%20%5Ctheta_t%20-%20%5Ceta_t%20%5Cnabla_%5Ctheta%20L(f_%5Ctheta(x_i),%20y_i)%0A"></p>
<p>Convergence rate for strongly convex functions:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5BJ(%5Ctheta_t)%20-%20J(%5Ctheta%5E*)%5D%20%5Cleq%20%5Cfrac%7BL%7D%7B2%5Cmu%20t%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?L"> is the Lipschitz constant - <img src="https://latex.codecogs.com/png.latex?%5Cmu"> is the strong convexity parameter</p>
</section>
<section id="momentum" class="level3">
<h3 class="anchored" data-anchor-id="momentum">2. Momentum</h3>
<p>Incorporates velocity in updates:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Av_%7Bt+1%7D%20&amp;=%20%5Cgamma%20v_t%20+%20%5Ceta%20%5Cnabla_%5Ctheta%20J(%5Ctheta_t)%20%5C%5C%0A%5Ctheta_%7Bt+1%7D%20&amp;=%20%5Ctheta_t%20-%20v_%7Bt+1%7D%0A%5Cend%7Baligned%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?v_t"> is the velocity at time t - <img src="https://latex.codecogs.com/png.latex?%5Cgamma"> is the momentum coefficient</p>
</section>
<section id="nesterov-accelerated-gradient-nag" class="level3">
<h3 class="anchored" data-anchor-id="nesterov-accelerated-gradient-nag">3. Nesterov Accelerated Gradient (NAG)</h3>
<p>Looks ahead for gradient computation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Av_%7Bt+1%7D%20&amp;=%20%5Cgamma%20v_t%20+%20%5Ceta%20%5Cnabla_%5Ctheta%20J(%5Ctheta_t%20+%20%5Cgamma%20v_t)%20%5C%5C%0A%5Ctheta_%7Bt+1%7D%20&amp;=%20%5Ctheta_t%20-%20v_%7Bt+1%7D%0A%5Cend%7Baligned%7D%0A"></p>
</section>
</section>
<section id="adaptive-methods" class="level2">
<h2 class="anchored" data-anchor-id="adaptive-methods">Adaptive Methods</h2>
<section id="adagrad" class="level3">
<h3 class="anchored" data-anchor-id="adagrad">1. AdaGrad</h3>
<p>Adapts learning rates per parameter:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_%7Bt+1%7D%20=%20%5Ctheta_t%20-%20%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7BG_t%20+%20%5Cepsilon%7D%7D%20%5Codot%20g_t%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?G_t"> is the sum of squared gradients up to time t - <img src="https://latex.codecogs.com/png.latex?g_t"> is the current gradient - <img src="https://latex.codecogs.com/png.latex?%5Codot"> represents element-wise multiplication</p>
</section>
<section id="rmsprop" class="level3">
<h3 class="anchored" data-anchor-id="rmsprop">2. RMSprop</h3>
<p>Exponentially decaying average of squared gradients:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0AG_t%20&amp;=%20%5Cgamma%20G_%7Bt-1%7D%20+%20(1-%5Cgamma)g_t%5E2%20%5C%5C%0A%5Ctheta_%7Bt+1%7D%20&amp;=%20%5Ctheta_t%20-%20%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7BG_t%20+%20%5Cepsilon%7D%7D%20%5Codot%20g_t%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="adam" class="level3">
<h3 class="anchored" data-anchor-id="adam">3. Adam</h3>
<p>Combines momentum and adaptive learning rates:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Am_t%20&amp;=%20%5Cbeta_1%20m_%7Bt-1%7D%20+%20(1-%5Cbeta_1)g_t%20%5C%5C%0Av_t%20&amp;=%20%5Cbeta_2%20v_%7Bt-1%7D%20+%20(1-%5Cbeta_2)g_t%5E2%20%5C%5C%0A%5Chat%7Bm%7D_t%20&amp;=%20%5Cfrac%7Bm_t%7D%7B1-%5Cbeta_1%5Et%7D%20%5C%5C%0A%5Chat%7Bv%7D_t%20&amp;=%20%5Cfrac%7Bv_t%7D%7B1-%5Cbeta_2%5Et%7D%20%5C%5C%0A%5Ctheta_%7Bt+1%7D%20&amp;=%20%5Ctheta_t%20-%20%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Chat%7Bv%7D_t%7D%20+%20%5Cepsilon%7D%20%5Codot%20%5Chat%7Bm%7D_t%0A%5Cend%7Baligned%7D%0A"></p>
</section>
</section>
<section id="second-order-methods" class="level2">
<h2 class="anchored" data-anchor-id="second-order-methods">Second-Order Methods</h2>
<section id="newtons-method" class="level3">
<h3 class="anchored" data-anchor-id="newtons-method">1. Newton’s Method</h3>
<p>Update rule using Hessian:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_%7Bt+1%7D%20=%20%5Ctheta_t%20-%20%5Ceta%20H%5E%7B-1%7D%5Cnabla_%5Ctheta%20J(%5Ctheta_t)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?H"> is the Hessian matrix of second derivatives</p>
</section>
<section id="quasi-newton-methods-bfgs" class="level3">
<h3 class="anchored" data-anchor-id="quasi-newton-methods-bfgs">2. Quasi-Newton Methods (BFGS)</h3>
<p>Approximates Hessian inverse:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0As_k%20&amp;=%20%5Ctheta_%7Bk+1%7D%20-%20%5Ctheta_k%20%5C%5C%0Ay_k%20&amp;=%20%5Cnabla%20J(%5Ctheta_%7Bk+1%7D)%20-%20%5Cnabla%20J(%5Ctheta_k)%20%5C%5C%0AB_%7Bk+1%7D%20&amp;=%20B_k%20+%20%5Cfrac%7By_ky_k%5ET%7D%7By_k%5ETs_k%7D%20-%20%5Cfrac%7BB_ks_ks_k%5ETB_k%7D%7Bs_k%5ETB_ks_k%7D%0A%5Cend%7Baligned%7D%0A"></p>
</section>
</section>
<section id="implementation-considerations" class="level2">
<h2 class="anchored" data-anchor-id="implementation-considerations">Implementation Considerations</h2>
<section id="learning-rate-scheduling" class="level3">
<h3 class="anchored" data-anchor-id="learning-rate-scheduling">1. Learning Rate Scheduling</h3>
<p>Common schedules include:</p>
<ol type="1">
<li><p>Step decay: <img src="https://latex.codecogs.com/png.latex?%0A%5Ceta_t%20=%20%5Ceta_0%20%5Cgamma%5E%7B%5Clfloor%20t/k%20%5Crfloor%7D%0A"></p></li>
<li><p>Exponential decay: <img src="https://latex.codecogs.com/png.latex?%0A%5Ceta_t%20=%20%5Ceta_0%20e%5E%7B-kt%7D%0A"></p></li>
<li><p>Cosine annealing: <img src="https://latex.codecogs.com/png.latex?%0A%5Ceta_t%20=%20%5Ceta_%7Bmin%7D%20+%20%5Cfrac%7B1%7D%7B2%7D(%5Ceta_%7Bmax%7D%20-%20%5Ceta_%7Bmin%7D)(1%20+%20%5Ccos(%5Cfrac%7Bt%5Cpi%7D%7BT%7D))%0A"></p></li>
</ol>
</section>
<section id="batch-size-selection" class="level3">
<h3 class="anchored" data-anchor-id="batch-size-selection">2. Batch Size Selection</h3>
<p>The relationship between batch size and learning rate:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ceta_%7Beffective%7D%20=%20%5Ceta%20%5Csqrt%7B%5Cfrac%7Bb%7D%7Bb_%7Bbase%7D%7D%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?b"> is the current batch size - <img src="https://latex.codecogs.com/png.latex?b_%7Bbase%7D"> is the reference batch size</p>
</section>
<section id="gradient-clipping" class="level3">
<h3 class="anchored" data-anchor-id="gradient-clipping">3. Gradient Clipping</h3>
<p>For handling exploding gradients:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ag_t%20=%20%5Cbegin%7Bcases%7D%0Ag_t%20&amp;%20%5Ctext%7Bif%20%7D%20%5C%7Cg_t%5C%7C%20%5Cleq%20c%20%5C%5C%0Ac%5Cfrac%7Bg_t%7D%7B%5C%7Cg_t%5C%7C%7D%20&amp;%20%5Ctext%7Botherwise%7D%0A%5Cend%7Bcases%7D%0A"></p>
</section>
</section>
<section id="advanced-topics" class="level2">
<h2 class="anchored" data-anchor-id="advanced-topics">Advanced Topics</h2>
<section id="natural-gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="natural-gradient-descent">1. Natural Gradient Descent</h3>
<p>Update rule using Fisher Information Matrix:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_%7Bt+1%7D%20=%20%5Ctheta_t%20-%20%5Ceta%20F%5E%7B-1%7D%5Cnabla_%5Ctheta%20J(%5Ctheta_t)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?F"> is the Fisher Information Matrix</p>
</section>
<section id="distributed-optimization" class="level3">
<h3 class="anchored" data-anchor-id="distributed-optimization">2. Distributed Optimization</h3>
<p>For parallel SGD with K workers:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_%7Bt+1%7D%20=%20%5Ctheta_t%20-%20%5Cfrac%7B%5Ceta%7D%7BK%7D%5Csum_%7Bk=1%7D%5EK%20%5Cnabla_%5Ctheta%20J_k(%5Ctheta_t)%0A"></p>
</section>
<section id="stochastic-weight-averaging-swa" class="level3">
<h3 class="anchored" data-anchor-id="stochastic-weight-averaging-swa">3. Stochastic Weight Averaging (SWA)</h3>
<p>Averaging weights along the trajectory:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_%7BSWA%7D%20=%20%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5En%20%5Ctheta_i%0A"></p>
</section>
</section>
<section id="practical-guidelines" class="level2">
<h2 class="anchored" data-anchor-id="practical-guidelines">Practical Guidelines</h2>
<section id="algorithm-selection" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-selection">1. Algorithm Selection</h3>
<ol type="1">
<li>First try Adam with default parameters:
<ul>
<li>Learning rate: <img src="https://latex.codecogs.com/png.latex?10%5E%7B-3%7D"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbeta_1%20=%200.9"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cbeta_2%20=%200.999"></li>
<li><img src="https://latex.codecogs.com/png.latex?%5Cepsilon%20=%2010%5E%7B-8%7D"></li>
</ul></li>
<li>If training is unstable, try:
<ul>
<li>Reducing learning rate</li>
<li>Gradient clipping</li>
<li>Layer normalization</li>
</ul></li>
<li>For fine-tuning, consider:
<ul>
<li>SGD with momentum</li>
<li>Cosine annealing</li>
<li>SWA</li>
</ul></li>
</ol>
</section>
<section id="hyperparameter-tuning" class="level3">
<h3 class="anchored" data-anchor-id="hyperparameter-tuning">2. Hyperparameter Tuning</h3>
<ol type="1">
<li>Learning rate search:
<ul>
<li>Start with logarithmic grid</li>
<li>Use learning rate finder algorithm</li>
</ul></li>
<li>Batch size selection:
<ul>
<li>Start with power of 2</li>
<li>Consider memory constraints</li>
<li>Scale learning rate accordingly</li>
</ul></li>
<li>Momentum tuning:
<ul>
<li>Default: 0.9</li>
<li>Increase for noisy gradients</li>
<li>Decrease for stable training</li>
</ul></li>
</ol>
</section>
</section>
<section id="common-issues-and-solutions" class="level2">
<h2 class="anchored" data-anchor-id="common-issues-and-solutions">Common Issues and Solutions</h2>
<section id="vanishingexploding-gradients" class="level3">
<h3 class="anchored" data-anchor-id="vanishingexploding-gradients">1. Vanishing/Exploding Gradients</h3>
<p>Solutions: 1. Proper initialization: <img src="https://latex.codecogs.com/png.latex?%0AW%20%5Csim%20%5Cmathcal%7BN%7D(0,%20%5Csqrt%7B%5Cfrac%7B2%7D%7Bn_%7Bin%7D%20+%20n_%7Bout%7D%7D%7D)%0A"></p>
<ol start="2" type="1">
<li>Gradient clipping</li>
<li>Layer normalization: <img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7Bx%7D%20=%20%5Cfrac%7Bx%20-%20%5Cmu%7D%7B%5Csqrt%7B%5Csigma%5E2%20+%20%5Cepsilon%7D%7D%0A"></li>
</ol>
</section>
<section id="saddle-points" class="level3">
<h3 class="anchored" data-anchor-id="saddle-points">2. Saddle Points</h3>
<p>Solutions: 1. Add noise to gradients: <img src="https://latex.codecogs.com/png.latex?%0Ag_t%20=%20%5Cnabla_%5Ctheta%20J(%5Ctheta_t)%20+%20%5Cmathcal%7BN%7D(0,%20%5Csigma%5E2)%0A"></p>
<ol start="2" type="1">
<li>Use momentum-based methods</li>
<li>Implement trust region methods</li>
</ol>
</section>
<section id="poor-conditioning" class="level3">
<h3 class="anchored" data-anchor-id="poor-conditioning">3. Poor Conditioning</h3>
<p>Solutions: 1. Preconditioning: <img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_%7Bt+1%7D%20=%20%5Ctheta_t%20-%20%5Ceta%20P%5E%7B-1%7D%5Cnabla_%5Ctheta%20J(%5Ctheta_t)%0A"></p>
<ol start="2" type="1">
<li>Adaptive methods (Adam, RMSprop)</li>
<li>Second-order methods when feasible</li>
</ol>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Key takeaways: 1. Understanding optimization fundamentals is crucial 2. Different algorithms suit different problems 3. Practical considerations often outweigh theoretical guarantees 4. Monitoring and debugging optimization is essential</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Mathematical Foundations:
<ul>
<li>“Convex Optimization” by Boyd and Vandenberghe</li>
<li>“Optimization Methods for Large-Scale Machine Learning” by Bottou et al.</li>
</ul></li>
<li>Implementation Details:
<ul>
<li>“Deep Learning” by Goodfellow et al.</li>
<li>“Adaptive Methods for Machine Learning” by Duchi et al.</li>
</ul></li>
<li>Advanced Topics:
<ul>
<li>“Natural Gradient Works Efficiently in Learning” by Amari</li>
<li>“On the Convergence of Adam and Beyond” by Reddi et al.</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>optimization</category>
  <category>mathematics</category>
  <category>algorithms</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/optimization-algorithms/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/optimization-algorithms/optimization.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Optimization Theory in Machine Learning</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/optimization-theory/</link>
  <description><![CDATA[ 





<section id="optimization-theory-in-machine-learning" class="level1">
<h1>Optimization Theory in Machine Learning</h1>
<section id="convex-analysis" class="level2">
<h2 class="anchored" data-anchor-id="convex-analysis">Convex Analysis</h2>
<section id="convex-sets-and-functions" class="level3">
<h3 class="anchored" data-anchor-id="convex-sets-and-functions">1. Convex Sets and Functions</h3>
<p>Convex set definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta%20x%20+%20(1-%5Ctheta)y%20%5Cin%20C,%20%5Cforall%20x,y%20%5Cin%20C,%20%5Ctheta%20%5Cin%20%5B0,1%5D%0A"></p>
<p>Convex function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(%5Ctheta%20x%20+%20(1-%5Ctheta)y)%20%5Cleq%20%5Ctheta%20f(x)%20+%20(1-%5Ctheta)f(y)%0A"></p>
</section>
<section id="properties" class="level3">
<h3 class="anchored" data-anchor-id="properties">2. Properties</h3>
<p>First-order characterization:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(y)%20%5Cgeq%20f(x)%20+%20%5Cnabla%20f(x)%5ET(y-x)%0A"></p>
<p>Second-order characterization:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla%5E2%20f(x)%20%5Csucceq%200%0A"></p>
</section>
<section id="strong-convexity" class="level3">
<h3 class="anchored" data-anchor-id="strong-convexity">3. Strong Convexity</h3>
<p>Definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(y)%20%5Cgeq%20f(x)%20+%20%5Cnabla%20f(x)%5ET(y-x)%20+%20%5Cfrac%7B%5Cmu%7D%7B2%7D%5C%7Cy-x%5C%7C%5E2%0A"></p>
<p>Quadratic growth:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x)%20-%20f(x%5E*)%20%5Cgeq%20%5Cfrac%7B%5Cmu%7D%7B2%7D%5C%7Cx-x%5E*%5C%7C%5E2%0A"></p>
</section>
</section>
<section id="optimality-conditions" class="level2">
<h2 class="anchored" data-anchor-id="optimality-conditions">Optimality Conditions</h2>
<section id="first-order-conditions" class="level3">
<h3 class="anchored" data-anchor-id="first-order-conditions">1. First-Order Conditions</h3>
<p>Unconstrained:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla%20f(x%5E*)%20=%200%0A"></p>
<p>Constrained (KKT):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cnabla_x%20%5Cmathcal%7BL%7D(x%5E*,%5Clambda%5E*)%20&amp;=%200%20%5C%5C%0Ag_i(x%5E*)%20&amp;%5Cleq%200%20%5C%5C%0A%5Clambda_i%5E*%20g_i(x%5E*)%20&amp;=%200%20%5C%5C%0A%5Clambda_i%5E*%20&amp;%5Cgeq%200%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="second-order-conditions" class="level3">
<h3 class="anchored" data-anchor-id="second-order-conditions">2. Second-Order Conditions</h3>
<p>Unconstrained:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cnabla%5E2%20f(x%5E*)%20%5Csucceq%200%0A"></p>
<p>Constrained:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ay%5ET%5Cnabla%5E2_%7Bxx%7D%5Cmathcal%7BL%7D(x%5E*,%5Clambda%5E*)y%20%5Cgeq%200%0A"></p>
</section>
<section id="saddle-point-conditions" class="level3">
<h3 class="anchored" data-anchor-id="saddle-point-conditions">3. Saddle Point Conditions</h3>
<p>Minimax:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(x%5E*,%5Clambda)%20%5Cleq%20%5Cmathcal%7BL%7D(x%5E*,%5Clambda%5E*)%20%5Cleq%20%5Cmathcal%7BL%7D(x,%5Clambda%5E*)%0A"></p>
<p>Duality gap:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x%5E*)%20-%20g(%5Clambda%5E*)%20=%200%0A"></p>
</section>
</section>
<section id="gradient-methods" class="level2">
<h2 class="anchored" data-anchor-id="gradient-methods">Gradient Methods</h2>
<section id="gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="gradient-descent">1. Gradient Descent</h3>
<p>Update rule:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_%7Bk+1%7D%20=%20x_k%20-%20%5Ceta_k%5Cnabla%20f(x_k)%0A"></p>
<p>Convergence rate (convex):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x_k)%20-%20f(x%5E*)%20%5Cleq%20%5Cfrac%7B%5C%7Cx_0-x%5E*%5C%7C%5E2%7D%7B2%5Ceta%20k%7D%0A"></p>
</section>
<section id="accelerated-methods" class="level3">
<h3 class="anchored" data-anchor-id="accelerated-methods">2. Accelerated Methods</h3>
<p>Nesterov’s acceleration:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Ay_k%20&amp;=%20x_k%20+%20%5Cbeta_k(x_k%20-%20x_%7Bk-1%7D)%20%5C%5C%0Ax_%7Bk+1%7D%20&amp;=%20y_k%20-%20%5Ceta_k%5Cnabla%20f(y_k)%0A%5Cend%7Baligned%7D%0A"></p>
<p>Convergence rate:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x_k)%20-%20f(x%5E*)%20%5Cleq%20%5Cfrac%7B2L%5C%7Cx_0-x%5E*%5C%7C%5E2%7D%7B(k+1)%5E2%7D%0A"></p>
</section>
<section id="stochastic-methods" class="level3">
<h3 class="anchored" data-anchor-id="stochastic-methods">3. Stochastic Methods</h3>
<p>SGD update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_%7Bk+1%7D%20=%20x_k%20-%20%5Ceta_k%5Cnabla%20f_%7Bi_k%7D(x_k)%0A"></p>
<p>Convergence rate:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5Bf(x_k)%20-%20f(x%5E*)%5D%20%5Cleq%20%5Cfrac%7BL%5C%7Cx_0-x%5E*%5C%7C%5E2%7D%7B2k%7D%20+%20%5Cfrac%7BL%5Csigma%5E2%7D%7B2%7D%5Csum_%7Bt=1%7D%5Ek%20%5Ceta_t%5E2%0A"></p>
</section>
</section>
<section id="non-convex-optimization" class="level2">
<h2 class="anchored" data-anchor-id="non-convex-optimization">Non-Convex Optimization</h2>
<section id="local-minima" class="level3">
<h3 class="anchored" data-anchor-id="local-minima">1. Local Minima</h3>
<p>First-order condition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5C%7C%5Cnabla%20f(x%5E*)%5C%7C%20%5Cleq%20%5Cepsilon%0A"></p>
<p>Second-order condition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clambda_%7B%5Cmin%7D(%5Cnabla%5E2%20f(x%5E*))%20%5Cgeq%20-%5Csqrt%7B%5Cepsilon%7D%0A"></p>
</section>
<section id="escape-from-saddle-points" class="level3">
<h3 class="anchored" data-anchor-id="escape-from-saddle-points">2. Escape from Saddle Points</h3>
<p>Perturbed gradient descent:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_%7Bk+1%7D%20=%20x_k%20-%20%5Ceta%5Cnabla%20f(x_k)%20+%20%5Cxi_k%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cxi_k%20%5Csim%20%5Cmathcal%7BN%7D(0,%5Csigma%5E2I)"></p>
</section>
<section id="global-optimization" class="level3">
<h3 class="anchored" data-anchor-id="global-optimization">3. Global Optimization</h3>
<p>Branch and bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BLB%7D(R)%20%5Cleq%20%5Cmin_%7Bx%20%5Cin%20R%7D%20f(x)%20%5Cleq%20%5Ctext%7BUB%7D(R)%0A"></p>
<p>Simulated annealing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Ctext%7Baccept%7D)%20=%20%5Cexp(-%5Cfrac%7B%5CDelta%20E%7D%7BT_k%7D)%0A"></p>
</section>
</section>
<section id="modern-optimization-methods" class="level2">
<h2 class="anchored" data-anchor-id="modern-optimization-methods">Modern Optimization Methods</h2>
<section id="adaptive-methods" class="level3">
<h3 class="anchored" data-anchor-id="adaptive-methods">1. Adaptive Methods</h3>
<p>AdaGrad:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_%7Bt+1,i%7D%20=%20x_%7Bt,i%7D%20-%20%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Csum_%7Bs=1%7D%5Et%20g_%7Bs,i%7D%5E2%7D%7Dg_%7Bt,i%7D%0A"></p>
<p>Adam:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Am_t%20&amp;=%20%5Cbeta_1%20m_%7Bt-1%7D%20+%20(1-%5Cbeta_1)g_t%20%5C%5C%0Av_t%20&amp;=%20%5Cbeta_2%20v_%7Bt-1%7D%20+%20(1-%5Cbeta_2)g_t%5E2%20%5C%5C%0A%5Chat%7Bm%7D_t%20&amp;=%20%5Cfrac%7Bm_t%7D%7B1-%5Cbeta_1%5Et%7D%20%5C%5C%0A%5Chat%7Bv%7D_t%20&amp;=%20%5Cfrac%7Bv_t%7D%7B1-%5Cbeta_2%5Et%7D%20%5C%5C%0Ax_%7Bt+1%7D%20&amp;=%20x_t%20-%20%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Chat%7Bv%7D_t%7D%20+%20%5Cepsilon%7D%5Chat%7Bm%7D_t%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="natural-gradient" class="level3">
<h3 class="anchored" data-anchor-id="natural-gradient">2. Natural Gradient</h3>
<p>Fisher information:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AF(x)%20=%20%5Cmathbb%7BE%7D_%7Bp(y%7Cx)%7D%5B%5Cnabla%20%5Clog%20p(y%7Cx)%5Cnabla%20%5Clog%20p(y%7Cx)%5ET%5D%0A"></p>
<p>Update rule:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_%7Bk+1%7D%20=%20x_k%20-%20%5Ceta%20F(x_k)%5E%7B-1%7D%5Cnabla%20f(x_k)%0A"></p>
</section>
<section id="second-order-methods" class="level3">
<h3 class="anchored" data-anchor-id="second-order-methods">3. Second-Order Methods</h3>
<p>Newton’s method:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_%7Bk+1%7D%20=%20x_k%20-%20%5B%5Cnabla%5E2%20f(x_k)%5D%5E%7B-1%7D%5Cnabla%20f(x_k)%0A"></p>
<p>BFGS update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AB_%7Bk+1%7D%20=%20B_k%20+%20%5Cfrac%7By_ky_k%5ET%7D%7By_k%5ETs_k%7D%20-%20%5Cfrac%7BB_ks_ks_k%5ETB_k%7D%7Bs_k%5ETB_ks_k%7D%0A"></p>
</section>
</section>
<section id="constrained-optimization" class="level2">
<h2 class="anchored" data-anchor-id="constrained-optimization">Constrained Optimization</h2>
<section id="projected-gradient" class="level3">
<h3 class="anchored" data-anchor-id="projected-gradient">1. Projected Gradient</h3>
<p>Update rule:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_%7Bk+1%7D%20=%20%5CPi_C(x_k%20-%20%5Ceta_k%5Cnabla%20f(x_k))%0A"></p>
<p>Convergence rate:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Af(x_k)%20-%20f(x%5E*)%20%5Cleq%20%5Cfrac%7B%5C%7Cx_0-x%5E*%5C%7C%5E2%7D%7B2%5Ceta%20k%7D%0A"></p>
</section>
<section id="proximal-methods" class="level3">
<h3 class="anchored" data-anchor-id="proximal-methods">2. Proximal Methods</h3>
<p>Proximal operator:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bprox%7D_%7B%5Ceta%20g%7D(x)%20=%20%5Carg%5Cmin_y%20%5C%7Bg(y)%20+%20%5Cfrac%7B1%7D%7B2%5Ceta%7D%5C%7Cy-x%5C%7C%5E2%5C%7D%0A"></p>
<p>ISTA update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_%7Bk+1%7D%20=%20%5Ctext%7Bprox%7D_%7B%5Ceta%20g%7D(x_k%20-%20%5Ceta%5Cnabla%20f(x_k))%0A"></p>
</section>
<section id="augmented-lagrangian" class="level3">
<h3 class="anchored" data-anchor-id="augmented-lagrangian">3. Augmented Lagrangian</h3>
<p>Function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D_%5Crho(x,%5Clambda)%20=%20f(x)%20+%20%5Clambda%5ETg(x)%20+%20%5Cfrac%7B%5Crho%7D%7B2%7D%5C%7Cg(x)%5C%7C%5E2%0A"></p>
<p>Update rules:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Ax_%7Bk+1%7D%20&amp;=%20%5Carg%5Cmin_x%20%5Cmathcal%7BL%7D_%5Crho(x,%5Clambda_k)%20%5C%5C%0A%5Clambda_%7Bk+1%7D%20&amp;=%20%5Clambda_k%20+%20%5Crho%20g(x_%7Bk+1%7D)%0A%5Cend%7Baligned%7D%0A"></p>
</section>
</section>
<section id="advanced-topics" class="level2">
<h2 class="anchored" data-anchor-id="advanced-topics">Advanced Topics</h2>
<section id="distributed-optimization" class="level3">
<h3 class="anchored" data-anchor-id="distributed-optimization">1. Distributed Optimization</h3>
<p>ADMM algorithm:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0Ax_%7Bk+1%7D%20&amp;=%20%5Carg%5Cmin_x%20%5Cmathcal%7BL%7D_%5Crho(x,z_k,y_k)%20%5C%5C%0Az_%7Bk+1%7D%20&amp;=%20%5Carg%5Cmin_z%20%5Cmathcal%7BL%7D_%5Crho(x_%7Bk+1%7D,z,y_k)%20%5C%5C%0Ay_%7Bk+1%7D%20&amp;=%20y_k%20+%20%5Crho(Ax_%7Bk+1%7D%20+%20Bz_%7Bk+1%7D%20-%20c)%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="online-optimization" class="level3">
<h3 class="anchored" data-anchor-id="online-optimization">2. Online Optimization</h3>
<p>Regret bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR_T%20%5Cleq%20O(%5Csqrt%7BT%7D)%0A"></p>
<p>Follow-the-regularized-leader:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_%7Bt+1%7D%20=%20%5Carg%5Cmin_x%20%5C%7B%5Ceta%5Csum_%7Bs=1%7D%5Et%20%5Cell_s(x)%20+%20R(x)%5C%7D%0A"></p>
</section>
<section id="zeroth-order-optimization" class="level3">
<h3 class="anchored" data-anchor-id="zeroth-order-optimization">3. Zeroth-Order Optimization</h3>
<p>Gradient estimation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Cnabla%7D%20f(x)%20=%20%5Cfrac%7Bd%7D%7Br%7Df(x+r%5Cxi)%5Cxi%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cxi%20%5Csim%20%5Ctext%7BUnif%7D(%5Cmathbb%7BS%7D%5E%7Bd-1%7D)"></p>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="algorithm-selection" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-selection">1. Algorithm Selection</h3>
<ol type="1">
<li>Problem Structure:
<ul>
<li>Convexity</li>
<li>Smoothness</li>
<li>Constraints</li>
</ul></li>
<li>Data Properties:
<ul>
<li>Size</li>
<li>Dimensionality</li>
<li>Sparsity</li>
</ul></li>
<li>Computational Resources:
<ul>
<li>Memory</li>
<li>Processing power</li>
<li>Time constraints</li>
</ul></li>
</ol>
</section>
<section id="implementation" class="level3">
<h3 class="anchored" data-anchor-id="implementation">2. Implementation</h3>
<ol type="1">
<li>Initialization:
<ul>
<li>Parameter scaling</li>
<li>Random seeding</li>
<li>Warm start</li>
</ul></li>
<li>Monitoring:
<ul>
<li>Convergence</li>
<li>Stability</li>
<li>Resource usage</li>
</ul></li>
<li>Tuning:
<ul>
<li>Learning rates</li>
<li>Momentum</li>
<li>Regularization</li>
</ul></li>
</ol>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Theory:
<ul>
<li>“Convex Optimization” by Boyd and Vandenberghe</li>
<li>“Introductory Lectures on Convex Optimization” by Nesterov</li>
<li>“Optimization Methods for Large-Scale Machine Learning” by Bottou et al.</li>
</ul></li>
<li>Methods:
<ul>
<li>“Numerical Optimization” by Nocedal and Wright</li>
<li>“First-Order Methods in Optimization” by Beck</li>
<li>“Proximal Algorithms” by Parikh and Boyd</li>
</ul></li>
<li>Applications:
<ul>
<li>“Deep Learning” by Goodfellow et al.</li>
<li>“Optimization for Machine Learning” by Sra et al.</li>
<li>“Large Scale Optimization in Machine Learning” by Shalev-Shwartz and Zhang</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>optimization</category>
  <category>mathematics</category>
  <category>theory</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/optimization-theory/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/optimization-theory/optimization_theory.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>PAC Learning Theory and VC Dimension</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/pac-learning-theory/</link>
  <description><![CDATA[ 





<section id="pac-learning-theory-and-vc-dimension" class="level1">
<h1>PAC Learning Theory and VC Dimension</h1>
<section id="pac-learning-framework" class="level2">
<h2 class="anchored" data-anchor-id="pac-learning-framework">PAC Learning Framework</h2>
<section id="basic-definitions" class="level3">
<h3 class="anchored" data-anchor-id="basic-definitions">1. Basic Definitions</h3>
<p>PAC learning definition: - Hypothesis class <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BH%7D"> - Instance space <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BX%7D"> - Target concept <img src="https://latex.codecogs.com/png.latex?c:%20%5Cmathcal%7BX%7D%20%5Cto%20%5C%7B0,1%5C%7D"> - Distribution <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BD%7D"> over <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BX%7D"></p>
<p>PAC requirements:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP_%7BS%20%5Csim%20%5Cmathcal%7BD%7D%5Em%7D(%5Ctext%7Berror%7D_%5Cmathcal%7BD%7D(h_S)%20%5Cleq%20%5Cepsilon)%20%5Cgeq%201-%5Cdelta%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> is accuracy parameter - <img src="https://latex.codecogs.com/png.latex?%5Cdelta"> is confidence parameter - <img src="https://latex.codecogs.com/png.latex?m"> is sample size - <img src="https://latex.codecogs.com/png.latex?h_S"> is learned hypothesis</p>
</section>
<section id="sample-complexity" class="level3">
<h3 class="anchored" data-anchor-id="sample-complexity">2. Sample Complexity</h3>
<p>Fundamental bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Am%20%5Cgeq%20%5Cfrac%7B1%7D%7B%5Cepsilon%7D%5Cleft(%5Cln%7C%5Cmathcal%7BH%7D%7C%20+%20%5Cln%5Cfrac%7B1%7D%7B%5Cdelta%7D%5Cright)%0A"></p>
<p>Realizable case:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Am%20%5Cgeq%20%5Cfrac%7B1%7D%7B%5Cepsilon%7D%5Cleft(%5Cln%5Cfrac%7B1%7D%7B%5Cdelta%7D%5Cright)%0A"></p>
</section>
<section id="agnostic-pac-learning" class="level3">
<h3 class="anchored" data-anchor-id="agnostic-pac-learning">3. Agnostic PAC Learning</h3>
<p>Error bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Berror%7D_%5Cmathcal%7BD%7D(h)%20%5Cleq%20%5Cmin_%7Bh'%20%5Cin%20%5Cmathcal%7BH%7D%7D%5Ctext%7Berror%7D_%5Cmathcal%7BD%7D(h')%20+%20%5Cepsilon%0A"></p>
<p>Sample complexity:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Am%20%5Cgeq%20%5Cfrac%7B2%7D%7B%5Cepsilon%5E2%7D%5Cleft(%5Cln%7C%5Cmathcal%7BH%7D%7C%20+%20%5Cln%5Cfrac%7B2%7D%7B%5Cdelta%7D%5Cright)%0A"></p>
</section>
</section>
<section id="vc-theory" class="level2">
<h2 class="anchored" data-anchor-id="vc-theory">VC Theory</h2>
<section id="vc-dimension" class="level3">
<h3 class="anchored" data-anchor-id="vc-dimension">1. VC Dimension</h3>
<p>Growth function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5CPi_%5Cmathcal%7BH%7D(m)%20=%20%5Cmax_%7Bx_1,...,x_m%20%5Cin%20%5Cmathcal%7BX%7D%7D%7C%5C%7B(h(x_1),...,h(x_m)):%20h%20%5Cin%20%5Cmathcal%7BH%7D%5C%7D%7C%0A"></p>
<p>Sauer’s Lemma:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BIf%20VC%7D(%5Cmathcal%7BH%7D)%20=%20d,%20%5Ctext%7B%20then%20%7D%20%5CPi_%5Cmathcal%7BH%7D(m)%20%5Cleq%20%5Csum_%7Bi=0%7D%5Ed%20%5Cbinom%7Bm%7D%7Bi%7D%0A"></p>
</section>
<section id="vc-generalization-bounds" class="level3">
<h3 class="anchored" data-anchor-id="vc-generalization-bounds">2. VC Generalization Bounds</h3>
<p>Fundamental theorem:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%7C%5Ctext%7Berror%7D_%5Cmathcal%7BD%7D(h)%20-%20%5Cwidehat%7B%5Ctext%7Berror%7D%7D_S(h)%7C%20%3E%20%5Cepsilon)%20%5Cleq%204%5CPi_%5Cmathcal%7BH%7D(2m)%5Cexp(-%5Cfrac%7Bm%5Cepsilon%5E2%7D%7B8%7D)%0A"></p>
<p>Sample complexity:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Am%20=%20O%5Cleft(%5Cfrac%7Bd%7D%7B%5Cepsilon%5E2%7D%5Cln%5Cfrac%7B1%7D%7B%5Cepsilon%7D%20+%20%5Cfrac%7B1%7D%7B%5Cepsilon%5E2%7D%5Cln%5Cfrac%7B1%7D%7B%5Cdelta%7D%5Cright)%0A"></p>
</section>
<section id="rademacher-complexity" class="level3">
<h3 class="anchored" data-anchor-id="rademacher-complexity">3. Rademacher Complexity</h3>
<p>Definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathfrak%7BR%7D_S(%5Cmathcal%7BH%7D)%20=%20%5Cmathbb%7BE%7D_%5Csigma%5Cleft%5B%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi=1%7D%5Em%20%5Csigma_i%20h(x_i)%5Cright%5D%0A"></p>
<p>Generalization bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%7C%5Ctext%7Berror%7D_%5Cmathcal%7BD%7D(h)%20-%20%5Cwidehat%7B%5Ctext%7Berror%7D%7D_S(h)%7C%20%5Cleq%202%5Cmathfrak%7BR%7D_m(%5Cmathcal%7BH%7D)%20+%20%5Csqrt%7B%5Cfrac%7B2%5Cln(2/%5Cdelta)%7D%7Bm%7D%7D)%20%5Cgeq%201-%5Cdelta%0A"></p>
</section>
</section>
<section id="advanced-pac-concepts" class="level2">
<h2 class="anchored" data-anchor-id="advanced-pac-concepts">Advanced PAC Concepts</h2>
<section id="sample-compression" class="level3">
<h3 class="anchored" data-anchor-id="sample-compression">1. Sample Compression</h3>
<p>Compression scheme:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ckappa:%20%5Ccup_%7Bm=1%7D%5E%5Cinfty%20(%5Cmathcal%7BX%7D%20%5Ctimes%20%5C%7B0,1%5C%7D)%5Em%20%5Cto%20%5Ccup_%7Bi=1%7D%5Ek%20(%5Cmathcal%7BX%7D%20%5Ctimes%20%5C%7B0,1%5C%7D)%5Ei%0A"></p>
<p>Bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Am%20%5Cgeq%20O%5Cleft(%5Cfrac%7Bk%7D%7B%5Cepsilon%7D%5Clog%5Cfrac%7B1%7D%7B%5Cepsilon%7D%20+%20%5Cfrac%7B1%7D%7B%5Cepsilon%7D%5Clog%5Cfrac%7B1%7D%7B%5Cdelta%7D%5Cright)%0A"></p>
</section>
<section id="boosting-in-pac-framework" class="level3">
<h3 class="anchored" data-anchor-id="boosting-in-pac-framework">2. Boosting in PAC Framework</h3>
<p>Weak learning condition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Ctext%7Berror%7D_%5Cmathcal%7BD%7D(h)%20%5Cleq%20%5Cfrac%7B1%7D%7B2%7D%20-%20%5Cgamma)%20%5Cgeq%201-%5Cdelta%0A"></p>
<p>Strong learning guarantee:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Ctext%7Berror%7D_%5Cmathcal%7BD%7D(H)%20%5Cleq%20%5Cepsilon)%20%5Cgeq%201-%5Cdelta%0A"></p>
</section>
<section id="online-learning" class="level3">
<h3 class="anchored" data-anchor-id="online-learning">3. Online Learning</h3>
<p>Mistake bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AM%20%5Cleq%20O%5Cleft(%5Cfrac%7Bd%7D%7B%5Cgamma%5E2%7D%5Clog%5Cfrac%7B1%7D%7B%5Cgamma%7D%5Cright)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?M"> is number of mistakes - <img src="https://latex.codecogs.com/png.latex?d"> is VC dimension - <img src="https://latex.codecogs.com/png.latex?%5Cgamma"> is margin</p>
</section>
</section>
<section id="learnability-analysis" class="level2">
<h2 class="anchored" data-anchor-id="learnability-analysis">Learnability Analysis</h2>
<section id="consistency" class="level3">
<h3 class="anchored" data-anchor-id="consistency">1. Consistency</h3>
<p>Empirical Risk Minimization (ERM):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ah_S%20=%20%5Carg%5Cmin_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%5Cwidehat%7B%5Ctext%7Berror%7D%7D_S(h)%0A"></p>
<p>Consistency condition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clim_%7Bm%20%5Cto%20%5Cinfty%7DP(%5Ctext%7Berror%7D_%5Cmathcal%7BD%7D(h_S)%20%3E%20%5Cinf_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%5Ctext%7Berror%7D_%5Cmathcal%7BD%7D(h)%20+%20%5Cepsilon)%20=%200%0A"></p>
</section>
<section id="uniform-convergence" class="level3">
<h3 class="anchored" data-anchor-id="uniform-convergence">2. Uniform Convergence</h3>
<p>Double sampling:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP_%7BS,S'%7D(%7C%5Cwidehat%7B%5Ctext%7Berror%7D%7D_S(h)%20-%20%5Cwidehat%7B%5Ctext%7Berror%7D%7D_%7BS'%7D(h)%7C%20%3E%20%5Cepsilon)%20%5Cleq%20%5Cdelta%0A"></p>
<p>Symmetrization bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%7C%5Ctext%7Berror%7D_%5Cmathcal%7BD%7D(h)%20-%20%5Cwidehat%7B%5Ctext%7Berror%7D%7D_S(h)%7C%20%3E%202%5Cepsilon)%20%5Cleq%202P(%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%7C%5Cwidehat%7B%5Ctext%7Berror%7D%7D_S(h)%20-%20%5Cwidehat%7B%5Ctext%7Berror%7D%7D_%7BS'%7D(h)%7C%20%3E%20%5Cepsilon)%0A"></p>
</section>
<section id="structural-risk-minimization" class="level3">
<h3 class="anchored" data-anchor-id="structural-risk-minimization">3. Structural Risk Minimization</h3>
<p>Nested hypothesis classes:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BH%7D_1%20%5Csubset%20%5Cmathcal%7BH%7D_2%20%5Csubset%20...%20%5Csubset%20%5Cmathcal%7BH%7D_k%0A"></p>
<p>Penalty term:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7Bpen%7D(h)%20=%20%5Csqrt%7B%5Cfrac%7B%5Ctext%7BVC%7D(%5Cmathcal%7BH%7D(h))%5Cln(em/%5Ctext%7BVC%7D(%5Cmathcal%7BH%7D(h)))%20+%20%5Cln(1/%5Cdelta)%7D%7Bm%7D%7D%0A"></p>
</section>
</section>
<section id="advanced-bounds" class="level2">
<h2 class="anchored" data-anchor-id="advanced-bounds">Advanced Bounds</h2>
<section id="local-rademacher-complexity" class="level3">
<h3 class="anchored" data-anchor-id="local-rademacher-complexity">1. Local Rademacher Complexity</h3>
<p>Local complexity:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathfrak%7BR%7D_S(%5Cmathcal%7BH%7D,%20r)%20=%20%5Cmathbb%7BE%7D_%5Csigma%5Cleft%5B%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D:%20%5Cwidehat%7B%5Ctext%7Berror%7D%7D_S(h)%20%5Cleq%20r%7D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi=1%7D%5Em%20%5Csigma_i%20h(x_i)%5Cright%5D%0A"></p>
<p>Fixed point equation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ar%5E*%20=%20%5Cinf%5C%7Br%20%3E%200:%20%5Cmathfrak%7BR%7D_S(%5Cmathcal%7BH%7D,%20r)%20%5Cleq%20r/4%5C%7D%0A"></p>
</section>
<section id="margin-based-bounds" class="level3">
<h3 class="anchored" data-anchor-id="margin-based-bounds">2. Margin-Based Bounds</h3>
<p>Margin loss:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cell_%5Cgamma(yf(x))%20=%20%5Cbegin%7Bcases%7D%0A1%20&amp;%20%5Ctext%7Bif%20%7D%20yf(x)%20%5Cleq%200%20%5C%5C%0A1-%5Cfrac%7Byf(x)%7D%7B%5Cgamma%7D%20&amp;%20%5Ctext%7Bif%20%7D%200%20%3C%20yf(x)%20%5Cleq%20%5Cgamma%20%5C%5C%0A0%20&amp;%20%5Ctext%7Bif%20%7D%20yf(x)%20%3E%20%5Cgamma%0A%5Cend%7Bcases%7D%0A"></p>
<p>Margin bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Ctext%7Berror%7D_%5Cmathcal%7BD%7D(h)%20%5Cleq%20%5Cwidehat%7B%5Ctext%7Berror%7D%7D_%5Cgamma(h)%20+%20O(%5Csqrt%7B%5Cfrac%7Bd%5Cln(1/%5Cgamma)%7D%7Bm%5Cgamma%5E2%7D%7D))%20%5Cgeq%201-%5Cdelta%0A"></p>
</section>
<section id="stability-based-bounds" class="level3">
<h3 class="anchored" data-anchor-id="stability-based-bounds">3. Stability-Based Bounds</h3>
<p>Uniform stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Csup_%7BS,z,i%7D%7C%5Cell(A_S,z)%20-%20%5Cell(A_%7BS%5Ei%7D,z)%7C%20%5Cleq%20%5Cbeta%0A"></p>
<p>Generalization bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%7C%5Ctext%7Berror%7D_%5Cmathcal%7BD%7D(A_S)%20-%20%5Cwidehat%7B%5Ctext%7Berror%7D%7D_S(A_S)%7C%20%5Cleq%20%5Cepsilon)%20%5Cgeq%201-2%5Cexp(-%5Cfrac%7Bm%5Cepsilon%5E2%7D%7B2%5Cbeta%5E2%7D)%0A"></p>
</section>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">Applications</h2>
<section id="linear-classification" class="level3">
<h3 class="anchored" data-anchor-id="linear-classification">1. Linear Classification</h3>
<p>VC dimension: - Hyperplanes in <img src="https://latex.codecogs.com/png.latex?%5Cmathbb%7BR%7D%5Ed">: <img src="https://latex.codecogs.com/png.latex?d+1"> - Homogeneous hyperplanes: <img src="https://latex.codecogs.com/png.latex?d"></p>
<p>Sample complexity:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Am%20=%20O%5Cleft(%5Cfrac%7Bd%7D%7B%5Cepsilon%7D%5Cln%5Cfrac%7B1%7D%7B%5Cepsilon%7D%20+%20%5Cfrac%7B1%7D%7B%5Cepsilon%7D%5Cln%5Cfrac%7B1%7D%7B%5Cdelta%7D%5Cright)%0A"></p>
</section>
<section id="neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="neural-networks">2. Neural Networks</h3>
<p>VC dimension bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BVC%7D(%5Ctext%7BNN%7D)%20%5Cleq%20O(WL%5Clog%20W)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?W"> is number of weights - <img src="https://latex.codecogs.com/png.latex?L"> is number of layers</p>
</section>
<section id="kernel-methods" class="level3">
<h3 class="anchored" data-anchor-id="kernel-methods">3. Kernel Methods</h3>
<p>Effective dimension:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ad_%5Ctext%7Beff%7D(%5Clambda)%20=%20%5Ctext%7Btr%7D(K(K+%5Clambda%20mI)%5E%7B-1%7D)%0A"></p>
<p>Sample complexity:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Am%20=%20O%5Cleft(%5Cfrac%7Bd_%5Ctext%7Beff%7D(%5Clambda)%7D%7B%5Cepsilon%5E2%7D%20+%20%5Cfrac%7B%5Clog(1/%5Cdelta)%7D%7B%5Cepsilon%5E2%7D%5Cright)%0A"></p>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="model-selection" class="level3">
<h3 class="anchored" data-anchor-id="model-selection">1. Model Selection</h3>
<ol type="1">
<li>Complexity Control:
<ul>
<li>VC dimension analysis</li>
<li>Rademacher complexity</li>
<li>Stability measures</li>
</ul></li>
<li>Regularization:
<ul>
<li>Theoretical guarantees</li>
<li>Sample complexity</li>
<li>Generalization bounds</li>
</ul></li>
<li>Validation:
<ul>
<li>PAC bounds</li>
<li>Cross-validation theory</li>
<li>Hold-out guarantees</li>
</ul></li>
</ol>
</section>
<section id="algorithm-design" class="level3">
<h3 class="anchored" data-anchor-id="algorithm-design">2. Algorithm Design</h3>
<ol type="1">
<li>Learning Rate:
<ul>
<li>Sample complexity analysis</li>
<li>Convergence guarantees</li>
<li>Stability considerations</li>
</ul></li>
<li>Architecture:
<ul>
<li>VC dimension bounds</li>
<li>Capacity control</li>
<li>Expressivity analysis</li>
</ul></li>
<li>Optimization:
<ul>
<li>Generalization bounds</li>
<li>Stability analysis</li>
<li>Convergence rates</li>
</ul></li>
</ol>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Theory:
<ul>
<li>“A Theory of the Learnable” by Valiant</li>
<li>“Foundations of Machine Learning” by Mohri et al.</li>
<li>“Understanding Machine Learning” by Shalev-Shwartz and Ben-David</li>
</ul></li>
<li>Advanced Topics:
<ul>
<li>“Statistical Learning Theory” by Vapnik</li>
<li>“The Nature of Statistical Learning Theory” by Vapnik</li>
<li>“Learning from Data” by Abu-Mostafa et al.</li>
</ul></li>
<li>Applications:
<ul>
<li>“Neural Network Learning” by Anthony and Bartlett</li>
<li>“Kernel Methods in Machine Learning” by Hofmann et al.</li>
<li>“Theory of Classification” by Devroye et al.</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>theory</category>
  <category>mathematics</category>
  <category>statistics</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/pac-learning-theory/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/pac-learning-theory/pac_learning.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Probabilistic Graphical Models: Mathematical Foundations</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/probabilistic-graphical-models/</link>
  <description><![CDATA[ 





<section id="probabilistic-graphical-models" class="level1">
<h1>Probabilistic Graphical Models</h1>
<section id="bayesian-networks" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-networks">Bayesian Networks</h2>
<section id="factorization" class="level3">
<h3 class="anchored" data-anchor-id="factorization">1. Factorization</h3>
<p>Joint probability factorization:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(X_1,%20...,%20X_n)%20=%20%5Cprod_%7Bi=1%7D%5En%20P(X_i%20%7C%20%5Ctext%7BPa%7D(X_i))%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?X_i"> are random variables - <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BPa%7D(X_i)"> are parents of <img src="https://latex.codecogs.com/png.latex?X_i"> in the graph</p>
</section>
<section id="conditional-independence" class="level3">
<h3 class="anchored" data-anchor-id="conditional-independence">2. Conditional Independence</h3>
<p>D-separation criterion: - Two nodes are d-separated if all paths between them are blocked - A path is blocked if: * Contains a collider not in evidence * Contains a non-collider in evidence</p>
<p>Formal definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AX%20%5Cperp%5C!%5C!%5C!%5Cperp%20Y%20%7C%20Z%20%5Ciff%20P(X%7CY,Z)%20=%20P(X%7CZ)%0A"></p>
</section>
</section>
<section id="markov-random-fields" class="level2">
<h2 class="anchored" data-anchor-id="markov-random-fields">Markov Random Fields</h2>
<section id="gibbs-distribution" class="level3">
<h3 class="anchored" data-anchor-id="gibbs-distribution">1. Gibbs Distribution</h3>
<p>Joint distribution representation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(X%20=%20x)%20=%20%5Cfrac%7B1%7D%7BZ%7D%5Cexp%5Cleft(-%5Csum_%7Bc%20%5Cin%20%5Cmathcal%7BC%7D%7D%20%5Cpsi_c(x_c)%5Cright)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BC%7D"> is the set of cliques - <img src="https://latex.codecogs.com/png.latex?%5Cpsi_c"> are potential functions - <img src="https://latex.codecogs.com/png.latex?Z"> is the partition function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AZ%20=%20%5Csum_x%20%5Cexp%5Cleft(-%5Csum_%7Bc%20%5Cin%20%5Cmathcal%7BC%7D%7D%20%5Cpsi_c(x_c)%5Cright)%0A"></p>
</section>
<section id="hammersley-clifford-theorem" class="level3">
<h3 class="anchored" data-anchor-id="hammersley-clifford-theorem">2. Hammersley-Clifford Theorem</h3>
<p>Equivalence between positive distributions and Gibbs distributions:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(X%20=%20x)%20%3E%200%20%5Ciff%20P(X%20=%20x)%20=%20%5Cfrac%7B1%7D%7BZ%7D%5Cprod_%7Bc%20%5Cin%20%5Cmathcal%7BC%7D%7D%20%5Cphi_c(x_c)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cphi_c"> are non-negative factors</p>
</section>
</section>
<section id="inference-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="inference-algorithms">Inference Algorithms</h2>
<section id="variable-elimination" class="level3">
<h3 class="anchored" data-anchor-id="variable-elimination">1. Variable Elimination</h3>
<p>Complexity for tree-structured graphs:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AO(n%20%5Ccdot%20d%5E%7Bw%7D)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?n"> is number of variables - <img src="https://latex.codecogs.com/png.latex?d"> is domain size - <img src="https://latex.codecogs.com/png.latex?w"> is tree width</p>
<p>Algorithm steps: 1. Choose elimination ordering 2. For each variable: - Multiply relevant factors - Sum out variable</p>
</section>
<section id="belief-propagation" class="level3">
<h3 class="anchored" data-anchor-id="belief-propagation">2. Belief Propagation</h3>
<p>Message passing equations:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Cmu_%7Bi%20%5Cto%20j%7D(x_j)%20&amp;=%20%5Csum_%7Bx_i%7D%20%5Cphi_i(x_i)%5Cphi_%7Bij%7D(x_i,x_j)%5Cprod_%7Bk%20%5Cin%20N(i)%5Cbackslash%20j%7D%20%5Cmu_%7Bk%20%5Cto%20i%7D(x_i)%20%5C%5C%0Ab_i(x_i)%20&amp;%5Cpropto%20%5Cphi_i(x_i)%5Cprod_%7Bj%20%5Cin%20N(i)%7D%20%5Cmu_%7Bj%20%5Cto%20i%7D(x_i)%0A%5Cend%7Baligned%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cmu_%7Bi%20%5Cto%20j%7D"> is message from i to j - <img src="https://latex.codecogs.com/png.latex?b_i"> is belief at node i - <img src="https://latex.codecogs.com/png.latex?N(i)"> is neighbors of i</p>
</section>
<section id="junction-tree-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="junction-tree-algorithm">3. Junction Tree Algorithm</h3>
<p>Clique tree construction: 1. Moralize graph 2. Triangulate 3. Find maximal cliques 4. Build junction tree</p>
<p>Running intersection property:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS_%7Bij%7D%20=%20C_i%20%5Ccap%20C_j%20%5Csubseteq%20C_k%0A"></p>
<p>For any cliques <img src="https://latex.codecogs.com/png.latex?C_i">, <img src="https://latex.codecogs.com/png.latex?C_j">, and clique <img src="https://latex.codecogs.com/png.latex?C_k"> on path between them.</p>
</section>
</section>
<section id="learning-methods" class="level2">
<h2 class="anchored" data-anchor-id="learning-methods">Learning Methods</h2>
<section id="maximum-likelihood-estimation" class="level3">
<h3 class="anchored" data-anchor-id="maximum-likelihood-estimation">1. Maximum Likelihood Estimation</h3>
<p>Objective function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Ctheta%7D_%7BMLE%7D%20=%20%5Carg%5Cmax_%5Ctheta%20%5Csum_%7Bi=1%7D%5EN%20%5Clog%20P(x%5E%7B(i)%7D%7C%5Ctheta)%0A"></p>
<p>For complete data in Bayesian networks:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Chat%7B%5Ctheta%7D_%7Bijk%7D%20=%20%5Cfrac%7BN_%7Bijk%7D%7D%7B%5Csum_k%20N_%7Bijk%7D%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?N_%7Bijk%7D"> is count of <img src="https://latex.codecogs.com/png.latex?X_i=k"> with parent configuration j</p>
</section>
<section id="bayesian-parameter-learning" class="level3">
<h3 class="anchored" data-anchor-id="bayesian-parameter-learning">2. Bayesian Parameter Learning</h3>
<p>Posterior distribution:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Ctheta%7CD)%20%5Cpropto%20P(D%7C%5Ctheta)P(%5Ctheta)%0A"></p>
<p>With Dirichlet prior:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctheta_%7Bijk%7D%20%5Csim%20%5Ctext%7BDir%7D(%5Calpha_%7Bijk%7D)%0A"></p>
<p>Posterior parameters:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Calpha_%7Bijk%7D%5E%7B%5Ctext%7Bpost%7D%7D%20=%20%5Calpha_%7Bijk%7D%20+%20N_%7Bijk%7D%0A"></p>
</section>
<section id="structure-learning" class="level3">
<h3 class="anchored" data-anchor-id="structure-learning">3. Structure Learning</h3>
<p>Score-based learning objective:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AG%5E*%20=%20%5Carg%5Cmax_G%20%5Ctext%7Bscore%7D(G:D)%0A"></p>
<p>Common scores: 1. BIC score:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BBIC%7D(G:D)%20=%20%5Cell(D%7C%5Chat%7B%5Ctheta%7D,%20G)%20-%20%5Cfrac%7B%5Clog%20N%7D%7B2%7D%7CG%7C%0A"></p>
<ol start="2" type="1">
<li>Bayesian score:</li>
</ol>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(G%7CD)%20%5Cpropto%20P(D%7CG)P(G)%0A"></p>
</section>
</section>
<section id="advanced-topics" class="level2">
<h2 class="anchored" data-anchor-id="advanced-topics">Advanced Topics</h2>
<section id="variational-inference" class="level3">
<h3 class="anchored" data-anchor-id="variational-inference">1. Variational Inference</h3>
<p>Evidence lower bound (ELBO):</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathcal%7BL%7D(q)%20=%20%5Cmathbb%7BE%7D_q%5B%5Clog%20p(x,z)%5D%20-%20%5Cmathbb%7BE%7D_q%5B%5Clog%20q(z)%5D%0A"></p>
<p>Mean field approximation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Aq(z)%20=%20%5Cprod_i%20q_i(z_i)%0A"></p>
<p>Update equations:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clog%20q_j%5E*(z_j)%20=%20%5Cmathbb%7BE%7D_%7Bq_%7B-j%7D%7D%5B%5Clog%20p(x,z)%5D%20+%20%5Ctext%7Bconst%7D%0A"></p>
</section>
<section id="mcmc-methods" class="level3">
<h3 class="anchored" data-anchor-id="mcmc-methods">2. MCMC Methods</h3>
<p>Metropolis-Hastings acceptance ratio:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Calpha%20=%20%5Cmin%5Cleft(1,%20%5Cfrac%7Bp(x')q(x%7Cx')%7D%7Bp(x)q(x'%7Cx)%7D%5Cright)%0A"></p>
<p>Gibbs sampling update:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ax_i%5E%7B(t+1)%7D%20%5Csim%20p(x_i%7Cx_%7B-i%7D%5E%7B(t)%7D)%0A"></p>
</section>
<section id="conditional-random-fields" class="level3">
<h3 class="anchored" data-anchor-id="conditional-random-fields">3. Conditional Random Fields</h3>
<p>Linear-chain CRF probability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(y%7Cx)%20=%20%5Cfrac%7B1%7D%7BZ(x)%7D%5Cexp%5Cleft(%5Csum_%7Bt=1%7D%5ET%5Csum_k%20%5Clambda_k%20f_k(y_t,y_%7Bt-1%7D,x_t)%5Cright)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?f_k"> are feature functions - <img src="https://latex.codecogs.com/png.latex?%5Clambda_k"> are weights - <img src="https://latex.codecogs.com/png.latex?Z(x)"> is normalization factor</p>
</section>
</section>
<section id="implementation-considerations" class="level2">
<h2 class="anchored" data-anchor-id="implementation-considerations">Implementation Considerations</h2>
<section id="numerical-stability" class="level3">
<h3 class="anchored" data-anchor-id="numerical-stability">1. Numerical Stability</h3>
<p>Log-space computations:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Clog%5Csum_i%20%5Cexp(x_i)%20=%20%5Cmax_i%20x_i%20+%20%5Clog%5Csum_i%20%5Cexp(x_i%20-%20%5Cmax_i%20x_i)%0A"></p>
</section>
<section id="sparse-representations" class="level3">
<h3 class="anchored" data-anchor-id="sparse-representations">2. Sparse Representations</h3>
<p>Efficient factor operations: - Sparse matrices for CPTs - Vectorized operations - Caching intermediate results</p>
</section>
<section id="parallelization" class="level3">
<h3 class="anchored" data-anchor-id="parallelization">3. Parallelization</h3>
<p>Parallel message passing: - Tree-structured graphs - Junction tree clusters - Mini-batch learning</p>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="model-selection" class="level3">
<h3 class="anchored" data-anchor-id="model-selection">1. Model Selection</h3>
<ol type="1">
<li>Network Structure:
<ul>
<li>Expert knowledge</li>
<li>Causal relationships</li>
<li>Data-driven learning</li>
</ul></li>
<li>Inference Method:
<ul>
<li>Exact vs approximate</li>
<li>Graph structure</li>
<li>Domain size</li>
</ul></li>
<li>Learning Approach:
<ul>
<li>Data completeness</li>
<li>Prior knowledge</li>
<li>Computational resources</li>
</ul></li>
</ol>
</section>
<section id="performance-optimization" class="level3">
<h3 class="anchored" data-anchor-id="performance-optimization">2. Performance Optimization</h3>
<ol type="1">
<li>Variable Ordering:
<ul>
<li>Min-fill heuristic</li>
<li>Min-degree ordering</li>
<li>Weighted variants</li>
</ul></li>
<li>Message Scheduling:
<ul>
<li>Residual belief propagation</li>
<li>Priority-based updates</li>
<li>Asynchronous methods</li>
</ul></li>
<li>Memory Management:
<ul>
<li>Factor caching</li>
<li>Message memoization</li>
<li>Sparse representations</li>
</ul></li>
</ol>
</section>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">Applications</h2>
<section id="medical-diagnosis" class="level3">
<h3 class="anchored" data-anchor-id="medical-diagnosis">1. Medical Diagnosis</h3>
<p>Network structure: - Diseases as root nodes - Symptoms as leaf nodes - Test results as intermediate nodes</p>
<p>Inference tasks: - Diagnostic reasoning - Predictive reasoning - Intercausal reasoning</p>
</section>
<section id="computer-vision" class="level3">
<h3 class="anchored" data-anchor-id="computer-vision">2. Computer Vision</h3>
<p>MRF applications: - Image segmentation - Stereo matching - Image restoration</p>
<p>Energy function:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AE(x)%20=%20%5Csum_i%20%5Cphi_i(x_i)%20+%20%5Csum_%7Bi,j%7D%20%5Cphi_%7Bij%7D(x_i,x_j)%0A"></p>
</section>
<section id="natural-language-processing" class="level3">
<h3 class="anchored" data-anchor-id="natural-language-processing">3. Natural Language Processing</h3>
<p>Linear-chain CRFs: - Part-of-speech tagging - Named entity recognition - Sequence labeling</p>
<p>Feature templates: - Word features - Context windows - Transition features</p>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Theory:
<ul>
<li>“Probabilistic Graphical Models” by Koller and Friedman</li>
<li>“Pattern Recognition and Machine Learning” by Bishop</li>
<li>“Information Theory, Inference, and Learning Algorithms” by MacKay</li>
</ul></li>
<li>Algorithms:
<ul>
<li>“Understanding Belief Propagation and its Generalizations” by Yedidia et al.</li>
<li>“An Introduction to MCMC for Machine Learning” by Andrieu et al.</li>
<li>“Structured Prediction for Natural Language Processing” by Smith</li>
</ul></li>
<li>Applications:
<ul>
<li>“Medical Applications of Artificial Intelligence” by Dua and Acharya</li>
<li>“Computer Vision: A Modern Approach” by Forsyth and Ponce</li>
<li>“Speech and Language Processing” by Jurafsky and Martin</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>probabilistic-models</category>
  <category>mathematics</category>
  <category>bayesian</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/probabilistic-graphical-models/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/probabilistic-graphical-models/pgm.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Understanding Reinforcement Learning: A Beginner’s Guide</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/reinforcement-learning-basics/</link>
  <description><![CDATA[ 





<section id="understanding-reinforcement-learning-learning-from-experience" class="level1">
<h1>Understanding Reinforcement Learning: Learning from Experience</h1>
<p>Have you ever wondered how animals learn through trial and error? Or how a child learns to ride a bicycle? These are perfect examples of reinforcement learning in nature. Let’s explore this fascinating field of machine learning in a way that’s easy to understand.</p>
<section id="what-is-reinforcement-learning" class="level2">
<h2 class="anchored" data-anchor-id="what-is-reinforcement-learning">What is Reinforcement Learning?</h2>
<p>Imagine teaching a dog new tricks. You: 1. Give treats when the dog performs correctly (reward) 2. Don’t give treats when it performs incorrectly (no reward) 3. The dog learns to associate actions with rewards</p>
<p>This is exactly how reinforcement learning works! It’s about: - Learning what to do (actions) - How to map situations to actions (strategy) - Maximizing a numerical reward signal</p>
</section>
<section id="key-components-of-reinforcement-learning" class="level2">
<h2 class="anchored" data-anchor-id="key-components-of-reinforcement-learning">Key Components of Reinforcement Learning</h2>
<section id="the-agent" class="level3">
<h3 class="anchored" data-anchor-id="the-agent">1. The Agent</h3>
<ul>
<li>This is our learner (like the dog in our example)</li>
<li>Makes decisions and performs actions</li>
<li>Learns from experience</li>
<li>Tries to maximize rewards</li>
</ul>
</section>
<section id="the-environment" class="level3">
<h3 class="anchored" data-anchor-id="the-environment">2. The Environment</h3>
<ul>
<li>Everything the agent interacts with</li>
<li>Could be real (physical world) or virtual (computer game)</li>
<li>Provides feedback to the agent</li>
<li>Changes in response to agent’s actions</li>
</ul>
</section>
<section id="states" class="level3">
<h3 class="anchored" data-anchor-id="states">3. States</h3>
<p>Think of states as “situations” the agent can be in: - Current position in a game - Current balance in a trading account - Current position of a robot</p>
</section>
<section id="actions" class="level3">
<h3 class="anchored" data-anchor-id="actions">4. Actions</h3>
<p>These are the choices available to the agent: - Move left/right in a game - Buy/sell in trading - Turn/move forward for a robot</p>
</section>
<section id="rewards" class="level3">
<h3 class="anchored" data-anchor-id="rewards">5. Rewards</h3>
<ul>
<li>Immediate feedback for actions</li>
<li>Can be positive or negative</li>
<li>Guides the learning process</li>
<li>Examples:
<ul>
<li>Points in a game</li>
<li>Profit/loss in trading</li>
<li>Successfully completing a task</li>
</ul></li>
</ul>
</section>
</section>
<section id="real-world-examples" class="level2">
<h2 class="anchored" data-anchor-id="real-world-examples">Real-World Examples</h2>
<section id="game-playing" class="level3">
<h3 class="anchored" data-anchor-id="game-playing">1. Game Playing</h3>
<p>Imagine teaching an AI to play chess: - <strong>States</strong>: Position of pieces on the board - <strong>Actions</strong>: Possible moves - <strong>Rewards</strong>: * +1 for winning * -1 for losing * 0 for drawing * Small rewards for capturing pieces</p>
</section>
<section id="robot-navigation" class="level3">
<h3 class="anchored" data-anchor-id="robot-navigation">2. Robot Navigation</h3>
<p>Teaching a robot to navigate a room: - <strong>States</strong>: Current location, obstacle positions - <strong>Actions</strong>: Move forward, turn left/right - <strong>Rewards</strong>: * +1 for reaching goal * -1 for hitting obstacles * Small negative reward for time taken</p>
</section>
<section id="smart-home-energy-management" class="level3">
<h3 class="anchored" data-anchor-id="smart-home-energy-management">3. Smart Home Energy Management</h3>
<p>Optimizing home energy usage: - <strong>States</strong>: Time of day, temperature, occupancy - <strong>Actions</strong>: Adjust heating/cooling - <strong>Rewards</strong>: * Positive for energy savings * Negative for user discomfort</p>
</section>
</section>
<section id="core-concepts" class="level2">
<h2 class="anchored" data-anchor-id="core-concepts">Core Concepts</h2>
<section id="exploration-vs.-exploitation" class="level3">
<h3 class="anchored" data-anchor-id="exploration-vs.-exploitation">1. Exploration vs.&nbsp;Exploitation</h3>
<p>This is like trying a new restaurant vs.&nbsp;going to your favorite one:</p>
<p><strong>Exploration</strong>: - Trying new actions - Gathering information - Risk of lower rewards - Necessary for learning</p>
<p><strong>Exploitation</strong>: - Using known good actions - Maximizing immediate rewards - Safe but might miss better options</p>
</section>
<section id="the-learning-process" class="level3">
<h3 class="anchored" data-anchor-id="the-learning-process">2. The Learning Process</h3>
<ol type="1">
<li><strong>Observation</strong>:
<ul>
<li>Agent observes current state</li>
<li>Like a chess player analyzing the board</li>
</ul></li>
<li><strong>Action Selection</strong>:
<ul>
<li>Choose action based on strategy</li>
<li>Balance between exploration and exploitation</li>
</ul></li>
<li><strong>Feedback</strong>:
<ul>
<li>Environment provides reward</li>
<li>State changes based on action</li>
</ul></li>
<li><strong>Learning</strong>:
<ul>
<li>Update knowledge based on experience</li>
<li>Improve future decision making</li>
</ul></li>
</ol>
</section>
<section id="policy-learning" class="level3">
<h3 class="anchored" data-anchor-id="policy-learning">3. Policy Learning</h3>
<p>A policy is like a strategy or rulebook: - Maps states to actions - Improves with experience - Aims to maximize long-term rewards</p>
</section>
</section>
<section id="common-challenges" class="level2">
<h2 class="anchored" data-anchor-id="common-challenges">Common Challenges</h2>
<section id="delayed-rewards" class="level3">
<h3 class="anchored" data-anchor-id="delayed-rewards">1. Delayed Rewards</h3>
<ul>
<li>Actions might have long-term consequences</li>
<li>Hard to attribute success to specific actions</li>
<li>Example: Chess moves leading to victory</li>
</ul>
</section>
<section id="the-credit-assignment-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-credit-assignment-problem">2. The Credit Assignment Problem</h3>
<ul>
<li>Which actions were actually responsible for the reward?</li>
<li>Like trying to identify which study habits led to good grades</li>
</ul>
</section>
<section id="exploration-exploitation-balance" class="level3">
<h3 class="anchored" data-anchor-id="exploration-exploitation-balance">3. Exploration-Exploitation Balance</h3>
<ul>
<li>Too much exploration: slow learning</li>
<li>Too much exploitation: missed opportunities</li>
<li>Finding the right balance is crucial</li>
</ul>
</section>
</section>
<section id="applications-in-everyday-life" class="level2">
<h2 class="anchored" data-anchor-id="applications-in-everyday-life">Applications in Everyday Life</h2>
<section id="personal-development" class="level3">
<h3 class="anchored" data-anchor-id="personal-development">1. Personal Development</h3>
<ul>
<li>Learning new skills</li>
<li>Developing good habits</li>
<li>Career progression</li>
</ul>
</section>
<section id="business-strategy" class="level3">
<h3 class="anchored" data-anchor-id="business-strategy">2. Business Strategy</h3>
<ul>
<li>Market expansion</li>
<li>Product development</li>
<li>Customer engagement</li>
</ul>
</section>
<section id="education" class="level3">
<h3 class="anchored" data-anchor-id="education">3. Education</h3>
<ul>
<li>Adaptive learning systems</li>
<li>Personalized curriculum</li>
<li>Student engagement</li>
</ul>
</section>
</section>
<section id="getting-started-with-reinforcement-learning" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-with-reinforcement-learning">Getting Started with Reinforcement Learning</h2>
<section id="build-understanding" class="level3">
<h3 class="anchored" data-anchor-id="build-understanding">1. Build Understanding</h3>
<ul>
<li>Start with simple concepts</li>
<li>Use analogies from daily life</li>
<li>Focus on principles before implementation</li>
</ul>
</section>
<section id="choose-simple-problems" class="level3">
<h3 class="anchored" data-anchor-id="choose-simple-problems">2. Choose Simple Problems</h3>
<ul>
<li>Start with basic scenarios</li>
<li>Clear states and actions</li>
<li>Immediate rewards</li>
</ul>
</section>
<section id="progress-gradually" class="level3">
<h3 class="anchored" data-anchor-id="progress-gradually">3. Progress Gradually</h3>
<ul>
<li>Move to more complex problems</li>
<li>Introduce delayed rewards</li>
<li>Handle larger state spaces</li>
</ul>
</section>
</section>
<section id="best-practices-for-learning" class="level2">
<h2 class="anchored" data-anchor-id="best-practices-for-learning">Best Practices for Learning</h2>
<ol type="1">
<li><strong>Start Simple</strong>
<ul>
<li>Begin with basic concepts</li>
<li>Use clear examples</li>
<li>Build foundational understanding</li>
</ul></li>
<li><strong>Use Analogies</strong>
<ul>
<li>Connect to familiar experiences</li>
<li>Make abstract concepts concrete</li>
<li>Use real-world examples</li>
</ul></li>
<li><strong>Practice Application</strong>
<ul>
<li>Think about RL in daily life</li>
<li>Identify states, actions, rewards</li>
<li>Consider strategies and policies</li>
</ul></li>
</ol>
</section>
<section id="common-misconceptions" class="level2">
<h2 class="anchored" data-anchor-id="common-misconceptions">Common Misconceptions</h2>
<ol type="1">
<li><strong>It’s All About Programming</strong>
<ul>
<li>Understanding concepts is more important</li>
<li>Programming is just a tool</li>
<li>Focus on principles first</li>
</ul></li>
<li><strong>It’s Only for Complex Problems</strong>
<ul>
<li>Can be applied to simple tasks</li>
<li>Useful for everyday decisions</li>
<li>Scalable to various situations</li>
</ul></li>
<li><strong>It Requires Advanced Math</strong>
<ul>
<li>Basic concepts are intuitive</li>
<li>Math helps but isn’t essential for understanding</li>
<li>Start with conceptual understanding</li>
</ul></li>
</ol>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Reinforcement learning is about: 1. Learning from experience 2. Making better decisions 3. Adapting to new situations 4. Maximizing long-term rewards</p>
<p>Remember: - Start with understanding - Use simple examples - Apply concepts to real life - Build gradually</p>
</section>
<section id="additional-resources" class="level2">
<h2 class="anchored" data-anchor-id="additional-resources">Additional Resources</h2>
<ol type="1">
<li>Books for Beginners:
<ul>
<li>“Reinforcement Learning: An Introduction” by Sutton &amp; Barto (first few chapters)</li>
<li>“Grokking Deep Reinforcement Learning” by Miguel Morales</li>
</ul></li>
<li>Online Resources:
<ul>
<li>DeepMind’s RL Introduction</li>
<li>OpenAI’s RL Resources</li>
<li>Stanford’s RL Course (basic concepts)</li>
</ul></li>
</ol>
<p>Remember: The key to understanding reinforcement learning is to start with the fundamentals and gradually build up to more complex concepts. Focus on understanding the principles before diving into implementation details.</p>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>reinforcement-learning</category>
  <category>theory</category>
  <category>beginner</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/reinforcement-learning-basics/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/reinforcement-learning-basics/rl_basics.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Statistical Learning Theory and Concentration Inequalities</title>
  <dc:creator>Ram Polisetti</dc:creator>
  <link>https://ram-polisetti.github.io/BendTheCurve/posts/statistical-learning-theory/</link>
  <description><![CDATA[ 





<section id="statistical-learning-theory-and-concentration-inequalities" class="level1">
<h1>Statistical Learning Theory and Concentration Inequalities</h1>
<section id="concentration-inequalities" class="level2">
<h2 class="anchored" data-anchor-id="concentration-inequalities">Concentration Inequalities</h2>
<section id="markovs-inequality" class="level3">
<h3 class="anchored" data-anchor-id="markovs-inequality">1. Markov’s Inequality</h3>
<p>Basic form:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(X%20%5Cgeq%20a)%20%5Cleq%20%5Cfrac%7B%5Cmathbb%7BE%7D%5BX%5D%7D%7Ba%7D%0A"></p>
<p>For non-negative random variables.</p>
<p>Moment version:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%7CX%7C%20%5Cgeq%20a)%20%5Cleq%20%5Cfrac%7B%5Cmathbb%7BE%7D%5B%7CX%7C%5Er%5D%7D%7Ba%5Er%7D%0A"></p>
</section>
<section id="chebyshevs-inequality" class="level3">
<h3 class="anchored" data-anchor-id="chebyshevs-inequality">2. Chebyshev’s Inequality</h3>
<p>Basic form:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%7CX%20-%20%5Cmu%7C%20%5Cgeq%20t)%20%5Cleq%20%5Cfrac%7B%5Csigma%5E2%7D%7Bt%5E2%7D%0A"></p>
<p>Moment version:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%7CX%20-%20%5Cmathbb%7BE%7D%5BX%5D%7C%20%5Cgeq%20t)%20%5Cleq%20%5Cfrac%7B%5Ctext%7BVar%7D(X)%7D%7Bt%5E2%7D%0A"></p>
</section>
<section id="hoeffdings-inequality" class="level3">
<h3 class="anchored" data-anchor-id="hoeffdings-inequality">3. Hoeffding’s Inequality</h3>
<p>Sum of bounded variables:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5En%20X_i%20-%20%5Cmathbb%7BE%7D%5BX%5D%20%5Cgeq%20t)%20%5Cleq%20%5Cexp(-%5Cfrac%7B2nt%5E2%7D%7B(b-a)%5E2%7D)%0A"></p>
<p>Martingale version:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(S_n%20-%20S_0%20%5Cgeq%20t)%20%5Cleq%20%5Cexp(-%5Cfrac%7B2t%5E2%7D%7B%5Csum_%7Bi=1%7D%5En%20(b_i-a_i)%5E2%7D)%0A"></p>
</section>
</section>
<section id="advanced-concentration-results" class="level2">
<h2 class="anchored" data-anchor-id="advanced-concentration-results">Advanced Concentration Results</h2>
<section id="bernsteins-inequality" class="level3">
<h3 class="anchored" data-anchor-id="bernsteins-inequality">1. Bernstein’s Inequality</h3>
<p>Variance-based bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5En%20(X_i%20-%20%5Cmathbb%7BE%7D%5BX_i%5D)%20%5Cgeq%20t)%20%5Cleq%20%5Cexp(-%5Cfrac%7Bnt%5E2%7D%7B2%5Csigma%5E2%20+%202Mt/3%7D)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%7CX_i%7C%20%5Cleq%20M"> - <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVar%7D(X_i)%20%5Cleq%20%5Csigma%5E2"></p>
</section>
<section id="mcdiarmids-inequality" class="level3">
<h3 class="anchored" data-anchor-id="mcdiarmids-inequality">2. McDiarmid’s Inequality</h3>
<p>Bounded differences:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(f(X_1,...,X_n)%20-%20%5Cmathbb%7BE%7D%5Bf%5D%20%5Cgeq%20t)%20%5Cleq%20%5Cexp(-%5Cfrac%7B2t%5E2%7D%7B%5Csum_%7Bi=1%7D%5En%20c_i%5E2%7D)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%7Cf(x)%20-%20f(x')%7C%20%5Cleq%20c_i"> when <img src="https://latex.codecogs.com/png.latex?x,x'"> differ in i-th coordinate</p>
</section>
<section id="talagrands-inequality" class="level3">
<h3 class="anchored" data-anchor-id="talagrands-inequality">3. Talagrand’s Inequality</h3>
<p>Convex distance:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%7CZ%20-%20M(Z)%7C%20%5Cgeq%20t)%20%5Cleq%204%5Cexp(-%5Cfrac%7Bt%5E2%7D%7B4%5Csigma%5E2%7D)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?Z"> is supremum of empirical process - <img src="https://latex.codecogs.com/png.latex?M(Z)"> is median</p>
</section>
</section>
<section id="statistical-learning-bounds" class="level2">
<h2 class="anchored" data-anchor-id="statistical-learning-bounds">Statistical Learning Bounds</h2>
<section id="uniform-convergence" class="level3">
<h3 class="anchored" data-anchor-id="uniform-convergence">1. Uniform Convergence</h3>
<p>Fundamental theorem:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%7C%5Chat%7BR%7D_n(h)%20-%20R(h)%7C%20%3E%20%5Cepsilon)%20%5Cleq%208%5Cmathcal%7BN%7D(%5Cepsilon/8)%5Cexp(-n%5Cepsilon%5E2/128)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5Cmathcal%7BN%7D(%5Cepsilon)"> is covering number - <img src="https://latex.codecogs.com/png.latex?R(h)"> is true risk - <img src="https://latex.codecogs.com/png.latex?%5Chat%7BR%7D_n(h)"> is empirical risk</p>
</section>
<section id="symmetrization" class="level3">
<h3 class="anchored" data-anchor-id="symmetrization">2. Symmetrization</h3>
<p>Basic inequality:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%7CR(h)%20-%20%5Chat%7BR%7D_n(h)%7C%20%3E%202%5Cepsilon)%20%5Cleq%202P(%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%7C%5Chat%7BR%7D_n(h)%20-%20%5Chat%7BR%7D'_n(h)%7C%20%3E%20%5Cepsilon)%0A"></p>
<p>Ghost sample technique:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5B%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%7CR(h)%20-%20%5Chat%7BR%7D_n(h)%7C%5D%20%5Cleq%202%5Cmathbb%7BE%7D%5B%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%7C%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5En%20%5Csigma_i%20h(X_i)%7C%5D%0A"></p>
</section>
<section id="rademacher-complexity" class="level3">
<h3 class="anchored" data-anchor-id="rademacher-complexity">3. Rademacher Complexity</h3>
<p>Definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathfrak%7BR%7D_n(%5Cmathcal%7BH%7D)%20=%20%5Cmathbb%7BE%7D_%7B%5Csigma,S%7D%5B%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5En%20%5Csigma_i%20h(x_i)%5D%0A"></p>
<p>Generalization bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D%7D%7CR(h)%20-%20%5Chat%7BR%7D_n(h)%7C%20%5Cleq%202%5Cmathfrak%7BR%7D_n(%5Cmathcal%7BH%7D)%20+%20%5Csqrt%7B%5Cfrac%7B%5Cln(2/%5Cdelta)%7D%7B2n%7D%7D)%20%5Cgeq%201-%5Cdelta%0A"></p>
</section>
</section>
<section id="local-analysis" class="level2">
<h2 class="anchored" data-anchor-id="local-analysis">Local Analysis</h2>
<section id="local-rademacher-complexity" class="level3">
<h3 class="anchored" data-anchor-id="local-rademacher-complexity">1. Local Rademacher Complexity</h3>
<p>Definition:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathfrak%7BR%7D_n(%5Cmathcal%7BH%7D,%20r)%20=%20%5Cmathbb%7BE%7D_%7B%5Csigma%7D%5B%5Csup_%7Bh%20%5Cin%20%5Cmathcal%7BH%7D:%20P(h-h%5E*)%5E2%20%5Cleq%20r%7D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi=1%7D%5En%20%5Csigma_i%20h(X_i)%5D%0A"></p>
<p>Fixed point:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Ar%5E*%20=%20%5Cinf%5C%7Br%20%3E%200:%20%5Cmathfrak%7BR%7D_n(%5Cmathcal%7BH%7D,%20r)%20%5Cleq%20r/4%5C%7D%0A"></p>
</section>
<section id="localized-uniform-convergence" class="level3">
<h3 class="anchored" data-anchor-id="localized-uniform-convergence">2. Localized Uniform Convergence</h3>
<p>Bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Csup_%7Bh%20%5Cin%20B(h%5E*,r)%7D%7CR(h)%20-%20%5Chat%7BR%7D_n(h)%7C%20%3E%20%5Cepsilon)%20%5Cleq%20%5Cmathcal%7BN%7D(r,%5Cepsilon/4)%5Cexp(-n%5Cepsilon%5E2/8)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?B(h%5E*,r)"> is ball around optimal hypothesis</p>
</section>
<section id="peeling" class="level3">
<h3 class="anchored" data-anchor-id="peeling">3. Peeling</h3>
<p>Geometric slicing:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5Cexists%20h:%20%7CR(h)%20-%20%5Chat%7BR%7D_n(h)%7C%20%3E%20%5Cepsilon%5Csqrt%7BR(h)%7D)%20%5Cleq%20%5Csum_%7Bj=0%7D%5E%5Cinfty%20P(%5Csup_%7Bh:%20R(h)%20%5Cin%20%5B2%5Ej%5Calpha,2%5E%7Bj+1%7D%5Calpha%5D%7D%7CR(h)%20-%20%5Chat%7BR%7D_n(h)%7C%20%3E%20%5Cepsilon%5Csqrt%7B2%5Ej%5Calpha%7D)%0A"></p>
</section>
</section>
<section id="advanced-theory" class="level2">
<h2 class="anchored" data-anchor-id="advanced-theory">Advanced Theory</h2>
<section id="stability-theory" class="level3">
<h3 class="anchored" data-anchor-id="stability-theory">1. Stability Theory</h3>
<p>Algorithmic stability:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%7C%5Cell(A_S,z)%20-%20%5Cell(A_%7BS%5Ei%7D,z)%7C%20%5Cleq%20%5Cbeta%0A"></p>
<p>Generalization bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%7CR(A_S)%20-%20%5Chat%7BR%7D_n(A_S)%7C%20%3E%20%5Cepsilon)%20%5Cleq%202%5Cexp(-%5Cfrac%7Bn%5Cepsilon%5E2%7D%7B2%5Cbeta%5E2%7D)%0A"></p>
</section>
<section id="compression-schemes" class="level3">
<h3 class="anchored" data-anchor-id="compression-schemes">2. Compression Schemes</h3>
<p>Sample compression:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0Am%20%5Cgeq%20k%5Clog%5Cfrac%7Bem%7D%7Bk%7D%20+%20%5Clog%5Cfrac%7B1%7D%7B%5Cdelta%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?k"> is size of compression set - <img src="https://latex.codecogs.com/png.latex?m"> is sample size</p>
</section>
<section id="pac-bayesian-theory" class="level3">
<h3 class="anchored" data-anchor-id="pac-bayesian-theory">3. PAC-Bayesian Theory</h3>
<p>KL-divergence bound:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AR(Q)%20%5Cleq%20%5Chat%7BR%7D_n(Q)%20+%20%5Csqrt%7B%5Cfrac%7BKL(Q%5C%7CP)%20+%20%5Cln%5Cfrac%7B2%5Csqrt%7Bn%7D%7D%7B%5Cdelta%7D%7D%7B2n%7D%7D%0A"></p>
</section>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">Applications</h2>
<section id="high-dimensional-statistics" class="level3">
<h3 class="anchored" data-anchor-id="high-dimensional-statistics">1. High-Dimensional Statistics</h3>
<p>Sparse recovery:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5C%7C%5Chat%7B%5Cbeta%7D%20-%20%5Cbeta%5E*%5C%7C_2%20%5Cleq%20%5Csqrt%7B%5Cfrac%7Bs%5Clog%20p%7D%7Bn%7D%7D%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?s"> is sparsity - <img src="https://latex.codecogs.com/png.latex?p"> is dimension</p>
</section>
<section id="random-matrices" class="level3">
<h3 class="anchored" data-anchor-id="random-matrices">2. Random Matrices</h3>
<p>Matrix Bernstein:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(%5C%7C%5Csum_%7Bi=1%7D%5En%20X_i%5C%7C%20%5Cgeq%20t)%20%5Cleq%202d%5Cexp(-%5Cfrac%7Bt%5E2/2%7D%7B%5Csigma%5E2%20+%20Mt/3%7D)%0A"></p>
<p>Where: - <img src="https://latex.codecogs.com/png.latex?%5C%7CX_i%5C%7C%20%5Cleq%20M"> - <img src="https://latex.codecogs.com/png.latex?%5C%7C%5Cmathbb%7BE%7D%5BX_iX_i%5ET%5D%5C%7C%20%5Cleq%20%5Csigma%5E2"></p>
</section>
<section id="empirical-processes" class="level3">
<h3 class="anchored" data-anchor-id="empirical-processes">3. Empirical Processes</h3>
<p>Maximal inequality:</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cmathbb%7BE%7D%5B%5Csup_%7Bf%20%5Cin%20%5Cmathcal%7BF%7D%7D%7C%5Csum_%7Bi=1%7D%5En%20%5Cepsilon_i%20f(X_i)%7C%5D%20%5Cleq%20K%5Csqrt%7Bn%7D%5Cint_0%5E%5Cinfty%20%5Csqrt%7B%5Clog%20N(%5Cepsilon,%5Cmathcal%7BF%7D,L_2)%7Dd%5Cepsilon%0A"></p>
</section>
</section>
<section id="implementation-considerations" class="level2">
<h2 class="anchored" data-anchor-id="implementation-considerations">Implementation Considerations</h2>
<section id="sample-size-selection" class="level3">
<h3 class="anchored" data-anchor-id="sample-size-selection">1. Sample Size Selection</h3>
<ol type="1">
<li>Fixed Confidence:
<ul>
<li>Error tolerance</li>
<li>Confidence level</li>
<li>Complexity measure</li>
</ul></li>
<li>Fixed Width:
<ul>
<li>Precision requirement</li>
<li>Coverage probability</li>
<li>Dimension impact</li>
</ul></li>
<li>Sequential:
<ul>
<li>Stopping rules</li>
<li>Error control</li>
<li>Efficiency</li>
</ul></li>
</ol>
</section>
<section id="bound-selection" class="level3">
<h3 class="anchored" data-anchor-id="bound-selection">2. Bound Selection</h3>
<ol type="1">
<li>Problem Structure:
<ul>
<li>Independence</li>
<li>Boundedness</li>
<li>Moment conditions</li>
</ul></li>
<li>Sample Properties:
<ul>
<li>Size</li>
<li>Distribution</li>
<li>Dependence</li>
</ul></li>
<li>Computational:
<ul>
<li>Tightness</li>
<li>Simplicity</li>
<li>Tractability</li>
</ul></li>
</ol>
</section>
</section>
<section id="best-practices" class="level2">
<h2 class="anchored" data-anchor-id="best-practices">Best Practices</h2>
<section id="analysis-strategy" class="level3">
<h3 class="anchored" data-anchor-id="analysis-strategy">1. Analysis Strategy</h3>
<ol type="1">
<li>Problem Formulation:
<ul>
<li>Identify assumptions</li>
<li>Choose metrics</li>
<li>Set objectives</li>
</ul></li>
<li>Bound Selection:
<ul>
<li>Match assumptions</li>
<li>Consider tightness</li>
<li>Balance complexity</li>
</ul></li>
<li>Implementation:
<ul>
<li>Numerical stability</li>
<li>Computational efficiency</li>
<li>Error handling</li>
</ul></li>
</ol>
</section>
<section id="practical-guidelines" class="level3">
<h3 class="anchored" data-anchor-id="practical-guidelines">2. Practical Guidelines</h3>
<ol type="1">
<li>Sample Size:
<ul>
<li>Conservative estimates</li>
<li>Safety margins</li>
<li>Power analysis</li>
</ul></li>
<li>Validation:
<ul>
<li>Cross-validation</li>
<li>Bootstrap</li>
<li>Permutation tests</li>
</ul></li>
<li>Monitoring:
<ul>
<li>Convergence checks</li>
<li>Stability measures</li>
<li>Error tracking</li>
</ul></li>
</ol>
</section>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li>Theory:
<ul>
<li>“Concentration Inequalities” by Boucheron et al.</li>
<li>“Statistical Learning Theory” by Vapnik</li>
<li>“High-Dimensional Probability” by Vershynin</li>
</ul></li>
<li>Methods:
<ul>
<li>“Empirical Processes in M-Estimation” by van der Vaart and Wellner</li>
<li>“Random Matrices: High Dimensional Phenomena” by Davidson and Szarek</li>
<li>“Theory of Classification” by Devroye et al.</li>
</ul></li>
<li>Applications:
<ul>
<li>“Statistical Learning Theory and Applications” by Bousquet et al.</li>
<li>“High-Dimensional Statistics” by Wainwright</li>
<li>“Machine Learning Theory” by Mohri et al.</li>
</ul></li>
</ol>



</section>
</section>

<div class="quarto-listing quarto-listing-container-default" id="listing-listing">
<div class="list quarto-listing-default">

</div>
<div class="listing-no-matching d-none">
No matching items
</div>
</div> ]]></description>
  <category>machine-learning</category>
  <category>theory</category>
  <category>mathematics</category>
  <category>statistics</category>
  <guid>https://ram-polisetti.github.io/BendTheCurve/posts/statistical-learning-theory/</guid>
  <pubDate>Tue, 19 Mar 2024 04:00:00 GMT</pubDate>
  <media:content url="https://ram-polisetti.github.io/BendTheCurve/posts/statistical-learning-theory/statistical_learning.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>

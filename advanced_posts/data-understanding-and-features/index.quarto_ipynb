{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Data Understanding & Feature Engineering: The Foundation of ML Success\"\n",
        "author: \"Ram Polisetti\"\n",
        "date: \"2024-03-19\"\n",
        "categories: [machine-learning, data-science, feature-engineering, tutorial]\n",
        "image: \"feature_engineering.jpg\"\n",
        "description: \"Master the art of data understanding and feature engineering - the most critical yet often overlooked aspects of machine learning.\"\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Data Understanding & Feature Engineering: The Core of Machine Learning\n",
        "\n",
        "While algorithms often get the spotlight, successful machine learning projects are built on the foundation of good data understanding and feature engineering. This post explores these crucial aspects using real-world datasets.\n",
        "\n",
        "## Data Understanding\n"
      ],
      "id": "3e77c9d1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_breast_cancer, fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Set style for better visualizations\n",
        "plt.style.use('seaborn')\n",
        "sns.set_theme(style=\"whitegrid\")"
      ],
      "id": "6c0af4d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Real-World Datasets\n"
      ],
      "id": "5c6e03cb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load breast cancer dataset for classification example\n",
        "cancer = load_breast_cancer()\n",
        "df_cancer = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "df_cancer['target'] = cancer.target\n",
        "\n",
        "# Load California housing dataset for regression example\n",
        "housing = fetch_california_housing()\n",
        "df_housing = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
        "df_housing['target'] = housing.target"
      ],
      "id": "ca9d0b44",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Exploratory Data Analysis (EDA)\n"
      ],
      "id": "006cc14b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Basic statistics for cancer dataset\n",
        "print(\"Breast Cancer Dataset Overview:\")\n",
        "print(\"\\nShape:\", df_cancer.shape)\n",
        "print(\"\\nFeatures:\", cancer.feature_names.tolist())\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(df_cancer.describe().round(2))\n",
        "\n",
        "# Visualize feature distributions\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, feature in enumerate(['mean radius', 'mean texture', 'mean perimeter']):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    sns.histplot(data=df_cancer, x=feature, hue='target', multiple=\"stack\", bins=30)\n",
        "    plt.title(f'{feature} Distribution by Class')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlation analysis\n",
        "plt.figure(figsize=(12, 8))\n",
        "correlation_matrix = df_cancer.iloc[:, :10].corr()  # First 10 features for clarity\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Feature Correlations (First 10 Features)')\n",
        "plt.show()"
      ],
      "id": "67e212b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Data Quality Assessment\n"
      ],
      "id": "42d01ef6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def assess_data_quality(df, name):\n",
        "    print(f\"\\nData Quality Assessment for {name} dataset:\")\n",
        "    \n",
        "    # Missing values\n",
        "    missing = df.isnull().sum()\n",
        "    if missing.any():\n",
        "        print(\"\\nMissing Values:\")\n",
        "        print(missing[missing > 0])\n",
        "    else:\n",
        "        print(\"\\nNo missing values found\")\n",
        "    \n",
        "    # Duplicates\n",
        "    duplicates = df.duplicated().sum()\n",
        "    print(f\"\\nDuplicate Rows: {duplicates}\")\n",
        "    \n",
        "    # Basic statistics\n",
        "    print(\"\\nValue Ranges:\")\n",
        "    for col in df.select_dtypes(include=[np.number]).columns[:5]:  # First 5 numeric columns\n",
        "        print(f\"{col}: {df[col].min():.2f} to {df[col].max():.2f}\")\n",
        "\n",
        "# Assess both datasets\n",
        "assess_data_quality(df_cancer, \"Breast Cancer\")\n",
        "assess_data_quality(df_housing, \"California Housing\")"
      ],
      "id": "868c2f73",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n",
        "\n",
        "### 1. Numerical Feature Transformations\n"
      ],
      "id": "95607fe7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Select subset of housing features for demonstration\n",
        "housing_features = ['MedInc', 'HouseAge', 'AveRooms', 'Population']\n",
        "X_housing = df_housing[housing_features]\n",
        "\n",
        "# Create derived features\n",
        "X_housing['RoomsPerPerson'] = X_housing['AveRooms'] / X_housing['Population']\n",
        "X_housing['LogIncome'] = np.log1p(X_housing['MedInc'])\n",
        "X_housing['AgeDecade'] = pd.qcut(X_housing['HouseAge'], q=4, labels=['New', 'Medium', 'Old', 'Very Old'])\n",
        "\n",
        "# Visualize transformed features\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "sns.histplot(X_housing['MedInc'], kde=True, label='Original')\n",
        "sns.histplot(X_housing['LogIncome'], kde=True, label='Log-transformed')\n",
        "plt.title('Income Distribution: Original vs Log-transformed')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(132)\n",
        "sns.boxplot(data=X_housing, x='AgeDecade', y='RoomsPerPerson')\n",
        "plt.title('Rooms per Person by House Age')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(133)\n",
        "sns.scatterplot(data=X_housing, x='LogIncome', y='RoomsPerPerson', hue='AgeDecade')\n",
        "plt.title('Income vs Rooms per Person')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "de828eb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Feature Scaling and Preprocessing\n"
      ],
      "id": "1df894c2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import RobustScaler, PowerTransformer\n",
        "\n",
        "# Create preprocessing pipeline\n",
        "numeric_features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area']\n",
        "X_cancer = df_cancer[numeric_features]\n",
        "\n",
        "# Create preprocessing pipeline\n",
        "preprocessor = Pipeline([\n",
        "    ('robust_scaler', RobustScaler()),\n",
        "    ('power_transform', PowerTransformer(method='yeo-johnson'))\n",
        "])\n",
        "\n",
        "# Fit and transform the data\n",
        "X_transformed = preprocessor.fit_transform(X_cancer)\n",
        "df_transformed = pd.DataFrame(X_transformed, columns=numeric_features)\n",
        "\n",
        "# Visualize before and after preprocessing\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "for i, feature in enumerate(numeric_features):\n",
        "    row = i // 2\n",
        "    col = i % 2\n",
        "    \n",
        "    # Original distribution\n",
        "    sns.histplot(X_cancer[feature], kde=True, ax=axes[row, col], color='blue', alpha=0.5, label='Original')\n",
        "    \n",
        "    # Transformed distribution\n",
        "    sns.histplot(df_transformed[feature], kde=True, ax=axes[row, col], color='red', alpha=0.5, label='Transformed')\n",
        "    \n",
        "    axes[row, col].set_title(f'{feature} Distribution')\n",
        "    axes[row, col].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "59936fb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Advanced Feature Engineering Techniques\n"
      ],
      "id": "ddcaec30"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Polynomial features for cancer dataset\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Select two features for demonstration\n",
        "X_poly = df_cancer[['mean radius', 'mean texture']]\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly_transformed = poly.fit_transform(X_poly)\n",
        "\n",
        "# Create feature names\n",
        "poly_features = poly.get_feature_names_out(['radius', 'texture'])\n",
        "df_poly = pd.DataFrame(X_poly_transformed, columns=poly_features)\n",
        "\n",
        "# Visualize polynomial features\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(121)\n",
        "sns.scatterplot(data=df_cancer, x='mean radius', y='mean texture', hue='target')\n",
        "plt.title('Original Features')\n",
        "\n",
        "plt.subplot(122)\n",
        "sns.scatterplot(data=df_poly, x='radius', y='radius texture', hue=df_cancer['target'])\n",
        "plt.title('Polynomial Interaction')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fe593809",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection\n"
      ],
      "id": "4c5e0651"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "\n",
        "# Select features using mutual information\n",
        "selector = SelectKBest(score_func=mutual_info_classif, k=5)\n",
        "X_selected = selector.fit_transform(df_cancer.drop('target', axis=1), df_cancer['target'])\n",
        "\n",
        "# Get selected feature names and scores\n",
        "feature_scores = pd.DataFrame({\n",
        "    'Feature': cancer.feature_names,\n",
        "    'Score': selector.scores_\n",
        "})\n",
        "feature_scores = feature_scores.sort_values('Score', ascending=False)\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=feature_scores.head(10), x='Score', y='Feature')\n",
        "plt.title('Top 10 Features by Mutual Information Score')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "0c756753",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Practices and Common Pitfalls\n",
        "\n",
        "### Best Practices:\n",
        "\n",
        "1. **Start with Domain Knowledge**\n",
        "   - Understand the business context\n",
        "   - Identify relevant features\n",
        "   - Consider expert insights\n",
        "\n",
        "2. **Systematic Approach**\n",
        "   - Begin with simple features\n",
        "   - Document transformations\n",
        "   - Validate assumptions\n",
        "\n",
        "3. **Feature Validation**\n",
        "   - Check distributions\n",
        "   - Verify transformations\n",
        "   - Test feature importance\n",
        "\n",
        "### Common Pitfalls:\n",
        "\n",
        "1. **Data Leakage**\n",
        "   - Using future information\n",
        "   - Target leakage\n",
        "   - Train-test contamination\n",
        "\n",
        "2. **Overengineering**\n",
        "   - Creating too many features\n",
        "   - Unnecessary complexity\n",
        "   - Redundant features\n",
        "\n",
        "3. **Poor Validation**\n",
        "   - Not checking distributions\n",
        "   - Ignoring outliers\n",
        "   - Missing data quality issues\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Feature engineering is both an art and a science. Key takeaways:\n",
        "\n",
        "1. Start with thorough data understanding\n",
        "2. Use domain knowledge to guide feature creation\n",
        "3. Validate features systematically\n",
        "4. Be mindful of common pitfalls\n",
        "5. Document your process\n",
        "\n",
        "In the next post, we'll explore model selection and evaluation strategies, building on these foundational concepts.\n",
        "\n",
        "## Additional Resources\n",
        "\n",
        "1. Books:\n",
        "   - \"Feature Engineering for Machine Learning\" by Alice Zheng\n",
        "   - \"Python Feature Engineering Cookbook\" by Soledad Galli\n",
        "\n",
        "2. Online Resources:\n",
        "   - Scikit-learn Feature Engineering Guide\n",
        "   - Kaggle Feature Engineering Tutorials\n",
        "   - Feature Tools Documentation\n",
        "\n",
        "Remember: Good features often matter more than sophisticated algorithms. Invest time in understanding your data and creating meaningful features."
      ],
      "id": "d2ec3284"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/anaconda3/envs/quarto-blog/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
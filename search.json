[
  {
    "objectID": "posts/algorithmic-stability/index.html",
    "href": "posts/algorithmic-stability/index.html",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Learning Objectives\n\n\n\nBy the end of this article, you will: 1. Understand what algorithmic stability means and why it matters 2. Learn different types of stability measures 3. See how stability affects model generalization 4. Practice implementing stability checks 5. Learn best practices for developing stable models\n\n\n\n\nImagine building a house of cards . If a slight breeze can topple it, we’d say it’s unstable. Similarly, in machine learning, we want our models to be stable - small changes in the training data shouldn’t cause dramatic changes in predictions.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n\n\n\n\nLet’s visualize what stability means with a simple example:\n\ndef generate_data(n_samples=100):\n    X = np.linspace(0, 10, n_samples).reshape(-1, 1)\n    y = 0.5 * X.ravel() + np.sin(X.ravel()) + np.random.normal(0, 0.1, n_samples)\n    return X, y\n\ndef plot_stability_comparison(alpha1=0.1, alpha2=10.0):\n    X, y = generate_data()\n    \n    # Create two models with different regularization\n    model1 = Ridge(alpha=alpha1)\n    model2 = Ridge(alpha=alpha2)\n    \n    # Fit models\n    model1.fit(X, y)\n    model2.fit(X, y)\n    \n    # Generate predictions\n    X_test = np.linspace(0, 10, 200).reshape(-1, 1)\n    y_pred1 = model1.predict(X_test)\n    y_pred2 = model2.predict(X_test)\n    \n    # Plot results\n    plt.figure(figsize=(12, 6))\n    plt.scatter(X, y, color='blue', alpha=0.5, label='Data points')\n    plt.plot(X_test, y_pred1, 'r-', label=f'Less stable (α={alpha1})')\n    plt.plot(X_test, y_pred2, 'g-', label=f'More stable (α={alpha2})')\n    plt.title('Stability Comparison: Effect of Regularization')\n    plt.xlabel('X')\n    plt.ylabel('y')\n    plt.legend()\n    plt.show()\n\nplot_stability_comparison()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey Insight\n\n\n\nNotice how the more stable model (green line) is less sensitive to individual data points, while the less stable model (red line) overfits to the noise in the data.\n\n\n\n\n\n\n\nHypothesis stability:\n\\[\n|\\ell(A_S,z) - \\ell(A_{S^i},z)| \\leq \\beta_m\n\\]\nWhere: - \\(A_S\\) is algorithm output on dataset \\(S\\) - \\(S^i\\) is dataset with i-th example replaced - \\(\\beta_m\\) is stability coefficient\nUniform stability:\n\\[\n\\sup_{S,z,i}|\\ell(A_S,z) - \\ell(A_{S^i},z)| \\leq \\beta\n\\]\n\n\n\nPoint-wise loss stability:\n\\[\n|\\ell(h_S,z) - \\ell(h_{S^i},z)| \\leq \\beta\n\\]\nAverage loss stability:\n\\[\n|\\mathbb{E}_{z \\sim \\mathcal{D}}[\\ell(h_S,z) - \\ell(h_{S^i},z)]| \\leq \\beta\n\\]\n\n\n\nMcDiarmid’s inequality based bound:\n\\[\nP(|R(A_S) - \\hat{R}_S(A_S)| &gt; \\epsilon) \\leq 2\\exp(-\\frac{2m\\epsilon^2}{(4\\beta)^2})\n\\]\nExpected generalization error:\n\\[\n|\\mathbb{E}[R(A_S) - \\hat{R}_S(A_S)]| \\leq \\beta\n\\]\n\n\n\n\n\n\nDefinition:\n\\[\n\\sup_{S,S': |S \\triangle S'| = 2}\\|A_S - A_{S'}\\| \\leq \\beta_m\n\\]\nGeneralization bound:\n\\[\nP(|R(A_S) - \\hat{R}_S(A_S)| &gt; \\epsilon) \\leq 2\\exp(-\\frac{m\\epsilon^2}{2\\beta_m^2})\n\\]\n\n\n\nLeave-one-out stability:\n\\[\n|\\mathbb{E}_{S,z}[\\ell(A_S,z) - \\ell(A_{S^{-i}},z)]| \\leq \\beta_m\n\\]\nk-fold stability:\n\\[\n|\\mathbb{E}_{S,z}[\\ell(A_S,z) - \\ell(A_{S_k},z)]| \\leq \\beta_m\n\\]\n\n\n\n\\((K,\\epsilon(\\cdot))\\)-robustness:\n\\[\nP_{S,z}(|\\ell(A_S,z) - \\ell(A_S,z')| &gt; \\epsilon(m)) \\leq K/m\n\\]\nWhere: - \\(z,z'\\) are in same partition - \\(K\\) is number of partitions - \\(\\epsilon(m)\\) is robustness parameter\n\n\n\n\n\n\nTikhonov regularization:\n\\[\nA_S = \\arg\\min_{h \\in \\mathcal{H}} \\frac{1}{m}\\sum_{i=1}^m \\ell(h,z_i) + \\lambda\\|h\\|^2\n\\]\nStability bound:\n\\[\n\\beta \\leq \\frac{L^2}{2m\\lambda}\n\\]\nWhere: - \\(L\\) is Lipschitz constant - \\(\\lambda\\) is regularization parameter\n\n\n\nGradient descent stability:\n\\[\n\\|w_t - w_t'\\| \\leq (1+\\eta L)^t\\|w_0 - w_0'\\|\n\\]\nSGD stability:\n\\[\n\\mathbb{E}[\\|w_t - w_t'\\|^2] \\leq \\frac{\\eta^2L^2}{2m}\n\\]\n\n\n\nBagging stability:\n\\[\n\\beta_{\\text{bag}} \\leq \\frac{\\beta}{\\sqrt{B}}\n\\]\nWhere: - \\(B\\) is number of bootstrap samples - \\(\\beta\\) is base learner stability\n\n\n\n\nLet’s implement some stability measures and visualize them:\n\n\nCode\nclass StabilityAnalyzer:\n    def __init__(self, model_class, **model_params):\n        self.model_class = model_class\n        self.model_params = model_params\n        \n    def measure_hypothesis_stability(self, X, y, n_perturbations=10):\n        \"\"\"Measure hypothesis stability by perturbing data points\"\"\"\n        m = len(X)\n        stabilities = []\n        \n        # Original model\n        base_model = self.model_class(**self.model_params)\n        base_model.fit(X, y)\n        base_preds = base_model.predict(X)\n        \n        for _ in range(n_perturbations):\n            # Randomly replace one point\n            idx = np.random.randint(m)\n            X_perturbed = X.copy()\n            y_perturbed = y.copy()\n            \n            # Add small noise to selected point\n            X_perturbed[idx] += np.random.normal(0, 0.1, X.shape[1])\n            \n            # Train perturbed model\n            perturbed_model = self.model_class(**self.model_params)\n            perturbed_model.fit(X_perturbed, y_perturbed)\n            perturbed_preds = perturbed_model.predict(X)\n            \n            # Calculate stability measure\n            stability = np.mean(np.abs(base_preds - perturbed_preds))\n            stabilities.append(stability)\n            \n        return np.mean(stabilities), np.std(stabilities)\n\n# Example usage with Ridge Regression\ndef compare_model_stability():\n    # Generate synthetic data\n    np.random.seed(42)\n    X = np.random.randn(100, 2)\n    y = 0.5 * X[:, 0] + 0.3 * X[:, 1] + np.random.normal(0, 0.1, 100)\n    \n    # Compare stability with different regularization strengths\n    alphas = [0.01, 0.1, 1.0, 10.0]\n    stabilities = []\n    errors = []\n    \n    for alpha in alphas:\n        analyzer = StabilityAnalyzer(Ridge, alpha=alpha)\n        stability, error = analyzer.measure_hypothesis_stability(X, y)\n        stabilities.append(stability)\n        errors.append(error)\n    \n    # Plot results\n    plt.figure(figsize=(10, 6))\n    plt.errorbar(alphas, stabilities, yerr=errors, fmt='o-', capsize=5)\n    plt.xscale('log')\n    plt.xlabel('Regularization Strength (α)')\n    plt.ylabel('Stability Measure')\n    plt.title('Model Stability vs Regularization')\n    plt.grid(True, alpha=0.3)\n    plt.show()\n\ncompare_model_stability()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting Stability Results\n\n\n\nLower values indicate more stable models. Notice how increasing regularization generally improves stability.\n\n\n\n\n\nLet’s visualize how different cross-validation strategies affect stability:\n\n\nCode\ndef analyze_cv_stability(n_splits=[2, 5, 10], n_repeats=10):\n    \"\"\"Analyze stability across different CV splits\"\"\"\n    from sklearn.model_selection import KFold\n    \n    # Generate data\n    X = np.random.randn(200, 2)\n    y = 0.5 * X[:, 0] + 0.3 * X[:, 1] + np.random.normal(0, 0.1, 200)\n    \n    results = {k: [] for k in n_splits}\n    \n    for k in n_splits:\n        for _ in range(n_repeats):\n            # Create k-fold split\n            kf = KFold(n_splits=k, shuffle=True)\n            fold_scores = []\n            \n            for train_idx, val_idx in kf.split(X):\n                # Train model\n                model = Ridge(alpha=1.0)\n                model.fit(X[train_idx], y[train_idx])\n                \n                # Get score\n                score = model.score(X[val_idx], y[val_idx])\n                fold_scores.append(score)\n            \n            # Calculate stability of scores\n            results[k].append(np.std(fold_scores))\n    \n    # Plot results\n    plt.figure(figsize=(10, 6))\n    plt.boxplot([results[k] for k in n_splits], labels=[f'{k}-fold' for k in n_splits])\n    plt.ylabel('Score Stability (std)')\n    plt.xlabel('Cross-Validation Strategy')\n    plt.title('Cross-Validation Stability Analysis')\n    plt.grid(True, alpha=0.3)\n    plt.show()\n\nanalyze_cv_stability()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCross-Validation Insight\n\n\n\nMore folds generally lead to more stable results but require more computational resources.\n\n\n\n\n\nLet’s implement and visualize the stability of ensemble methods:\n\n\nCode\ndef analyze_ensemble_stability(n_estimators=[1, 5, 10, 20]):\n    \"\"\"Analyze how ensemble size affects stability\"\"\"\n    from sklearn.ensemble import BaggingRegressor\n    \n    # Generate data\n    X = np.random.randn(150, 2)\n    y = 0.5 * X[:, 0] + 0.3 * X[:, 1] + np.random.normal(0, 0.1, 150)\n    \n    # Test data for stability measurement\n    X_test = np.random.randn(50, 2)\n    \n    stabilities = []\n    errors = []\n    \n    for n in n_estimators:\n        # Create multiple ensembles with same size\n        predictions = []\n        for _ in range(10):\n            model = BaggingRegressor(\n                estimator=Ridge(alpha=1.0),\n                n_estimators=n,\n                random_state=None\n            )\n            model.fit(X, y)\n            predictions.append(model.predict(X_test))\n        \n        # Calculate stability across different ensemble instances\n        stability = np.mean([np.std(pred) for pred in zip(*predictions)])\n        error = np.std([np.std(pred) for pred in zip(*predictions)])\n        \n        stabilities.append(stability)\n        errors.append(error)\n    \n    # Plot results\n    plt.figure(figsize=(10, 6))\n    plt.errorbar(n_estimators, stabilities, yerr=errors, fmt='o-', capsize=5)\n    plt.xlabel('Number of Estimators')\n    plt.ylabel('Prediction Stability')\n    plt.title('Ensemble Size vs. Prediction Stability')\n    plt.grid(True, alpha=0.3)\n    plt.show()\n\nanalyze_ensemble_stability()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsemble Benefits\n\n\n\nLarger ensembles tend to have more stable predictions, demonstrating the “wisdom of crowds” effect.\n\n\n\n\n\n\n\nRidge regression stability:\n\\[\n\\beta_{\\text{ridge}} \\leq \\frac{4M^2}{m\\lambda}\n\\]\nWhere: - \\(M\\) is bound on features - \\(\\lambda\\) is regularization\n\n\n\nOnline stability:\n\\[\n\\mathbb{E}[\\|w_t - w_t'\\|] \\leq \\frac{2G}{\\lambda\\sqrt{t}}\n\\]\nWhere: - \\(G\\) is gradient bound - \\(t\\) is iteration number\n\n\n\nDropout stability:\n\\[\n\\beta_{\\text{dropout}} \\leq \\frac{p(1-p)L^2}{m}\n\\]\nWhere: - \\(p\\) is dropout probability - \\(L\\) is network Lipschitz constant\n\n\n\n\n\n\nDefinition:\n\\[\n|\\ell(A_S,z) - \\ell(A_{S^i},z)| \\leq \\beta(z)\n\\]\nAdaptive bound:\n\\[\nP(|R(A_S) - \\hat{R}_S(A_S)| &gt; \\epsilon) \\leq 2\\exp(-\\frac{2m\\epsilon^2}{\\mathbb{E}[\\beta(Z)^2]})\n\\]\n\n\n\nDefinition:\n\\[\n\\|\\mathcal{D}_{A_S} - \\mathcal{D}_{A_{S^i}}\\|_1 \\leq \\beta\n\\]\nGeneralization:\n\\[\n|\\mathbb{E}[R(A_S)] - \\mathbb{E}[\\hat{R}_S(A_S)]| \\leq \\beta\n\\]\n\n\n\nDifferential privacy:\n\\[\nP(A_S \\in E) \\leq e^\\epsilon P(A_{S'} \\in E)\n\\]\nPrivacy-stability relationship:\n\\[\n\\beta \\leq \\epsilon L\n\\]\n\n\n\n\n\n\nRelationships:\n\\[\n\\text{Uniform} \\implies \\text{Hypothesis} \\implies \\text{Point-wise} \\implies \\text{Average}\n\\]\nEquivalence conditions:\n\\[\n\\beta_{\\text{uniform}} = \\beta_{\\text{hypothesis}} \\iff \\text{convex loss}\n\\]\n\n\n\nMinimal stability:\n\\[\n\\beta_m \\geq \\Omega(\\frac{1}{\\sqrt{m}})\n\\]\nOptimal rates:\n\\[\n\\beta_m = \\Theta(\\frac{1}{m})\n\\]\n\n\n\nSerial composition:\n\\[\n\\beta_{A \\circ B} \\leq \\beta_A + \\beta_B\n\\]\nParallel composition:\n\\[\n\\beta_{\\text{parallel}} \\leq \\max_i \\beta_i\n\\]\n\n\n\n\n\n\n\nRegularization:\n\nChoose appropriate \\(\\lambda\\)\nBalance stability-accuracy\nAdaptive regularization\n\nOptimization:\n\nStep size selection\nBatch size impact\nMomentum effects\n\nArchitecture:\n\nLayer stability\nSkip connections\nNormalization impact\n\n\n\n\n\n\nEmpirical Stability:\n\nLeave-one-out estimates\nBootstrap estimates\nCross-validation\n\nTheoretical Bounds:\n\nLipschitz constants\nCondition numbers\nSpectral norms\n\nMonitoring:\n\nStability metrics\nGeneralization gaps\nValidation curves\n\n\n\n\n\n\n\n\n\nStability Analysis:\n\nCross-validation stability\nParameter sensitivity\nModel robustness\n\nRegularization:\n\nMultiple techniques\nAdaptive schemes\nStability-based selection\n\nValidation:\n\nStability metrics\nGeneralization bounds\nRobustness checks\n\n\n\n\n\n\nOptimization:\n\nStable algorithms\nAdaptive methods\nEarly stopping\n\nData Processing:\n\nRobust preprocessing\nFeature stability\nOutlier handling\n\nEvaluation:\n\nStability measures\nConfidence bounds\nSensitivity analysis\n\n\n\n\n\n\nLet’s create an interactive tool to measure stability:\n\ndef measure_stability(model, X, y, n_perturbations=10):\n    predictions = []\n    for _ in range(n_perturbations):\n        # Add small random noise to data\n        X_perturbed = X + np.random.normal(0, 0.1, X.shape)\n        model.fit(X_perturbed, y)\n        predictions.append(model.predict(X))\n    \n    # Calculate stability score (lower is more stable)\n    stability_score = np.std(predictions, axis=0).mean()\n    return stability_score\n\n# Compare stability of different models\nX, y = generate_data()\nmodels = {\n    'Ridge (α=0.1)': Ridge(alpha=0.1),\n    'Ridge (α=1.0)': Ridge(alpha=1.0),\n    'Ridge (α=10.0)': Ridge(alpha=10.0)\n}\n\nfor name, model in models.items():\n    score = measure_stability(model, X, y)\n    print(f\"{name} stability score: {score:.4f}\")\n\nRidge (α=0.1) stability score: 0.0078\nRidge (α=1.0) stability score: 0.0060\nRidge (α=10.0) stability score: 0.0065\n\n\n\n\n\nHere’s a practical implementation of stability monitoring:\n\nclass StabilityMonitor:\n    def __init__(self, model, threshold=0.1):\n        self.model = model\n        self.threshold = threshold\n        self.history = []\n    \n    def check_stability(self, X, y, n_splits=5):\n        from sklearn.model_selection import KFold\n        predictions = []\n        kf = KFold(n_splits=n_splits, shuffle=True)\n        \n        for train_idx, _ in kf.split(X):\n            X_subset = X[train_idx]\n            y_subset = y[train_idx]\n            self.model.fit(X_subset, y_subset)\n            predictions.append(self.model.predict(X))\n        \n        stability_score = np.std(predictions, axis=0).mean()\n        self.history.append(stability_score)\n        \n        return stability_score &lt;= self.threshold\n\n# Example usage\nmonitor = StabilityMonitor(Ridge(alpha=1.0))\nis_stable = monitor.check_stability(X, y)\nprint(f\"Model is stable: {is_stable}\")\n\nModel is stable: True\n\n\n\n\n\n\nTheory:\n\n“Stability and Generalization” by Bousquet and Elisseeff\n“Learning, Testing, and the Stability Approach” by Shalev-Shwartz et al.\n“Stability and Learning Theory” by Mukherjee et al.\n\nMethods:\n\n“Algorithmic Stability and Uniform Convergence” by Kearns and Ron\n“Stability and Instance-Based Learning” by Devroye and Wagner\n“Stable Learning Algorithms” by Kutin and Niyogi\n\nApplications:\n\n“Stability in Machine Learning” by Hardt et al.\n“Deep Learning and Stability” by Hardt and Ma\n“Stability-Based Generalization Analysis” by Poggio et al."
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#introduction",
    "href": "posts/algorithmic-stability/index.html#introduction",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Imagine building a house of cards . If a slight breeze can topple it, we’d say it’s unstable. Similarly, in machine learning, we want our models to be stable - small changes in the training data shouldn’t cause dramatic changes in predictions.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import Ridge\nfrom sklearn.preprocessing import StandardScaler\n\n# Set random seed for reproducibility\nnp.random.seed(42)"
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#understanding-stability-through-examples",
    "href": "posts/algorithmic-stability/index.html#understanding-stability-through-examples",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Let’s visualize what stability means with a simple example:\n\ndef generate_data(n_samples=100):\n    X = np.linspace(0, 10, n_samples).reshape(-1, 1)\n    y = 0.5 * X.ravel() + np.sin(X.ravel()) + np.random.normal(0, 0.1, n_samples)\n    return X, y\n\ndef plot_stability_comparison(alpha1=0.1, alpha2=10.0):\n    X, y = generate_data()\n    \n    # Create two models with different regularization\n    model1 = Ridge(alpha=alpha1)\n    model2 = Ridge(alpha=alpha2)\n    \n    # Fit models\n    model1.fit(X, y)\n    model2.fit(X, y)\n    \n    # Generate predictions\n    X_test = np.linspace(0, 10, 200).reshape(-1, 1)\n    y_pred1 = model1.predict(X_test)\n    y_pred2 = model2.predict(X_test)\n    \n    # Plot results\n    plt.figure(figsize=(12, 6))\n    plt.scatter(X, y, color='blue', alpha=0.5, label='Data points')\n    plt.plot(X_test, y_pred1, 'r-', label=f'Less stable (α={alpha1})')\n    plt.plot(X_test, y_pred2, 'g-', label=f'More stable (α={alpha2})')\n    plt.title('Stability Comparison: Effect of Regularization')\n    plt.xlabel('X')\n    plt.ylabel('y')\n    plt.legend()\n    plt.show()\n\nplot_stability_comparison()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey Insight\n\n\n\nNotice how the more stable model (green line) is less sensitive to individual data points, while the less stable model (red line) overfits to the noise in the data."
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#fundamental-concepts",
    "href": "posts/algorithmic-stability/index.html#fundamental-concepts",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Hypothesis stability:\n\\[\n|\\ell(A_S,z) - \\ell(A_{S^i},z)| \\leq \\beta_m\n\\]\nWhere: - \\(A_S\\) is algorithm output on dataset \\(S\\) - \\(S^i\\) is dataset with i-th example replaced - \\(\\beta_m\\) is stability coefficient\nUniform stability:\n\\[\n\\sup_{S,z,i}|\\ell(A_S,z) - \\ell(A_{S^i},z)| \\leq \\beta\n\\]\n\n\n\nPoint-wise loss stability:\n\\[\n|\\ell(h_S,z) - \\ell(h_{S^i},z)| \\leq \\beta\n\\]\nAverage loss stability:\n\\[\n|\\mathbb{E}_{z \\sim \\mathcal{D}}[\\ell(h_S,z) - \\ell(h_{S^i},z)]| \\leq \\beta\n\\]\n\n\n\nMcDiarmid’s inequality based bound:\n\\[\nP(|R(A_S) - \\hat{R}_S(A_S)| &gt; \\epsilon) \\leq 2\\exp(-\\frac{2m\\epsilon^2}{(4\\beta)^2})\n\\]\nExpected generalization error:\n\\[\n|\\mathbb{E}[R(A_S) - \\hat{R}_S(A_S)]| \\leq \\beta\n\\]"
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#types-of-stability",
    "href": "posts/algorithmic-stability/index.html#types-of-stability",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Definition:\n\\[\n\\sup_{S,S': |S \\triangle S'| = 2}\\|A_S - A_{S'}\\| \\leq \\beta_m\n\\]\nGeneralization bound:\n\\[\nP(|R(A_S) - \\hat{R}_S(A_S)| &gt; \\epsilon) \\leq 2\\exp(-\\frac{m\\epsilon^2}{2\\beta_m^2})\n\\]\n\n\n\nLeave-one-out stability:\n\\[\n|\\mathbb{E}_{S,z}[\\ell(A_S,z) - \\ell(A_{S^{-i}},z)]| \\leq \\beta_m\n\\]\nk-fold stability:\n\\[\n|\\mathbb{E}_{S,z}[\\ell(A_S,z) - \\ell(A_{S_k},z)]| \\leq \\beta_m\n\\]\n\n\n\n\\((K,\\epsilon(\\cdot))\\)-robustness:\n\\[\nP_{S,z}(|\\ell(A_S,z) - \\ell(A_S,z')| &gt; \\epsilon(m)) \\leq K/m\n\\]\nWhere: - \\(z,z'\\) are in same partition - \\(K\\) is number of partitions - \\(\\epsilon(m)\\) is robustness parameter"
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#stability-analysis",
    "href": "posts/algorithmic-stability/index.html#stability-analysis",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Tikhonov regularization:\n\\[\nA_S = \\arg\\min_{h \\in \\mathcal{H}} \\frac{1}{m}\\sum_{i=1}^m \\ell(h,z_i) + \\lambda\\|h\\|^2\n\\]\nStability bound:\n\\[\n\\beta \\leq \\frac{L^2}{2m\\lambda}\n\\]\nWhere: - \\(L\\) is Lipschitz constant - \\(\\lambda\\) is regularization parameter\n\n\n\nGradient descent stability:\n\\[\n\\|w_t - w_t'\\| \\leq (1+\\eta L)^t\\|w_0 - w_0'\\|\n\\]\nSGD stability:\n\\[\n\\mathbb{E}[\\|w_t - w_t'\\|^2] \\leq \\frac{\\eta^2L^2}{2m}\n\\]\n\n\n\nBagging stability:\n\\[\n\\beta_{\\text{bag}} \\leq \\frac{\\beta}{\\sqrt{B}}\n\\]\nWhere: - \\(B\\) is number of bootstrap samples - \\(\\beta\\) is base learner stability"
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#practical-stability-analysis",
    "href": "posts/algorithmic-stability/index.html#practical-stability-analysis",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Let’s implement some stability measures and visualize them:\n\n\nCode\nclass StabilityAnalyzer:\n    def __init__(self, model_class, **model_params):\n        self.model_class = model_class\n        self.model_params = model_params\n        \n    def measure_hypothesis_stability(self, X, y, n_perturbations=10):\n        \"\"\"Measure hypothesis stability by perturbing data points\"\"\"\n        m = len(X)\n        stabilities = []\n        \n        # Original model\n        base_model = self.model_class(**self.model_params)\n        base_model.fit(X, y)\n        base_preds = base_model.predict(X)\n        \n        for _ in range(n_perturbations):\n            # Randomly replace one point\n            idx = np.random.randint(m)\n            X_perturbed = X.copy()\n            y_perturbed = y.copy()\n            \n            # Add small noise to selected point\n            X_perturbed[idx] += np.random.normal(0, 0.1, X.shape[1])\n            \n            # Train perturbed model\n            perturbed_model = self.model_class(**self.model_params)\n            perturbed_model.fit(X_perturbed, y_perturbed)\n            perturbed_preds = perturbed_model.predict(X)\n            \n            # Calculate stability measure\n            stability = np.mean(np.abs(base_preds - perturbed_preds))\n            stabilities.append(stability)\n            \n        return np.mean(stabilities), np.std(stabilities)\n\n# Example usage with Ridge Regression\ndef compare_model_stability():\n    # Generate synthetic data\n    np.random.seed(42)\n    X = np.random.randn(100, 2)\n    y = 0.5 * X[:, 0] + 0.3 * X[:, 1] + np.random.normal(0, 0.1, 100)\n    \n    # Compare stability with different regularization strengths\n    alphas = [0.01, 0.1, 1.0, 10.0]\n    stabilities = []\n    errors = []\n    \n    for alpha in alphas:\n        analyzer = StabilityAnalyzer(Ridge, alpha=alpha)\n        stability, error = analyzer.measure_hypothesis_stability(X, y)\n        stabilities.append(stability)\n        errors.append(error)\n    \n    # Plot results\n    plt.figure(figsize=(10, 6))\n    plt.errorbar(alphas, stabilities, yerr=errors, fmt='o-', capsize=5)\n    plt.xscale('log')\n    plt.xlabel('Regularization Strength (α)')\n    plt.ylabel('Stability Measure')\n    plt.title('Model Stability vs Regularization')\n    plt.grid(True, alpha=0.3)\n    plt.show()\n\ncompare_model_stability()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpreting Stability Results\n\n\n\nLower values indicate more stable models. Notice how increasing regularization generally improves stability."
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#cross-validation-stability-1",
    "href": "posts/algorithmic-stability/index.html#cross-validation-stability-1",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Let’s visualize how different cross-validation strategies affect stability:\n\n\nCode\ndef analyze_cv_stability(n_splits=[2, 5, 10], n_repeats=10):\n    \"\"\"Analyze stability across different CV splits\"\"\"\n    from sklearn.model_selection import KFold\n    \n    # Generate data\n    X = np.random.randn(200, 2)\n    y = 0.5 * X[:, 0] + 0.3 * X[:, 1] + np.random.normal(0, 0.1, 200)\n    \n    results = {k: [] for k in n_splits}\n    \n    for k in n_splits:\n        for _ in range(n_repeats):\n            # Create k-fold split\n            kf = KFold(n_splits=k, shuffle=True)\n            fold_scores = []\n            \n            for train_idx, val_idx in kf.split(X):\n                # Train model\n                model = Ridge(alpha=1.0)\n                model.fit(X[train_idx], y[train_idx])\n                \n                # Get score\n                score = model.score(X[val_idx], y[val_idx])\n                fold_scores.append(score)\n            \n            # Calculate stability of scores\n            results[k].append(np.std(fold_scores))\n    \n    # Plot results\n    plt.figure(figsize=(10, 6))\n    plt.boxplot([results[k] for k in n_splits], labels=[f'{k}-fold' for k in n_splits])\n    plt.ylabel('Score Stability (std)')\n    plt.xlabel('Cross-Validation Strategy')\n    plt.title('Cross-Validation Stability Analysis')\n    plt.grid(True, alpha=0.3)\n    plt.show()\n\nanalyze_cv_stability()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCross-Validation Insight\n\n\n\nMore folds generally lead to more stable results but require more computational resources."
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#ensemble-stability",
    "href": "posts/algorithmic-stability/index.html#ensemble-stability",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Let’s implement and visualize the stability of ensemble methods:\n\n\nCode\ndef analyze_ensemble_stability(n_estimators=[1, 5, 10, 20]):\n    \"\"\"Analyze how ensemble size affects stability\"\"\"\n    from sklearn.ensemble import BaggingRegressor\n    \n    # Generate data\n    X = np.random.randn(150, 2)\n    y = 0.5 * X[:, 0] + 0.3 * X[:, 1] + np.random.normal(0, 0.1, 150)\n    \n    # Test data for stability measurement\n    X_test = np.random.randn(50, 2)\n    \n    stabilities = []\n    errors = []\n    \n    for n in n_estimators:\n        # Create multiple ensembles with same size\n        predictions = []\n        for _ in range(10):\n            model = BaggingRegressor(\n                estimator=Ridge(alpha=1.0),\n                n_estimators=n,\n                random_state=None\n            )\n            model.fit(X, y)\n            predictions.append(model.predict(X_test))\n        \n        # Calculate stability across different ensemble instances\n        stability = np.mean([np.std(pred) for pred in zip(*predictions)])\n        error = np.std([np.std(pred) for pred in zip(*predictions)])\n        \n        stabilities.append(stability)\n        errors.append(error)\n    \n    # Plot results\n    plt.figure(figsize=(10, 6))\n    plt.errorbar(n_estimators, stabilities, yerr=errors, fmt='o-', capsize=5)\n    plt.xlabel('Number of Estimators')\n    plt.ylabel('Prediction Stability')\n    plt.title('Ensemble Size vs. Prediction Stability')\n    plt.grid(True, alpha=0.3)\n    plt.show()\n\nanalyze_ensemble_stability()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEnsemble Benefits\n\n\n\nLarger ensembles tend to have more stable predictions, demonstrating the “wisdom of crowds” effect."
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#applications",
    "href": "posts/algorithmic-stability/index.html#applications",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Ridge regression stability:\n\\[\n\\beta_{\\text{ridge}} \\leq \\frac{4M^2}{m\\lambda}\n\\]\nWhere: - \\(M\\) is bound on features - \\(\\lambda\\) is regularization\n\n\n\nOnline stability:\n\\[\n\\mathbb{E}[\\|w_t - w_t'\\|] \\leq \\frac{2G}{\\lambda\\sqrt{t}}\n\\]\nWhere: - \\(G\\) is gradient bound - \\(t\\) is iteration number\n\n\n\nDropout stability:\n\\[\n\\beta_{\\text{dropout}} \\leq \\frac{p(1-p)L^2}{m}\n\\]\nWhere: - \\(p\\) is dropout probability - \\(L\\) is network Lipschitz constant"
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#advanced-topics",
    "href": "posts/algorithmic-stability/index.html#advanced-topics",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Definition:\n\\[\n|\\ell(A_S,z) - \\ell(A_{S^i},z)| \\leq \\beta(z)\n\\]\nAdaptive bound:\n\\[\nP(|R(A_S) - \\hat{R}_S(A_S)| &gt; \\epsilon) \\leq 2\\exp(-\\frac{2m\\epsilon^2}{\\mathbb{E}[\\beta(Z)^2]})\n\\]\n\n\n\nDefinition:\n\\[\n\\|\\mathcal{D}_{A_S} - \\mathcal{D}_{A_{S^i}}\\|_1 \\leq \\beta\n\\]\nGeneralization:\n\\[\n|\\mathbb{E}[R(A_S)] - \\mathbb{E}[\\hat{R}_S(A_S)]| \\leq \\beta\n\\]\n\n\n\nDifferential privacy:\n\\[\nP(A_S \\in E) \\leq e^\\epsilon P(A_{S'} \\in E)\n\\]\nPrivacy-stability relationship:\n\\[\n\\beta \\leq \\epsilon L\n\\]"
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#theoretical-results",
    "href": "posts/algorithmic-stability/index.html#theoretical-results",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Relationships:\n\\[\n\\text{Uniform} \\implies \\text{Hypothesis} \\implies \\text{Point-wise} \\implies \\text{Average}\n\\]\nEquivalence conditions:\n\\[\n\\beta_{\\text{uniform}} = \\beta_{\\text{hypothesis}} \\iff \\text{convex loss}\n\\]\n\n\n\nMinimal stability:\n\\[\n\\beta_m \\geq \\Omega(\\frac{1}{\\sqrt{m}})\n\\]\nOptimal rates:\n\\[\n\\beta_m = \\Theta(\\frac{1}{m})\n\\]\n\n\n\nSerial composition:\n\\[\n\\beta_{A \\circ B} \\leq \\beta_A + \\beta_B\n\\]\nParallel composition:\n\\[\n\\beta_{\\text{parallel}} \\leq \\max_i \\beta_i\n\\]"
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#implementation-considerations",
    "href": "posts/algorithmic-stability/index.html#implementation-considerations",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Regularization:\n\nChoose appropriate \\(\\lambda\\)\nBalance stability-accuracy\nAdaptive regularization\n\nOptimization:\n\nStep size selection\nBatch size impact\nMomentum effects\n\nArchitecture:\n\nLayer stability\nSkip connections\nNormalization impact\n\n\n\n\n\n\nEmpirical Stability:\n\nLeave-one-out estimates\nBootstrap estimates\nCross-validation\n\nTheoretical Bounds:\n\nLipschitz constants\nCondition numbers\nSpectral norms\n\nMonitoring:\n\nStability metrics\nGeneralization gaps\nValidation curves"
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#best-practices",
    "href": "posts/algorithmic-stability/index.html#best-practices",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Stability Analysis:\n\nCross-validation stability\nParameter sensitivity\nModel robustness\n\nRegularization:\n\nMultiple techniques\nAdaptive schemes\nStability-based selection\n\nValidation:\n\nStability metrics\nGeneralization bounds\nRobustness checks\n\n\n\n\n\n\nOptimization:\n\nStable algorithms\nAdaptive methods\nEarly stopping\n\nData Processing:\n\nRobust preprocessing\nFeature stability\nOutlier handling\n\nEvaluation:\n\nStability measures\nConfidence bounds\nSensitivity analysis"
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#interactive-stability-analysis",
    "href": "posts/algorithmic-stability/index.html#interactive-stability-analysis",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Let’s create an interactive tool to measure stability:\n\ndef measure_stability(model, X, y, n_perturbations=10):\n    predictions = []\n    for _ in range(n_perturbations):\n        # Add small random noise to data\n        X_perturbed = X + np.random.normal(0, 0.1, X.shape)\n        model.fit(X_perturbed, y)\n        predictions.append(model.predict(X))\n    \n    # Calculate stability score (lower is more stable)\n    stability_score = np.std(predictions, axis=0).mean()\n    return stability_score\n\n# Compare stability of different models\nX, y = generate_data()\nmodels = {\n    'Ridge (α=0.1)': Ridge(alpha=0.1),\n    'Ridge (α=1.0)': Ridge(alpha=1.0),\n    'Ridge (α=10.0)': Ridge(alpha=10.0)\n}\n\nfor name, model in models.items():\n    score = measure_stability(model, X, y)\n    print(f\"{name} stability score: {score:.4f}\")\n\nRidge (α=0.1) stability score: 0.0078\nRidge (α=1.0) stability score: 0.0060\nRidge (α=10.0) stability score: 0.0065"
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#code-implementation",
    "href": "posts/algorithmic-stability/index.html#code-implementation",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Here’s a practical implementation of stability monitoring:\n\nclass StabilityMonitor:\n    def __init__(self, model, threshold=0.1):\n        self.model = model\n        self.threshold = threshold\n        self.history = []\n    \n    def check_stability(self, X, y, n_splits=5):\n        from sklearn.model_selection import KFold\n        predictions = []\n        kf = KFold(n_splits=n_splits, shuffle=True)\n        \n        for train_idx, _ in kf.split(X):\n            X_subset = X[train_idx]\n            y_subset = y[train_idx]\n            self.model.fit(X_subset, y_subset)\n            predictions.append(self.model.predict(X))\n        \n        stability_score = np.std(predictions, axis=0).mean()\n        self.history.append(stability_score)\n        \n        return stability_score &lt;= self.threshold\n\n# Example usage\nmonitor = StabilityMonitor(Ridge(alpha=1.0))\nis_stable = monitor.check_stability(X, y)\nprint(f\"Model is stable: {is_stable}\")\n\nModel is stable: True"
  },
  {
    "objectID": "posts/algorithmic-stability/index.html#references",
    "href": "posts/algorithmic-stability/index.html#references",
    "title": "Algorithmic Stability and Learning Theory",
    "section": "",
    "text": "Theory:\n\n“Stability and Generalization” by Bousquet and Elisseeff\n“Learning, Testing, and the Stability Approach” by Shalev-Shwartz et al.\n“Stability and Learning Theory” by Mukherjee et al.\n\nMethods:\n\n“Algorithmic Stability and Uniform Convergence” by Kearns and Ron\n“Stability and Instance-Based Learning” by Devroye and Wagner\n“Stable Learning Algorithms” by Kutin and Niyogi\n\nApplications:\n\n“Stability in Machine Learning” by Hardt et al.\n“Deep Learning and Stability” by Hardt and Ma\n“Stability-Based Generalization Analysis” by Poggio et al."
  },
  {
    "objectID": "posts/pac-learning-theory/index.html",
    "href": "posts/pac-learning-theory/index.html",
    "title": "PAC Learning Theory and VC Dimension",
    "section": "",
    "text": "Learning Objectives\n\n\n\nBy the end of this article, you will: 1. Understand PAC learning intuitively and mathematically 2. Visualize VC dimension in practice 3. Calculate sample complexity for real problems 4. Implement PAC learning algorithms 5. Apply VC theory to model selection\n\n\n\n\nImagine you’re teaching a robot to recognize apples . How can you be “probably approximately correct” about its ability to recognize any apple? PAC learning theory gives us the mathematical framework to answer such questions.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import make_classification, make_circles\nfrom sklearn.model_selection import learning_curve\nimport time\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n\n\n\n\nLet’s visualize what “probably approximately correct” means:\n\ndef visualize_pac_learning(n_samples=100, noise_level=0.1):\n    # Generate synthetic dataset\n    X, y = make_circles(n_samples=n_samples, noise=noise_level, factor=0.3)\n    \n    # Train models with different sample sizes\n    sample_sizes = [10, 30, 50, n_samples]\n    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n    axes = axes.ravel()\n    \n    for i, size in enumerate(sample_sizes):\n        # Train model on subset\n        model = SVC(kernel='rbf')\n        idx = np.random.choice(n_samples, size=size, replace=False)\n        model.fit(X[idx], y[idx])\n        \n        # Create grid for decision boundary\n        xx, yy = np.meshgrid(np.linspace(X[:, 0].min()-0.5, X[:, 0].max()+0.5, 100),\n                            np.linspace(X[:, 1].min()-0.5, X[:, 1].max()+0.5, 100))\n        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n        Z = Z.reshape(xx.shape)\n        \n        # Plot\n        axes[i].contourf(xx, yy, Z, alpha=0.4)\n        axes[i].scatter(X[:, 0], X[:, 1], c=y, alpha=0.8)\n        axes[i].set_title(f'Training samples: {size}')\n    \n    plt.tight_layout()\n    plt.show()\n\nvisualize_pac_learning()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey Insight\n\n\n\nNotice how the decision boundary becomes more stable and accurate as we increase the sample size. This is PAC learning in action!\n\n\n\n\n\nLet’s create an interactive tool to explore VC dimension:\n\ndef explore_vc_dimension(n_points=100):\n    def generate_points(n):\n        return np.random.rand(n, 2)\n    \n    def plot_linear_classifier(ax, points, labels):\n        if len(points) &gt;= 2:\n            model = SVC(kernel='linear')\n            try:\n                model.fit(points, labels)\n                \n                # Plot decision boundary\n                xx, yy = np.meshgrid(np.linspace(0, 1, 100),\n                                   np.linspace(0, 1, 100))\n                Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n                Z = Z.reshape(xx.shape)\n                ax.contourf(xx, yy, Z, alpha=0.4)\n            except:\n                pass\n        \n        # Plot points\n        colors = ['red' if l == 0 else 'blue' for l in labels]\n        ax.scatter(points[:, 0], points[:, 1], c=colors)\n        ax.set_xlim(0, 1)\n        ax.set_ylim(0, 1)\n    \n    # Generate different labelings\n    points = generate_points(3)  # Try with 3 points\n    all_labels = [[int(i) for i in format(j, f'0{3}b')] \n                 for j in range(2**3)]\n    \n    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n    axes = axes.ravel()\n    \n    for i, labels in enumerate(all_labels):\n        plot_linear_classifier(axes[i], points, labels)\n        axes[i].set_title(f'Labeling {i+1}')\n    \n    plt.tight_layout()\n    plt.show()\n\nexplore_vc_dimension()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding VC Dimension\n\n\n\nThe plots above show different possible labelings of 3 points. A linear classifier (VC dimension = 3) can shatter these points in most, but not all configurations.\n\n\n\n\n\n\n\nThe PAC (Probably Approximately Correct) learning framework provides theoretical guarantees for learning algorithms:\n\\[\nP_{S \\sim \\mathcal{D}^m}(\\text{error}_\\mathcal{D}(h_S) \\leq \\epsilon) \\geq 1-\\delta\n\\]\nWhere: - \\(\\epsilon\\) is the accuracy parameter (how close to perfect) - \\(\\delta\\) is the confidence parameter (how sure we are) - \\(m\\) is the sample size - \\(h_S\\) is the learned hypothesis\n\n\n\nThe fundamental bound for sample complexity:\n\\[\nm \\geq \\frac{1}{\\epsilon}\\left(\\ln|\\mathcal{H}| + \\ln\\frac{1}{\\delta}\\right)\n\\]\nFor the realizable case (when perfect classification is possible):\n\\[\nm \\geq \\frac{1}{\\epsilon}\\left(\\ln\\frac{1}{\\delta}\\right)\n\\]\n\n\n\nThe VC dimension of a hypothesis class \\(\\mathcal{H}\\) is the largest number of points that can be shattered (assigned any possible labeling) by \\(\\mathcal{H}\\).\nGrowth function:\n\\[\n\\Pi_\\mathcal{H}(m) = \\max_{x_1,...,x_m \\in \\mathcal{X}}|\\{(h(x_1),...,h(x_m)): h \\in \\mathcal{H}\\}|\n\\]\nSauer’s Lemma:\n\\[\n\\text{If VC}(\\mathcal{H}) = d, \\text{ then } \\Pi_\\mathcal{H}(m) \\leq \\sum_{i=0}^d \\binom{m}{i}\n\\]\n\n\n\nThe fundamental theorem of learning theory:\n\\[\nP(\\sup_{h \\in \\mathcal{H}}|\\text{error}_\\mathcal{D}(h) - \\widehat{\\text{error}}_S(h)| &gt; \\epsilon) \\leq 4\\Pi_\\mathcal{H}(2m)\\exp(-\\frac{m\\epsilon^2}{8})\n\\]\nSample complexity in terms of VC dimension:\n\\[\nm = O\\left(\\frac{d}{\\epsilon^2}\\ln\\frac{1}{\\epsilon} + \\frac{1}{\\epsilon^2}\\ln\\frac{1}{\\delta}\\right)\n\\]\n\n\n\n\n\n\nKey Insight\n\n\n\nThe VC dimension (\\(d\\)) appears in the sample complexity bound, showing how model complexity affects learning guarantees.\n\n\n\n\n\n\n\n\nLet’s make PAC learning concrete with an example:\n\nclass PACLearner:\n    def __init__(self, epsilon=0.1, delta=0.05):\n        self.epsilon = epsilon  # accuracy parameter\n        self.delta = delta    # confidence parameter\n        self.model = None\n    \n    def required_samples(self, vc_dim):\n        \"\"\"Calculate required sample size using VC bound\"\"\"\n        return int(np.ceil((8/self.epsilon) * \n                         (2*vc_dim * np.log2(16/self.epsilon) + \n                          np.log2(2/self.delta))))\n    \n    def fit(self, X, y):\n        \"\"\"Train model with PAC guarantees\"\"\"\n        n_samples = len(X)\n        required = self.required_samples(vc_dim=3)  # for linear classifier\n        \n        if n_samples &lt; required:\n            print(f\"Warning: Need at least {required} samples for PAC guarantees\")\n        \n        self.model = SVC(kernel='linear')\n        self.model.fit(X, y)\n        return self\n    \n    def predict(self, X):\n        return self.model.predict(X)\n\n# Example usage\nX, y = make_classification(n_samples=1000, n_features=2, n_redundant=0,\n                          n_informative=2, random_state=42)\nlearner = PACLearner(epsilon=0.1, delta=0.05)\nprint(f\"Required samples: {learner.required_samples(vc_dim=3)}\")\nlearner.fit(X, y)\n\nRequired samples: 3941\nWarning: Need at least 3941 samples for PAC guarantees\n\n\n&lt;__main__.PACLearner at 0x16c51beb0&gt;\n\n\n\n\n\n\n\n\nPractical PAC Learning\n\n\n\n\nChoose your desired accuracy (ε) and confidence (δ)\nCalculate required sample size using VC dimension\nCollect enough samples to meet PAC guarantees\nTrain your model on the collected samples\n\n\n\n\n\n\n\n\n\nRademacher complexity measures the richness of a hypothesis class:\n\\[\n\\mathfrak{R}_S(\\mathcal{H}) = \\mathbb{E}_\\sigma\\left[\\sup_{h \\in \\mathcal{H}}\\frac{1}{m}\\sum_{i=1}^m \\sigma_i h(x_i)\\right]\n\\]\n\n\n\nFor the non-realizable case:\n\\[\n\\text{error}_\\mathcal{D}(h) \\leq \\min_{h' \\in \\mathcal{H}}\\text{error}_\\mathcal{D}(h') + \\epsilon\n\\]\nSample complexity:\n\\[\nm \\geq \\frac{2}{\\epsilon^2}\\left(\\ln|\\mathcal{H}| + \\ln\\frac{2}{\\delta}\\right)\n\\]\n\n\n\nFor nested hypothesis classes \\(\\mathcal{H}_1 \\subset \\mathcal{H}_2 \\subset ... \\subset \\mathcal{H}_k\\):\n\\[\n\\text{pen}(h) = \\sqrt{\\frac{\\text{VC}(\\mathcal{H}(h))\\ln(em/\\text{VC}(\\mathcal{H}(h))) + \\ln(1/\\delta)}{m}}\n\\]\n\n\n\n\n\n\nPractical Application\n\n\n\nUse structural risk minimization to automatically select model complexity based on your dataset size.\n\n\n\n\n\n\nHere’s a complete example of PAC learning in practice:\n#| code-fold: false class MemoryEfficientLearner: def init(self, max_memory=1000): self.max_memory = max_memory self.model = None\ndef fit_with_memory_constraint(self, X, y):\n    n_samples = len(X)\n    batch_size = min(self.max_memory, n_samples)\n    \n    # Simulate streaming learning\n    times = []\n    memories = []\n    accuracies = []\n    \n    for batch_end in range(batch_size, n_samples + batch_size, batch_size):\n        batch_start = batch_end - batch_size\n        X_batch = X[batch_start:batch_end]\n        y_batch = y[batch_start:batch_end]\n        \n        start_time = time.time()\n        if self.model is None:\n            self.model = SVC(kernel='linear')\n        self.model.fit(X_batch, y_batch)\n        \n        times.append(time.time() - start_time)\n        memories.append(batch_size * X.shape[1] * 8)  # Approximate memory in bytes\n        accuracies.append(self.model.score(X_batch, y_batch))\n    \n    return times, memories, accuracies"
  },
  {
    "objectID": "posts/pac-learning-theory/index.html#introduction",
    "href": "posts/pac-learning-theory/index.html#introduction",
    "title": "PAC Learning Theory and VC Dimension",
    "section": "",
    "text": "Imagine you’re teaching a robot to recognize apples . How can you be “probably approximately correct” about its ability to recognize any apple? PAC learning theory gives us the mathematical framework to answer such questions.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import make_classification, make_circles\nfrom sklearn.model_selection import learning_curve\nimport time\n\n# Set random seed for reproducibility\nnp.random.seed(42)"
  },
  {
    "objectID": "posts/pac-learning-theory/index.html#pac-learning-visualization",
    "href": "posts/pac-learning-theory/index.html#pac-learning-visualization",
    "title": "PAC Learning Theory and VC Dimension",
    "section": "",
    "text": "Let’s visualize what “probably approximately correct” means:\n\ndef visualize_pac_learning(n_samples=100, noise_level=0.1):\n    # Generate synthetic dataset\n    X, y = make_circles(n_samples=n_samples, noise=noise_level, factor=0.3)\n    \n    # Train models with different sample sizes\n    sample_sizes = [10, 30, 50, n_samples]\n    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n    axes = axes.ravel()\n    \n    for i, size in enumerate(sample_sizes):\n        # Train model on subset\n        model = SVC(kernel='rbf')\n        idx = np.random.choice(n_samples, size=size, replace=False)\n        model.fit(X[idx], y[idx])\n        \n        # Create grid for decision boundary\n        xx, yy = np.meshgrid(np.linspace(X[:, 0].min()-0.5, X[:, 0].max()+0.5, 100),\n                            np.linspace(X[:, 1].min()-0.5, X[:, 1].max()+0.5, 100))\n        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n        Z = Z.reshape(xx.shape)\n        \n        # Plot\n        axes[i].contourf(xx, yy, Z, alpha=0.4)\n        axes[i].scatter(X[:, 0], X[:, 1], c=y, alpha=0.8)\n        axes[i].set_title(f'Training samples: {size}')\n    \n    plt.tight_layout()\n    plt.show()\n\nvisualize_pac_learning()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKey Insight\n\n\n\nNotice how the decision boundary becomes more stable and accurate as we increase the sample size. This is PAC learning in action!"
  },
  {
    "objectID": "posts/pac-learning-theory/index.html#vc-dimension-explorer",
    "href": "posts/pac-learning-theory/index.html#vc-dimension-explorer",
    "title": "PAC Learning Theory and VC Dimension",
    "section": "",
    "text": "Let’s create an interactive tool to explore VC dimension:\n\ndef explore_vc_dimension(n_points=100):\n    def generate_points(n):\n        return np.random.rand(n, 2)\n    \n    def plot_linear_classifier(ax, points, labels):\n        if len(points) &gt;= 2:\n            model = SVC(kernel='linear')\n            try:\n                model.fit(points, labels)\n                \n                # Plot decision boundary\n                xx, yy = np.meshgrid(np.linspace(0, 1, 100),\n                                   np.linspace(0, 1, 100))\n                Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n                Z = Z.reshape(xx.shape)\n                ax.contourf(xx, yy, Z, alpha=0.4)\n            except:\n                pass\n        \n        # Plot points\n        colors = ['red' if l == 0 else 'blue' for l in labels]\n        ax.scatter(points[:, 0], points[:, 1], c=colors)\n        ax.set_xlim(0, 1)\n        ax.set_ylim(0, 1)\n    \n    # Generate different labelings\n    points = generate_points(3)  # Try with 3 points\n    all_labels = [[int(i) for i in format(j, f'0{3}b')] \n                 for j in range(2**3)]\n    \n    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n    axes = axes.ravel()\n    \n    for i, labels in enumerate(all_labels):\n        plot_linear_classifier(axes[i], points, labels)\n        axes[i].set_title(f'Labeling {i+1}')\n    \n    plt.tight_layout()\n    plt.show()\n\nexplore_vc_dimension()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding VC Dimension\n\n\n\nThe plots above show different possible labelings of 3 points. A linear classifier (VC dimension = 3) can shatter these points in most, but not all configurations."
  },
  {
    "objectID": "posts/pac-learning-theory/index.html#theoretical-foundations",
    "href": "posts/pac-learning-theory/index.html#theoretical-foundations",
    "title": "PAC Learning Theory and VC Dimension",
    "section": "",
    "text": "The PAC (Probably Approximately Correct) learning framework provides theoretical guarantees for learning algorithms:\n\\[\nP_{S \\sim \\mathcal{D}^m}(\\text{error}_\\mathcal{D}(h_S) \\leq \\epsilon) \\geq 1-\\delta\n\\]\nWhere: - \\(\\epsilon\\) is the accuracy parameter (how close to perfect) - \\(\\delta\\) is the confidence parameter (how sure we are) - \\(m\\) is the sample size - \\(h_S\\) is the learned hypothesis\n\n\n\nThe fundamental bound for sample complexity:\n\\[\nm \\geq \\frac{1}{\\epsilon}\\left(\\ln|\\mathcal{H}| + \\ln\\frac{1}{\\delta}\\right)\n\\]\nFor the realizable case (when perfect classification is possible):\n\\[\nm \\geq \\frac{1}{\\epsilon}\\left(\\ln\\frac{1}{\\delta}\\right)\n\\]\n\n\n\nThe VC dimension of a hypothesis class \\(\\mathcal{H}\\) is the largest number of points that can be shattered (assigned any possible labeling) by \\(\\mathcal{H}\\).\nGrowth function:\n\\[\n\\Pi_\\mathcal{H}(m) = \\max_{x_1,...,x_m \\in \\mathcal{X}}|\\{(h(x_1),...,h(x_m)): h \\in \\mathcal{H}\\}|\n\\]\nSauer’s Lemma:\n\\[\n\\text{If VC}(\\mathcal{H}) = d, \\text{ then } \\Pi_\\mathcal{H}(m) \\leq \\sum_{i=0}^d \\binom{m}{i}\n\\]\n\n\n\nThe fundamental theorem of learning theory:\n\\[\nP(\\sup_{h \\in \\mathcal{H}}|\\text{error}_\\mathcal{D}(h) - \\widehat{\\text{error}}_S(h)| &gt; \\epsilon) \\leq 4\\Pi_\\mathcal{H}(2m)\\exp(-\\frac{m\\epsilon^2}{8})\n\\]\nSample complexity in terms of VC dimension:\n\\[\nm = O\\left(\\frac{d}{\\epsilon^2}\\ln\\frac{1}{\\epsilon} + \\frac{1}{\\epsilon^2}\\ln\\frac{1}{\\delta}\\right)\n\\]\n\n\n\n\n\n\nKey Insight\n\n\n\nThe VC dimension (\\(d\\)) appears in the sample complexity bound, showing how model complexity affects learning guarantees."
  },
  {
    "objectID": "posts/pac-learning-theory/index.html#pac-learning-framework-1",
    "href": "posts/pac-learning-theory/index.html#pac-learning-framework-1",
    "title": "PAC Learning Theory and VC Dimension",
    "section": "",
    "text": "Let’s make PAC learning concrete with an example:\n\nclass PACLearner:\n    def __init__(self, epsilon=0.1, delta=0.05):\n        self.epsilon = epsilon  # accuracy parameter\n        self.delta = delta    # confidence parameter\n        self.model = None\n    \n    def required_samples(self, vc_dim):\n        \"\"\"Calculate required sample size using VC bound\"\"\"\n        return int(np.ceil((8/self.epsilon) * \n                         (2*vc_dim * np.log2(16/self.epsilon) + \n                          np.log2(2/self.delta))))\n    \n    def fit(self, X, y):\n        \"\"\"Train model with PAC guarantees\"\"\"\n        n_samples = len(X)\n        required = self.required_samples(vc_dim=3)  # for linear classifier\n        \n        if n_samples &lt; required:\n            print(f\"Warning: Need at least {required} samples for PAC guarantees\")\n        \n        self.model = SVC(kernel='linear')\n        self.model.fit(X, y)\n        return self\n    \n    def predict(self, X):\n        return self.model.predict(X)\n\n# Example usage\nX, y = make_classification(n_samples=1000, n_features=2, n_redundant=0,\n                          n_informative=2, random_state=42)\nlearner = PACLearner(epsilon=0.1, delta=0.05)\nprint(f\"Required samples: {learner.required_samples(vc_dim=3)}\")\nlearner.fit(X, y)\n\nRequired samples: 3941\nWarning: Need at least 3941 samples for PAC guarantees\n\n\n&lt;__main__.PACLearner at 0x16c51beb0&gt;\n\n\n\n\n\n\n\n\nPractical PAC Learning\n\n\n\n\nChoose your desired accuracy (ε) and confidence (δ)\nCalculate required sample size using VC dimension\nCollect enough samples to meet PAC guarantees\nTrain your model on the collected samples"
  },
  {
    "objectID": "posts/pac-learning-theory/index.html#advanced-topics",
    "href": "posts/pac-learning-theory/index.html#advanced-topics",
    "title": "PAC Learning Theory and VC Dimension",
    "section": "",
    "text": "Rademacher complexity measures the richness of a hypothesis class:\n\\[\n\\mathfrak{R}_S(\\mathcal{H}) = \\mathbb{E}_\\sigma\\left[\\sup_{h \\in \\mathcal{H}}\\frac{1}{m}\\sum_{i=1}^m \\sigma_i h(x_i)\\right]\n\\]\n\n\n\nFor the non-realizable case:\n\\[\n\\text{error}_\\mathcal{D}(h) \\leq \\min_{h' \\in \\mathcal{H}}\\text{error}_\\mathcal{D}(h') + \\epsilon\n\\]\nSample complexity:\n\\[\nm \\geq \\frac{2}{\\epsilon^2}\\left(\\ln|\\mathcal{H}| + \\ln\\frac{2}{\\delta}\\right)\n\\]\n\n\n\nFor nested hypothesis classes \\(\\mathcal{H}_1 \\subset \\mathcal{H}_2 \\subset ... \\subset \\mathcal{H}_k\\):\n\\[\n\\text{pen}(h) = \\sqrt{\\frac{\\text{VC}(\\mathcal{H}(h))\\ln(em/\\text{VC}(\\mathcal{H}(h))) + \\ln(1/\\delta)}{m}}\n\\]\n\n\n\n\n\n\nPractical Application\n\n\n\nUse structural risk minimization to automatically select model complexity based on your dataset size."
  },
  {
    "objectID": "posts/pac-learning-theory/index.html#practical-implementation",
    "href": "posts/pac-learning-theory/index.html#practical-implementation",
    "title": "PAC Learning Theory and VC Dimension",
    "section": "",
    "text": "Here’s a complete example of PAC learning in practice:\n#| code-fold: false class MemoryEfficientLearner: def init(self, max_memory=1000): self.max_memory = max_memory self.model = None\ndef fit_with_memory_constraint(self, X, y):\n    n_samples = len(X)\n    batch_size = min(self.max_memory, n_samples)\n    \n    # Simulate streaming learning\n    times = []\n    memories = []\n    accuracies = []\n    \n    for batch_end in range(batch_size, n_samples + batch_size, batch_size):\n        batch_start = batch_end - batch_size\n        X_batch = X[batch_start:batch_end]\n        y_batch = y[batch_start:batch_end]\n        \n        start_time = time.time()\n        if self.model is None:\n            self.model = SVC(kernel='linear')\n        self.model.fit(X_batch, y_batch)\n        \n        times.append(time.time() - start_time)\n        memories.append(batch_size * X.shape[1] * 8)  # Approximate memory in bytes\n        accuracies.append(self.model.score(X_batch, y_batch))\n    \n    return times, memories, accuracies"
  },
  {
    "objectID": "posts/reinforcement-learning-basics/index.html",
    "href": "posts/reinforcement-learning-basics/index.html",
    "title": "Understanding Reinforcement Learning: A Beginner’s Guide",
    "section": "",
    "text": "What You’ll Learn\n\n\n\nBy the end of this guide, you’ll understand: - The basic concepts of reinforcement learning\n\nHow agents learn from experience\nReal-world applications\nHow to implement a simple RL algorithm"
  },
  {
    "objectID": "posts/reinforcement-learning-basics/index.html#what-is-reinforcement-learning",
    "href": "posts/reinforcement-learning-basics/index.html#what-is-reinforcement-learning",
    "title": "Understanding Reinforcement Learning: A Beginner’s Guide",
    "section": "What is Reinforcement Learning?",
    "text": "What is Reinforcement Learning?\n\n\n\n\n\n\nKey Insight\n\n\n\nReinforcement Learning (RL) is about learning to make decisions by interacting with an environment. Think of it as learning from experience, just like humans do!\n\n\nImagine teaching a dog new tricks: 1. Give treats when the dog performs correctly (reward) 2. Don’t give treats when it performs incorrectly (no reward) 3. The dog learns to associate actions with rewards\nThis is exactly how reinforcement learning works! It’s about: - Learning what to do (actions)\n\nHow to map situations to actions (strategy)\nMaximizing a numerical reward signal"
  },
  {
    "objectID": "posts/reinforcement-learning-basics/index.html#your-first-rl-algorithm",
    "href": "posts/reinforcement-learning-basics/index.html#your-first-rl-algorithm",
    "title": "Understanding Reinforcement Learning: A Beginner’s Guide",
    "section": "Your First RL Algorithm",
    "text": "Your First RL Algorithm\nLet’s implement a simple Q-learning algorithm in Python:\n\nCodeExplanationOutput Visualization\n\n\nimport numpy as np\n\nclass SimpleQLearning:\n    def __init__(self, states, actions, learning_rate=0.1, discount=0.95):\n        self.q_table = np.zeros((states, actions))\n        self.lr = learning_rate\n        self.gamma = discount\n    \n    def get_action(self, state, epsilon=0.1):\n        # Exploration vs exploitation\n        if np.random.random() &lt; epsilon:\n            return np.random.randint(self.q_table.shape[1])\n        return np.argmax(self.q_table[state])\n    \n    def learn(self, state, action, reward, next_state):\n        old_value = self.q_table[state, action]\n        next_max = np.max(self.q_table[next_state])\n        \n        # Q-learning formula\n        new_value = (1 - self.lr) * old_value + self.lr * (reward + self.gamma * next_max)\n        self.q_table[state, action] = new_value\n\n# Example usage\nenv_size = 5  # 5 states\nn_actions = 4  # 4 possible actions\nagent = SimpleQLearning(env_size, n_actions)\n\n# Learning loop (simplified)\nstate = 0\nfor _ in range(10):\n    action = agent.get_action(state)\n    # Simulate environment (in real case, this would be your environment)\n    next_state = min(state + 1, env_size - 1)\n    reward = 1 if next_state == env_size - 1 else 0\n    \n    # Learn from experience\n    agent.learn(state, action, reward, next_state)\n    state = next_state\n\n\nThis code demonstrates: 1. Creating a Q-learning agent\n\nBalancing exploration vs exploitation\nLearning from experience\nUpdating Q-values based on rewards\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Visualize Q-table\nplt.figure(figsize=(10, 5))\nsns.heatmap(agent.q_table, annot=True, fmt='.2f')\nplt.xlabel('Actions')\nplt.ylabel('States')\nplt.title('Q-values After Learning')\nplt.show()"
  },
  {
    "objectID": "posts/reinforcement-learning-basics/index.html#key-components-of-reinforcement-learning",
    "href": "posts/reinforcement-learning-basics/index.html#key-components-of-reinforcement-learning",
    "title": "Understanding Reinforcement Learning: A Beginner’s Guide",
    "section": "Key Components of Reinforcement Learning",
    "text": "Key Components of Reinforcement Learning\n\n1. The Agent\n\n\n\n\n\n\nImportant\n\n\n\nThe agent is the learner and decision-maker. Like a player in a game, it: - Observes the environment - Makes decisions (takes actions) - Receives rewards - Updates its strategy\n\n\n\n\n2. The Environment\nThe world the agent interacts with:\n┌────────────────────────┐\n│      Environment      │\n│   ┌──────────────┐    │\n│   │    State     │    │\n│   └──────────────┘    │\n│          ↑↓           │\n│   ┌──────────────┐    │\n│   │    Agent     │    │\n│   └──────────────┘    │\n│          ↑↓           │\n│   ┌──────────────┐    │\n│   │    Reward    │    │\n│   └──────────────┘    │\n└────────────────────────┘\n\n\n3. States and Actions\n\nStatesActions\n\n\nCurrent situation: - Position in a maze - Game board configuration - Robot’s location\n\n\nPossible choices: - Move: Up, Down, Left, Right - Game moves: Place piece, Attack, Defend - Trading: Buy, Sell, Hold"
  },
  {
    "objectID": "posts/reinforcement-learning-basics/index.html#practical-applications",
    "href": "posts/reinforcement-learning-basics/index.html#practical-applications",
    "title": "Understanding Reinforcement Learning: A Beginner’s Guide",
    "section": "Practical Applications",
    "text": "Practical Applications\n\n1. Game AI\n\n\n\n\n\n\nExample: Teaching an AI to Play Tic-Tac-Toe\n\n\n\nclass TicTacToeEnv:\n    def __init__(self):\n        self.board = np.zeros((3, 3))\n        self.current_player = 1\n    \n    def get_state(self):\n        return tuple(self.board.flatten())\n    \n    def make_move(self, position):\n        row, col = position // 3, position % 3\n        if self.board[row, col] == 0:\n            self.board[row, col] = self.current_player\n            self.current_player *= -1\n            return True\n        return False\n\n\n\n\n2. Robotics\nTeaching robots to: - Navigate environments - Manipulate objects - Learn from demonstrations\n\n\n3. Business Applications\n\nInventory management\nResource allocation\nMarketing optimization"
  },
  {
    "objectID": "posts/reinforcement-learning-basics/index.html#advanced-concepts",
    "href": "posts/reinforcement-learning-basics/index.html#advanced-concepts",
    "title": "Understanding Reinforcement Learning: A Beginner’s Guide",
    "section": "Advanced Concepts",
    "text": "Advanced Concepts\n\n1. Deep Reinforcement Learning\n\nConceptExample Architecture\n\n\nCombining neural networks with RL: - Handle complex state spaces - Learn features automatically - Scale to real-world problems\n\n\nimport tensorflow as tf\n\ndef create_dqn(state_size, action_size):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(24, activation='relu', input_shape=(state_size,)),\n        tf.keras.layers.Dense(24, activation='relu'),\n        tf.keras.layers.Dense(action_size, activation='linear')\n    ])\n    return model\n\n\n\n\n\n2. Policy Gradients\nLearning the policy directly:\ndef policy_network(state_size, action_size):\n    return tf.keras.Sequential([\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(action_size, activation='softmax')\n    ])"
  },
  {
    "objectID": "posts/reinforcement-learning-basics/index.html#getting-started",
    "href": "posts/reinforcement-learning-basics/index.html#getting-started",
    "title": "Understanding Reinforcement Learning: A Beginner’s Guide",
    "section": "Getting Started",
    "text": "Getting Started\n\n\n\n\n\n\nLearning Path\n\n\n\n\nBasics: Start with Q-learning\nPractice: Implement simple environments\nTools: Learn OpenAI Gym\nAdvanced: Move to deep RL\n\n\n\n\nResources\n\nOnline CoursesLibrariesBooks\n\n\n\nCoursera’s RL Specialization\nDavid Silver’s RL Course\nFast.ai’s Practical Deep Learning\n\n\n\n\nOpenAI Gym\nStable Baselines3\nTensorFlow Agents\n\n\n\n\n“Reinforcement Learning: An Introduction” by Sutton & Barto\n“Deep Reinforcement Learning Hands-On”"
  },
  {
    "objectID": "posts/reinforcement-learning-basics/index.html#practice-projects",
    "href": "posts/reinforcement-learning-basics/index.html#practice-projects",
    "title": "Understanding Reinforcement Learning: A Beginner’s Guide",
    "section": "Practice Projects",
    "text": "Practice Projects\n\nSimple Games\n\nTic-tac-toe\nCart-pole balancing\nGrid world navigation\n\nAdvanced Projects\n\nStock trading bot\nRobot simulation\nGame AI development\n\n\n\n\n\n\n\n\nCommon Pitfalls\n\n\n\n\nStarting too complex\nIgnoring exploration\nPoor reward design\nInsufficient training time\n\n\n\nRemember: Start simple, experiment often, and gradually increase complexity. Reinforcement learning is a powerful tool, but it requires patience and practice to master!"
  },
  {
    "objectID": "posts/optimization-theory/index.html",
    "href": "posts/optimization-theory/index.html",
    "title": "Optimization Theory in Machine Learning",
    "section": "",
    "text": "Convex set definition:\n\\[\n\\theta x + (1-\\theta)y \\in C, \\forall x,y \\in C, \\theta \\in [0,1]\n\\]\nConvex function:\n\\[\nf(\\theta x + (1-\\theta)y) \\leq \\theta f(x) + (1-\\theta)f(y)\n\\]\n\n\n\nFirst-order characterization:\n\\[\nf(y) \\geq f(x) + \\nabla f(x)^T(y-x)\n\\]\nSecond-order characterization:\n\\[\n\\nabla^2 f(x) \\succeq 0\n\\]\n\n\n\nDefinition:\n\\[\nf(y) \\geq f(x) + \\nabla f(x)^T(y-x) + \\frac{\\mu}{2}\\|y-x\\|^2\n\\]\nQuadratic growth:\n\\[\nf(x) - f(x^*) \\geq \\frac{\\mu}{2}\\|x-x^*\\|^2\n\\]\n\n\n\n\n\n\nUnconstrained:\n\\[\n\\nabla f(x^*) = 0\n\\]\nConstrained (KKT):\n\\[\n\\begin{aligned}\n\\nabla_x \\mathcal{L}(x^*,\\lambda^*) &= 0 \\\\\ng_i(x^*) &\\leq 0 \\\\\n\\lambda_i^* g_i(x^*) &= 0 \\\\\n\\lambda_i^* &\\geq 0\n\\end{aligned}\n\\]\n\n\n\nUnconstrained:\n\\[\n\\nabla^2 f(x^*) \\succeq 0\n\\]\nConstrained:\n\\[\ny^T\\nabla^2_{xx}\\mathcal{L}(x^*,\\lambda^*)y \\geq 0\n\\]\n\n\n\nMinimax:\n\\[\n\\mathcal{L}(x^*,\\lambda) \\leq \\mathcal{L}(x^*,\\lambda^*) \\leq \\mathcal{L}(x,\\lambda^*)\n\\]\nDuality gap:\n\\[\nf(x^*) - g(\\lambda^*) = 0\n\\]\n\n\n\n\n\n\nUpdate rule:\n\\[\nx_{k+1} = x_k - \\eta_k\\nabla f(x_k)\n\\]\nConvergence rate (convex):\n\\[\nf(x_k) - f(x^*) \\leq \\frac{\\|x_0-x^*\\|^2}{2\\eta k}\n\\]\n\n\n\nNesterov’s acceleration:\n\\[\n\\begin{aligned}\ny_k &= x_k + \\beta_k(x_k - x_{k-1}) \\\\\nx_{k+1} &= y_k - \\eta_k\\nabla f(y_k)\n\\end{aligned}\n\\]\nConvergence rate:\n\\[\nf(x_k) - f(x^*) \\leq \\frac{2L\\|x_0-x^*\\|^2}{(k+1)^2}\n\\]\n\n\n\nSGD update:\n\\[\nx_{k+1} = x_k - \\eta_k\\nabla f_{i_k}(x_k)\n\\]\nConvergence rate:\n\\[\n\\mathbb{E}[f(x_k) - f(x^*)] \\leq \\frac{L\\|x_0-x^*\\|^2}{2k} + \\frac{L\\sigma^2}{2}\\sum_{t=1}^k \\eta_t^2\n\\]\n\n\n\n\n\n\nFirst-order condition:\n\\[\n\\|\\nabla f(x^*)\\| \\leq \\epsilon\n\\]\nSecond-order condition:\n\\[\n\\lambda_{\\min}(\\nabla^2 f(x^*)) \\geq -\\sqrt{\\epsilon}\n\\]\n\n\n\nPerturbed gradient descent:\n\\[\nx_{k+1} = x_k - \\eta\\nabla f(x_k) + \\xi_k\n\\]\nWhere: - \\(\\xi_k \\sim \\mathcal{N}(0,\\sigma^2I)\\)\n\n\n\nBranch and bound:\n\\[\n\\text{LB}(R) \\leq \\min_{x \\in R} f(x) \\leq \\text{UB}(R)\n\\]\nSimulated annealing:\n\\[\nP(\\text{accept}) = \\exp(-\\frac{\\Delta E}{T_k})\n\\]\n\n\n\n\n\n\nAdaGrad:\n\\[\nx_{t+1,i} = x_{t,i} - \\frac{\\eta}{\\sqrt{\\sum_{s=1}^t g_{s,i}^2}}g_{t,i}\n\\]\nAdam:\n\\[\n\\begin{aligned}\nm_t &= \\beta_1 m_{t-1} + (1-\\beta_1)g_t \\\\\nv_t &= \\beta_2 v_{t-1} + (1-\\beta_2)g_t^2 \\\\\n\\hat{m}_t &= \\frac{m_t}{1-\\beta_1^t} \\\\\n\\hat{v}_t &= \\frac{v_t}{1-\\beta_2^t} \\\\\nx_{t+1} &= x_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon}\\hat{m}_t\n\\end{aligned}\n\\]\n\n\n\nFisher information:\n\\[\nF(x) = \\mathbb{E}_{p(y|x)}[\\nabla \\log p(y|x)\\nabla \\log p(y|x)^T]\n\\]\nUpdate rule:\n\\[\nx_{k+1} = x_k - \\eta F(x_k)^{-1}\\nabla f(x_k)\n\\]\n\n\n\nNewton’s method:\n\\[\nx_{k+1} = x_k - [\\nabla^2 f(x_k)]^{-1}\\nabla f(x_k)\n\\]\nBFGS update:\n\\[\nB_{k+1} = B_k + \\frac{y_ky_k^T}{y_k^Ts_k} - \\frac{B_ks_ks_k^TB_k}{s_k^TB_ks_k}\n\\]\n\n\n\n\n\n\nUpdate rule:\n\\[\nx_{k+1} = \\Pi_C(x_k - \\eta_k\\nabla f(x_k))\n\\]\nConvergence rate:\n\\[\nf(x_k) - f(x^*) \\leq \\frac{\\|x_0-x^*\\|^2}{2\\eta k}\n\\]\n\n\n\nProximal operator:\n\\[\n\\text{prox}_{\\eta g}(x) = \\arg\\min_y \\{g(y) + \\frac{1}{2\\eta}\\|y-x\\|^2\\}\n\\]\nISTA update:\n\\[\nx_{k+1} = \\text{prox}_{\\eta g}(x_k - \\eta\\nabla f(x_k))\n\\]\n\n\n\nFunction:\n\\[\n\\mathcal{L}_\\rho(x,\\lambda) = f(x) + \\lambda^Tg(x) + \\frac{\\rho}{2}\\|g(x)\\|^2\n\\]\nUpdate rules:\n\\[\n\\begin{aligned}\nx_{k+1} &= \\arg\\min_x \\mathcal{L}_\\rho(x,\\lambda_k) \\\\\n\\lambda_{k+1} &= \\lambda_k + \\rho g(x_{k+1})\n\\end{aligned}\n\\]\n\n\n\n\n\n\nADMM algorithm:\n\\[\n\\begin{aligned}\nx_{k+1} &= \\arg\\min_x \\mathcal{L}_\\rho(x,z_k,y_k) \\\\\nz_{k+1} &= \\arg\\min_z \\mathcal{L}_\\rho(x_{k+1},z,y_k) \\\\\ny_{k+1} &= y_k + \\rho(Ax_{k+1} + Bz_{k+1} - c)\n\\end{aligned}\n\\]\n\n\n\nRegret bound:\n\\[\nR_T \\leq O(\\sqrt{T})\n\\]\nFollow-the-regularized-leader:\n\\[\nx_{t+1} = \\arg\\min_x \\{\\eta\\sum_{s=1}^t \\ell_s(x) + R(x)\\}\n\\]\n\n\n\nGradient estimation:\n\\[\n\\hat{\\nabla} f(x) = \\frac{d}{r}f(x+r\\xi)\\xi\n\\]\nWhere: - \\(\\xi \\sim \\text{Unif}(\\mathbb{S}^{d-1})\\)\n\n\n\n\n\n\n\nProblem Structure:\n\nConvexity\nSmoothness\nConstraints\n\nData Properties:\n\nSize\nDimensionality\nSparsity\n\nComputational Resources:\n\nMemory\nProcessing power\nTime constraints\n\n\n\n\n\n\nInitialization:\n\nParameter scaling\nRandom seeding\nWarm start\n\nMonitoring:\n\nConvergence\nStability\nResource usage\n\nTuning:\n\nLearning rates\nMomentum\nRegularization\n\n\n\n\n\n\n\nTheory:\n\n“Convex Optimization” by Boyd and Vandenberghe\n“Introductory Lectures on Convex Optimization” by Nesterov\n“Optimization Methods for Large-Scale Machine Learning” by Bottou et al.\n\nMethods:\n\n“Numerical Optimization” by Nocedal and Wright\n“First-Order Methods in Optimization” by Beck\n“Proximal Algorithms” by Parikh and Boyd\n\nApplications:\n\n“Deep Learning” by Goodfellow et al.\n“Optimization for Machine Learning” by Sra et al.\n“Large Scale Optimization in Machine Learning” by Shalev-Shwartz and Zhang"
  },
  {
    "objectID": "posts/optimization-theory/index.html#convex-analysis",
    "href": "posts/optimization-theory/index.html#convex-analysis",
    "title": "Optimization Theory in Machine Learning",
    "section": "",
    "text": "Convex set definition:\n\\[\n\\theta x + (1-\\theta)y \\in C, \\forall x,y \\in C, \\theta \\in [0,1]\n\\]\nConvex function:\n\\[\nf(\\theta x + (1-\\theta)y) \\leq \\theta f(x) + (1-\\theta)f(y)\n\\]\n\n\n\nFirst-order characterization:\n\\[\nf(y) \\geq f(x) + \\nabla f(x)^T(y-x)\n\\]\nSecond-order characterization:\n\\[\n\\nabla^2 f(x) \\succeq 0\n\\]\n\n\n\nDefinition:\n\\[\nf(y) \\geq f(x) + \\nabla f(x)^T(y-x) + \\frac{\\mu}{2}\\|y-x\\|^2\n\\]\nQuadratic growth:\n\\[\nf(x) - f(x^*) \\geq \\frac{\\mu}{2}\\|x-x^*\\|^2\n\\]"
  },
  {
    "objectID": "posts/optimization-theory/index.html#optimality-conditions",
    "href": "posts/optimization-theory/index.html#optimality-conditions",
    "title": "Optimization Theory in Machine Learning",
    "section": "",
    "text": "Unconstrained:\n\\[\n\\nabla f(x^*) = 0\n\\]\nConstrained (KKT):\n\\[\n\\begin{aligned}\n\\nabla_x \\mathcal{L}(x^*,\\lambda^*) &= 0 \\\\\ng_i(x^*) &\\leq 0 \\\\\n\\lambda_i^* g_i(x^*) &= 0 \\\\\n\\lambda_i^* &\\geq 0\n\\end{aligned}\n\\]\n\n\n\nUnconstrained:\n\\[\n\\nabla^2 f(x^*) \\succeq 0\n\\]\nConstrained:\n\\[\ny^T\\nabla^2_{xx}\\mathcal{L}(x^*,\\lambda^*)y \\geq 0\n\\]\n\n\n\nMinimax:\n\\[\n\\mathcal{L}(x^*,\\lambda) \\leq \\mathcal{L}(x^*,\\lambda^*) \\leq \\mathcal{L}(x,\\lambda^*)\n\\]\nDuality gap:\n\\[\nf(x^*) - g(\\lambda^*) = 0\n\\]"
  },
  {
    "objectID": "posts/optimization-theory/index.html#gradient-methods",
    "href": "posts/optimization-theory/index.html#gradient-methods",
    "title": "Optimization Theory in Machine Learning",
    "section": "",
    "text": "Update rule:\n\\[\nx_{k+1} = x_k - \\eta_k\\nabla f(x_k)\n\\]\nConvergence rate (convex):\n\\[\nf(x_k) - f(x^*) \\leq \\frac{\\|x_0-x^*\\|^2}{2\\eta k}\n\\]\n\n\n\nNesterov’s acceleration:\n\\[\n\\begin{aligned}\ny_k &= x_k + \\beta_k(x_k - x_{k-1}) \\\\\nx_{k+1} &= y_k - \\eta_k\\nabla f(y_k)\n\\end{aligned}\n\\]\nConvergence rate:\n\\[\nf(x_k) - f(x^*) \\leq \\frac{2L\\|x_0-x^*\\|^2}{(k+1)^2}\n\\]\n\n\n\nSGD update:\n\\[\nx_{k+1} = x_k - \\eta_k\\nabla f_{i_k}(x_k)\n\\]\nConvergence rate:\n\\[\n\\mathbb{E}[f(x_k) - f(x^*)] \\leq \\frac{L\\|x_0-x^*\\|^2}{2k} + \\frac{L\\sigma^2}{2}\\sum_{t=1}^k \\eta_t^2\n\\]"
  },
  {
    "objectID": "posts/optimization-theory/index.html#non-convex-optimization",
    "href": "posts/optimization-theory/index.html#non-convex-optimization",
    "title": "Optimization Theory in Machine Learning",
    "section": "",
    "text": "First-order condition:\n\\[\n\\|\\nabla f(x^*)\\| \\leq \\epsilon\n\\]\nSecond-order condition:\n\\[\n\\lambda_{\\min}(\\nabla^2 f(x^*)) \\geq -\\sqrt{\\epsilon}\n\\]\n\n\n\nPerturbed gradient descent:\n\\[\nx_{k+1} = x_k - \\eta\\nabla f(x_k) + \\xi_k\n\\]\nWhere: - \\(\\xi_k \\sim \\mathcal{N}(0,\\sigma^2I)\\)\n\n\n\nBranch and bound:\n\\[\n\\text{LB}(R) \\leq \\min_{x \\in R} f(x) \\leq \\text{UB}(R)\n\\]\nSimulated annealing:\n\\[\nP(\\text{accept}) = \\exp(-\\frac{\\Delta E}{T_k})\n\\]"
  },
  {
    "objectID": "posts/optimization-theory/index.html#modern-optimization-methods",
    "href": "posts/optimization-theory/index.html#modern-optimization-methods",
    "title": "Optimization Theory in Machine Learning",
    "section": "",
    "text": "AdaGrad:\n\\[\nx_{t+1,i} = x_{t,i} - \\frac{\\eta}{\\sqrt{\\sum_{s=1}^t g_{s,i}^2}}g_{t,i}\n\\]\nAdam:\n\\[\n\\begin{aligned}\nm_t &= \\beta_1 m_{t-1} + (1-\\beta_1)g_t \\\\\nv_t &= \\beta_2 v_{t-1} + (1-\\beta_2)g_t^2 \\\\\n\\hat{m}_t &= \\frac{m_t}{1-\\beta_1^t} \\\\\n\\hat{v}_t &= \\frac{v_t}{1-\\beta_2^t} \\\\\nx_{t+1} &= x_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon}\\hat{m}_t\n\\end{aligned}\n\\]\n\n\n\nFisher information:\n\\[\nF(x) = \\mathbb{E}_{p(y|x)}[\\nabla \\log p(y|x)\\nabla \\log p(y|x)^T]\n\\]\nUpdate rule:\n\\[\nx_{k+1} = x_k - \\eta F(x_k)^{-1}\\nabla f(x_k)\n\\]\n\n\n\nNewton’s method:\n\\[\nx_{k+1} = x_k - [\\nabla^2 f(x_k)]^{-1}\\nabla f(x_k)\n\\]\nBFGS update:\n\\[\nB_{k+1} = B_k + \\frac{y_ky_k^T}{y_k^Ts_k} - \\frac{B_ks_ks_k^TB_k}{s_k^TB_ks_k}\n\\]"
  },
  {
    "objectID": "posts/optimization-theory/index.html#constrained-optimization",
    "href": "posts/optimization-theory/index.html#constrained-optimization",
    "title": "Optimization Theory in Machine Learning",
    "section": "",
    "text": "Update rule:\n\\[\nx_{k+1} = \\Pi_C(x_k - \\eta_k\\nabla f(x_k))\n\\]\nConvergence rate:\n\\[\nf(x_k) - f(x^*) \\leq \\frac{\\|x_0-x^*\\|^2}{2\\eta k}\n\\]\n\n\n\nProximal operator:\n\\[\n\\text{prox}_{\\eta g}(x) = \\arg\\min_y \\{g(y) + \\frac{1}{2\\eta}\\|y-x\\|^2\\}\n\\]\nISTA update:\n\\[\nx_{k+1} = \\text{prox}_{\\eta g}(x_k - \\eta\\nabla f(x_k))\n\\]\n\n\n\nFunction:\n\\[\n\\mathcal{L}_\\rho(x,\\lambda) = f(x) + \\lambda^Tg(x) + \\frac{\\rho}{2}\\|g(x)\\|^2\n\\]\nUpdate rules:\n\\[\n\\begin{aligned}\nx_{k+1} &= \\arg\\min_x \\mathcal{L}_\\rho(x,\\lambda_k) \\\\\n\\lambda_{k+1} &= \\lambda_k + \\rho g(x_{k+1})\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/optimization-theory/index.html#advanced-topics",
    "href": "posts/optimization-theory/index.html#advanced-topics",
    "title": "Optimization Theory in Machine Learning",
    "section": "",
    "text": "ADMM algorithm:\n\\[\n\\begin{aligned}\nx_{k+1} &= \\arg\\min_x \\mathcal{L}_\\rho(x,z_k,y_k) \\\\\nz_{k+1} &= \\arg\\min_z \\mathcal{L}_\\rho(x_{k+1},z,y_k) \\\\\ny_{k+1} &= y_k + \\rho(Ax_{k+1} + Bz_{k+1} - c)\n\\end{aligned}\n\\]\n\n\n\nRegret bound:\n\\[\nR_T \\leq O(\\sqrt{T})\n\\]\nFollow-the-regularized-leader:\n\\[\nx_{t+1} = \\arg\\min_x \\{\\eta\\sum_{s=1}^t \\ell_s(x) + R(x)\\}\n\\]\n\n\n\nGradient estimation:\n\\[\n\\hat{\\nabla} f(x) = \\frac{d}{r}f(x+r\\xi)\\xi\n\\]\nWhere: - \\(\\xi \\sim \\text{Unif}(\\mathbb{S}^{d-1})\\)"
  },
  {
    "objectID": "posts/optimization-theory/index.html#best-practices",
    "href": "posts/optimization-theory/index.html#best-practices",
    "title": "Optimization Theory in Machine Learning",
    "section": "",
    "text": "Problem Structure:\n\nConvexity\nSmoothness\nConstraints\n\nData Properties:\n\nSize\nDimensionality\nSparsity\n\nComputational Resources:\n\nMemory\nProcessing power\nTime constraints\n\n\n\n\n\n\nInitialization:\n\nParameter scaling\nRandom seeding\nWarm start\n\nMonitoring:\n\nConvergence\nStability\nResource usage\n\nTuning:\n\nLearning rates\nMomentum\nRegularization"
  },
  {
    "objectID": "posts/optimization-theory/index.html#references",
    "href": "posts/optimization-theory/index.html#references",
    "title": "Optimization Theory in Machine Learning",
    "section": "",
    "text": "Theory:\n\n“Convex Optimization” by Boyd and Vandenberghe\n“Introductory Lectures on Convex Optimization” by Nesterov\n“Optimization Methods for Large-Scale Machine Learning” by Bottou et al.\n\nMethods:\n\n“Numerical Optimization” by Nocedal and Wright\n“First-Order Methods in Optimization” by Beck\n“Proximal Algorithms” by Parikh and Boyd\n\nApplications:\n\n“Deep Learning” by Goodfellow et al.\n“Optimization for Machine Learning” by Sra et al.\n“Large Scale Optimization in Machine Learning” by Shalev-Shwartz and Zhang"
  },
  {
    "objectID": "posts/online-learning/index.html",
    "href": "posts/online-learning/index.html",
    "title": "Online Learning and Regret Minimization",
    "section": "",
    "text": "Learning process: 1. Receive instance \\(x_t\\) 2. Predict \\(\\hat{y}_t\\) 3. Observe true outcome \\(y_t\\) 4. Suffer loss \\(\\ell({\\hat{y}_t, y_t})\\) 5. Update model\nRegret definition:\n\\[\nR_T = \\sum_{t=1}^T \\ell(h_t(x_t), y_t) - \\min_{h \\in \\mathcal{H}}\\sum_{t=1}^T \\ell(h(x_t), y_t)\n\\]\n\n\n\nExternal regret:\n\\[\nR_T^{\\text{ext}} = \\mathbb{E}\\left[\\sum_{t=1}^T \\ell_t(a_t)\\right] - \\min_{a \\in \\mathcal{A}}\\mathbb{E}\\left[\\sum_{t=1}^T \\ell_t(a)\\right]\n\\]\nInternal/swap regret:\n\\[\nR_T^{\\text{int}} = \\mathbb{E}\\left[\\sum_{t=1}^T \\ell_t(a_t)\\right] - \\min_{\\phi: \\mathcal{A} \\to \\mathcal{A}}\\mathbb{E}\\left[\\sum_{t=1}^T \\ell_t(\\phi(a_t))\\right]\n\\]\n\n\n\nAverage regret:\n\\[\n\\bar{R}_T = \\frac{R_T}{T}\n\\]\nCompetitive ratio:\n\\[\nCR_T = \\frac{\\sum_{t=1}^T \\ell_t(a_t)}{\\min_{a \\in \\mathcal{A}}\\sum_{t=1}^T \\ell_t(a)}\n\\]\n\n\n\n\n\n\nUpdate rule:\n\\[\nw_{t+1} = \\Pi_{\\mathcal{W}}(w_t - \\eta_t \\nabla \\ell_t(w_t))\n\\]\nRegret bound:\n\\[\nR_T \\leq \\frac{D^2}{2\\eta} + \\frac{\\eta G^2T}{2}\n\\]\nWhere: - \\(D\\) is diameter of feasible set - \\(G\\) is gradient bound - \\(\\eta\\) is learning rate\n\n\n\nFTRL update:\n\\[\nw_{t+1} = \\arg\\min_{w \\in \\mathcal{W}}\\{\\eta\\sum_{s=1}^t \\ell_s(w) + R(w)\\}\n\\]\nRegret bound:\n\\[\nR_T \\leq \\frac{R(w^*)}{\\eta} + \\frac{\\eta G^2T}{2}\n\\]\n\n\n\nUpdate rule:\n\\[\n\\nabla \\psi(w_{t+1}) = \\nabla \\psi(w_t) - \\eta_t \\nabla \\ell_t(w_t)\n\\]\nRegret bound:\n\\[\nR_T \\leq \\frac{D_\\psi(w^*\\|w_1)}{\\eta} + \\frac{\\eta G^2T}{2}\n\\]\n\n\n\n\n\n\nUCB index:\n\\[\nUCB_i(t) = \\hat{\\mu}_i(t) + \\sqrt{\\frac{2\\ln t}{N_i(t)}}\n\\]\nRegret bound:\n\\[\nR_T \\leq \\sum_{i:\\Delta_i&gt;0}\\left(\\frac{8\\ln T}{\\Delta_i} + (1+\\pi^2/3)\\Delta_i\\right)\n\\]\n\n\n\nPosterior sampling:\n\\[\n\\theta_i(t) \\sim Beta(\\alpha_i(t), \\beta_i(t))\n\\]\nRegret bound:\n\\[\nR_T \\leq O(\\sqrt{KT\\ln T})\n\\]\n\n\n\nProbability update:\n\\[\np_i(t) = \\frac{(1-\\gamma)\\exp(\\eta G_i(t))}{\\sum_{j=1}^K \\exp(\\eta G_j(t))} + \\frac{\\gamma}{K}\n\\]\nRegret bound:\n\\[\nR_T \\leq 2\\sqrt{KT\\ln K}\n\\]\n\n\n\n\n\n\nWeight update:\n\\[\nw_i(t+1) = w_i(t)(1-\\eta)^{\\ell_i(t)}\n\\]\nRegret bound:\n\\[\nR_T \\leq \\sqrt{T\\ln N}\n\\]\n\n\n\nProbability update:\n\\[\np_i(t+1) = \\frac{\\exp(-\\eta L_i(t))}{\\sum_{j=1}^N \\exp(-\\eta L_j(t))}\n\\]\nRegret bound:\n\\[\nR_T \\leq \\sqrt{2T\\ln N}\n\\]\n\n\n\nAdaptive learning rate:\n\\[\n\\eta_t = \\frac{\\ln N}{V_t}\n\\]\nWhere: - \\(V_t\\) is cumulative variance - \\(N\\) is number of experts\n\n\n\n\n\n\nAdaGrad update:\n\\[\nw_{t+1,i} = w_{t,i} - \\frac{\\eta}{\\sqrt{\\sum_{s=1}^t g_{s,i}^2}}g_{t,i}\n\\]\nRegret bound:\n\\[\nR_T \\leq O(\\sqrt{T}\\|w^*\\|_2\\sqrt{\\sum_{i=1}^d\\sum_{t=1}^T g_{t,i}^2})\n\\]\n\n\n\nONS update:\n\\[\nw_{t+1} = w_t - \\eta A_t^{-1}\\nabla \\ell_t(w_t)\n\\]\nWhere: - \\(A_t = \\sum_{s=1}^t \\nabla \\ell_s(w_s)\\nabla \\ell_s(w_s)^T\\)\n\n\n\nMetaGrad update:\n\\[\nw_{t+1} = w_t - \\eta_t H_t^{-1/2}\\nabla \\ell_t(w_t)\n\\]\nWhere: - \\(H_t\\) is preconditioner matrix\n\n\n\n\n\n\nObjective:\n\\[\n\\max_{w \\in \\Delta_n} \\sum_{t=1}^T \\log(w^T r_t)\n\\]\nUniversal portfolio:\n\\[\nw_{t+1} = \\int_{\\Delta_n} w P_t(w)dw\n\\]\n\n\n\nFlow update:\n\\[\nf_{t+1}(e) = f_t(e)\\exp(-\\eta \\ell_t(e))\n\\]\nPath selection:\n\\[\nP(p) = \\frac{\\prod_{e \\in p}f_t(e)}{\\sum_{p' \\in \\mathcal{P}}\\prod_{e \\in p'}f_t(e)}\n\\]\n\n\n\nPerceptron update:\n\\[\nw_{t+1} = w_t + y_tx_t\\mathbb{1}[y_tw_t^Tx_t \\leq 0]\n\\]\nMistake bound:\n\\[\nM \\leq \\left(\\frac{R}{\\gamma}\\right)^2\n\\]\n\n\n\n\n\n\nMinimax regret:\n\\[\n\\min_{\\text{ALG}}\\max_{\\text{ADV}} R_T = \\Omega(\\sqrt{T})\n\\]\nExpert setting:\n\\[\nR_T = \\Omega(\\sqrt{T\\ln N})\n\\]\n\n\n\nRedundancy bound:\n\\[\nR_T \\leq \\frac{KL(P\\|Q) + \\ln(1/\\delta)}{\\eta} + \\frac{\\eta T}{8}\n\\]\n\n\n\nNash equilibrium:\n\\[\n\\max_P \\min_Q \\mathbb{E}_{p \\sim P, q \\sim Q}[M(p,q)] = \\min_Q \\max_P \\mathbb{E}_{p \\sim P, q \\sim Q}[M(p,q)]\n\\]\n\n\n\n\n\n\n\nProblem Structure:\n\nConvexity\nSmoothness\nSparsity\n\nComputational Constraints:\n\nMemory limits\nUpdate time\nParallelization\n\nPerformance Requirements:\n\nRegret bounds\nAdaptation speed\nRobustness\n\n\n\n\n\n\nLearning Rates:\n\nFixed vs adaptive\nSchedule design\nInitialization\n\nExploration:\n\nExploration rate\nDecay schedule\nAdaptive schemes\n\nRegularization:\n\nStrength\nType selection\nAdaptation\n\n\n\n\n\n\n\n\n\nRobustness:\n\nAdversarial scenarios\nNoise handling\nDistribution shifts\n\nEfficiency:\n\nMemory usage\nUpdate complexity\nParallelization\n\nAdaptivity:\n\nParameter tuning\nDistribution changes\nModel selection\n\n\n\n\n\n\nData Handling:\n\nStreaming processing\nFeature extraction\nPreprocessing\n\nMonitoring:\n\nRegret tracking\nPerformance metrics\nResource usage\n\nDeployment:\n\nSystem integration\nError handling\nScaling strategy\n\n\n\n\n\n\n\nTheory:\n\n“Introduction to Online Convex Optimization” by Hazan\n“Bandit Algorithms” by Lattimore and Szepesvári\n“Prediction, Learning, and Games” by Cesa-Bianchi and Lugosi\n\nMethods:\n\n“Online Learning and Online Convex Optimization” by Shalev-Shwartz\n“A Modern Introduction to Online Learning” by Orabona\n“Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems” by Bubeck and Cesa-Bianchi\n\nApplications:\n\n“Online Portfolio Selection” by Li and Hoi\n“Online Learning in Routing Games” by Roughgarden\n“Online Methods in Machine Learning” by Bottou"
  },
  {
    "objectID": "posts/online-learning/index.html#fundamental-concepts",
    "href": "posts/online-learning/index.html#fundamental-concepts",
    "title": "Online Learning and Regret Minimization",
    "section": "",
    "text": "Learning process: 1. Receive instance \\(x_t\\) 2. Predict \\(\\hat{y}_t\\) 3. Observe true outcome \\(y_t\\) 4. Suffer loss \\(\\ell({\\hat{y}_t, y_t})\\) 5. Update model\nRegret definition:\n\\[\nR_T = \\sum_{t=1}^T \\ell(h_t(x_t), y_t) - \\min_{h \\in \\mathcal{H}}\\sum_{t=1}^T \\ell(h(x_t), y_t)\n\\]\n\n\n\nExternal regret:\n\\[\nR_T^{\\text{ext}} = \\mathbb{E}\\left[\\sum_{t=1}^T \\ell_t(a_t)\\right] - \\min_{a \\in \\mathcal{A}}\\mathbb{E}\\left[\\sum_{t=1}^T \\ell_t(a)\\right]\n\\]\nInternal/swap regret:\n\\[\nR_T^{\\text{int}} = \\mathbb{E}\\left[\\sum_{t=1}^T \\ell_t(a_t)\\right] - \\min_{\\phi: \\mathcal{A} \\to \\mathcal{A}}\\mathbb{E}\\left[\\sum_{t=1}^T \\ell_t(\\phi(a_t))\\right]\n\\]\n\n\n\nAverage regret:\n\\[\n\\bar{R}_T = \\frac{R_T}{T}\n\\]\nCompetitive ratio:\n\\[\nCR_T = \\frac{\\sum_{t=1}^T \\ell_t(a_t)}{\\min_{a \\in \\mathcal{A}}\\sum_{t=1}^T \\ell_t(a)}\n\\]"
  },
  {
    "objectID": "posts/online-learning/index.html#online-convex-optimization",
    "href": "posts/online-learning/index.html#online-convex-optimization",
    "title": "Online Learning and Regret Minimization",
    "section": "",
    "text": "Update rule:\n\\[\nw_{t+1} = \\Pi_{\\mathcal{W}}(w_t - \\eta_t \\nabla \\ell_t(w_t))\n\\]\nRegret bound:\n\\[\nR_T \\leq \\frac{D^2}{2\\eta} + \\frac{\\eta G^2T}{2}\n\\]\nWhere: - \\(D\\) is diameter of feasible set - \\(G\\) is gradient bound - \\(\\eta\\) is learning rate\n\n\n\nFTRL update:\n\\[\nw_{t+1} = \\arg\\min_{w \\in \\mathcal{W}}\\{\\eta\\sum_{s=1}^t \\ell_s(w) + R(w)\\}\n\\]\nRegret bound:\n\\[\nR_T \\leq \\frac{R(w^*)}{\\eta} + \\frac{\\eta G^2T}{2}\n\\]\n\n\n\nUpdate rule:\n\\[\n\\nabla \\psi(w_{t+1}) = \\nabla \\psi(w_t) - \\eta_t \\nabla \\ell_t(w_t)\n\\]\nRegret bound:\n\\[\nR_T \\leq \\frac{D_\\psi(w^*\\|w_1)}{\\eta} + \\frac{\\eta G^2T}{2}\n\\]"
  },
  {
    "objectID": "posts/online-learning/index.html#multi-armed-bandits",
    "href": "posts/online-learning/index.html#multi-armed-bandits",
    "title": "Online Learning and Regret Minimization",
    "section": "",
    "text": "UCB index:\n\\[\nUCB_i(t) = \\hat{\\mu}_i(t) + \\sqrt{\\frac{2\\ln t}{N_i(t)}}\n\\]\nRegret bound:\n\\[\nR_T \\leq \\sum_{i:\\Delta_i&gt;0}\\left(\\frac{8\\ln T}{\\Delta_i} + (1+\\pi^2/3)\\Delta_i\\right)\n\\]\n\n\n\nPosterior sampling:\n\\[\n\\theta_i(t) \\sim Beta(\\alpha_i(t), \\beta_i(t))\n\\]\nRegret bound:\n\\[\nR_T \\leq O(\\sqrt{KT\\ln T})\n\\]\n\n\n\nProbability update:\n\\[\np_i(t) = \\frac{(1-\\gamma)\\exp(\\eta G_i(t))}{\\sum_{j=1}^K \\exp(\\eta G_j(t))} + \\frac{\\gamma}{K}\n\\]\nRegret bound:\n\\[\nR_T \\leq 2\\sqrt{KT\\ln K}\n\\]"
  },
  {
    "objectID": "posts/online-learning/index.html#expert-algorithms",
    "href": "posts/online-learning/index.html#expert-algorithms",
    "title": "Online Learning and Regret Minimization",
    "section": "",
    "text": "Weight update:\n\\[\nw_i(t+1) = w_i(t)(1-\\eta)^{\\ell_i(t)}\n\\]\nRegret bound:\n\\[\nR_T \\leq \\sqrt{T\\ln N}\n\\]\n\n\n\nProbability update:\n\\[\np_i(t+1) = \\frac{\\exp(-\\eta L_i(t))}{\\sum_{j=1}^N \\exp(-\\eta L_j(t))}\n\\]\nRegret bound:\n\\[\nR_T \\leq \\sqrt{2T\\ln N}\n\\]\n\n\n\nAdaptive learning rate:\n\\[\n\\eta_t = \\frac{\\ln N}{V_t}\n\\]\nWhere: - \\(V_t\\) is cumulative variance - \\(N\\) is number of experts"
  },
  {
    "objectID": "posts/online-learning/index.html#advanced-topics",
    "href": "posts/online-learning/index.html#advanced-topics",
    "title": "Online Learning and Regret Minimization",
    "section": "",
    "text": "AdaGrad update:\n\\[\nw_{t+1,i} = w_{t,i} - \\frac{\\eta}{\\sqrt{\\sum_{s=1}^t g_{s,i}^2}}g_{t,i}\n\\]\nRegret bound:\n\\[\nR_T \\leq O(\\sqrt{T}\\|w^*\\|_2\\sqrt{\\sum_{i=1}^d\\sum_{t=1}^T g_{t,i}^2})\n\\]\n\n\n\nONS update:\n\\[\nw_{t+1} = w_t - \\eta A_t^{-1}\\nabla \\ell_t(w_t)\n\\]\nWhere: - \\(A_t = \\sum_{s=1}^t \\nabla \\ell_s(w_s)\\nabla \\ell_s(w_s)^T\\)\n\n\n\nMetaGrad update:\n\\[\nw_{t+1} = w_t - \\eta_t H_t^{-1/2}\\nabla \\ell_t(w_t)\n\\]\nWhere: - \\(H_t\\) is preconditioner matrix"
  },
  {
    "objectID": "posts/online-learning/index.html#applications",
    "href": "posts/online-learning/index.html#applications",
    "title": "Online Learning and Regret Minimization",
    "section": "",
    "text": "Objective:\n\\[\n\\max_{w \\in \\Delta_n} \\sum_{t=1}^T \\log(w^T r_t)\n\\]\nUniversal portfolio:\n\\[\nw_{t+1} = \\int_{\\Delta_n} w P_t(w)dw\n\\]\n\n\n\nFlow update:\n\\[\nf_{t+1}(e) = f_t(e)\\exp(-\\eta \\ell_t(e))\n\\]\nPath selection:\n\\[\nP(p) = \\frac{\\prod_{e \\in p}f_t(e)}{\\sum_{p' \\in \\mathcal{P}}\\prod_{e \\in p'}f_t(e)}\n\\]\n\n\n\nPerceptron update:\n\\[\nw_{t+1} = w_t + y_tx_t\\mathbb{1}[y_tw_t^Tx_t \\leq 0]\n\\]\nMistake bound:\n\\[\nM \\leq \\left(\\frac{R}{\\gamma}\\right)^2\n\\]"
  },
  {
    "objectID": "posts/online-learning/index.html#theoretical-results",
    "href": "posts/online-learning/index.html#theoretical-results",
    "title": "Online Learning and Regret Minimization",
    "section": "",
    "text": "Minimax regret:\n\\[\n\\min_{\\text{ALG}}\\max_{\\text{ADV}} R_T = \\Omega(\\sqrt{T})\n\\]\nExpert setting:\n\\[\nR_T = \\Omega(\\sqrt{T\\ln N})\n\\]\n\n\n\nRedundancy bound:\n\\[\nR_T \\leq \\frac{KL(P\\|Q) + \\ln(1/\\delta)}{\\eta} + \\frac{\\eta T}{8}\n\\]\n\n\n\nNash equilibrium:\n\\[\n\\max_P \\min_Q \\mathbb{E}_{p \\sim P, q \\sim Q}[M(p,q)] = \\min_Q \\max_P \\mathbb{E}_{p \\sim P, q \\sim Q}[M(p,q)]\n\\]"
  },
  {
    "objectID": "posts/online-learning/index.html#implementation-considerations",
    "href": "posts/online-learning/index.html#implementation-considerations",
    "title": "Online Learning and Regret Minimization",
    "section": "",
    "text": "Problem Structure:\n\nConvexity\nSmoothness\nSparsity\n\nComputational Constraints:\n\nMemory limits\nUpdate time\nParallelization\n\nPerformance Requirements:\n\nRegret bounds\nAdaptation speed\nRobustness\n\n\n\n\n\n\nLearning Rates:\n\nFixed vs adaptive\nSchedule design\nInitialization\n\nExploration:\n\nExploration rate\nDecay schedule\nAdaptive schemes\n\nRegularization:\n\nStrength\nType selection\nAdaptation"
  },
  {
    "objectID": "posts/online-learning/index.html#best-practices",
    "href": "posts/online-learning/index.html#best-practices",
    "title": "Online Learning and Regret Minimization",
    "section": "",
    "text": "Robustness:\n\nAdversarial scenarios\nNoise handling\nDistribution shifts\n\nEfficiency:\n\nMemory usage\nUpdate complexity\nParallelization\n\nAdaptivity:\n\nParameter tuning\nDistribution changes\nModel selection\n\n\n\n\n\n\nData Handling:\n\nStreaming processing\nFeature extraction\nPreprocessing\n\nMonitoring:\n\nRegret tracking\nPerformance metrics\nResource usage\n\nDeployment:\n\nSystem integration\nError handling\nScaling strategy"
  },
  {
    "objectID": "posts/online-learning/index.html#references",
    "href": "posts/online-learning/index.html#references",
    "title": "Online Learning and Regret Minimization",
    "section": "",
    "text": "Theory:\n\n“Introduction to Online Convex Optimization” by Hazan\n“Bandit Algorithms” by Lattimore and Szepesvári\n“Prediction, Learning, and Games” by Cesa-Bianchi and Lugosi\n\nMethods:\n\n“Online Learning and Online Convex Optimization” by Shalev-Shwartz\n“A Modern Introduction to Online Learning” by Orabona\n“Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems” by Bubeck and Cesa-Bianchi\n\nApplications:\n\n“Online Portfolio Selection” by Li and Hoi\n“Online Learning in Routing Games” by Roughgarden\n“Online Methods in Machine Learning” by Bottou"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html",
    "href": "posts/ml-in-everyday-life/index.html",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "You might not realize it, but machine learning is already a big part of your daily routine. From the moment you wake up until you go to bed, ML algorithms are working behind the scenes to make your life easier and more convenient.\n\n\n\n\n\nSmart Thermostats\n\nLearn your temperature preferences\nAdjust based on time of day\nSave energy by predicting when you’re away\nExample: Nest Learning Thermostat\n\nVoice Assistants\n\nRecognize your voice commands\nLearn your accent and speaking patterns\nImprove understanding over time\nExamples: Alexa, Google Assistant, Siri\n\n\n\n\n\n\nFace Recognition\n\nUnlocks your phone securely\nAdapts to changes in appearance\nWorks in different lighting conditions\n\nKeyboard Predictions\n\nLearns your typing patterns\nSuggests words based on context\nAdapts to your vocabulary\n\n\n\n\n\n\n\n\n\nTraffic Prediction\n\nAnalyzes historical traffic patterns\nPredicts delays in real-time\nSuggests faster routes\nExample: Google Maps, Waze\n\n\n\n\n\n\nPrice Optimization\n\nAdjusts prices based on demand\nPredicts busy periods\nMatches drivers efficiently\nExamples: Uber, Lyft\n\n\n\n\n\n\n\n\n\nSpam Filtering\n\nIdentifies unwanted emails\nLearns from your actions\nAdapts to new spam patterns\n\nSmart Categorization\n\nSorts emails automatically\nPrioritizes important messages\nSuggests quick responses\n\n\n\n\n\n\nDocument Search\n\nUnderstands natural language queries\nFinds relevant files quickly\nImproves with usage\n\nMeeting Scheduling\n\nLearns preferred meeting times\nSuggests optimal slots\nConsiders participants’ schedules\n\n\n\n\n\n\n\n\n\nProduct Recommendations\n\nBased on your browsing history\nSimilar items you might like\nPersonalized deals\nExample: Amazon’s recommendations\n\nPrice Tracking\n\nPredicts price changes\nAlerts for best buying times\nFinds similar products\n\n\n\n\n\n\nContent Recommendations\n\nLearns your viewing preferences\nSuggests new shows/movies\nPersonalizes homepage\nExamples: Netflix, Spotify\n\n\n\n\n\n\nFeed Customization\n\nShows relevant content\nLearns from your interactions\nFilters unwanted content\nExamples: Instagram, Facebook\n\n\n\n\n\n\n\n\n\nActivity Recognition\n\nIdentifies exercise types\nCounts steps accurately\nMonitors sleep patterns\n\nHealth Insights\n\nPredicts fitness trends\nSuggests workout improvements\nPersonalizes goals\n\n\n\n\n\n\nSymptom Checking\n\nAnalyzes symptoms\nSuggests possible causes\nRecommends actions\n\nMental Health Support\n\nMood tracking\nPersonalized recommendations\nEarly warning signs\n\n\n\n\n\n\n\n\n\nFraud Detection\n\nSpots unusual transactions\nPrevents unauthorized use\nLearns spending patterns\n\nAutomated Banking\n\nSmart ATMs\nChatbot customer service\nPersonalized financial advice\n\n\n\n\n\n\nBudget Apps\n\nCategorize expenses\nPredict future spending\nSuggest savings opportunities\n\n\n\n\n\n\n\n\n\nIdentifies regular behaviors\n\nSpots unusual activities\nLearns from historical data\n\n\n\n\n\n\nAdapts to individual preferences\n\nImproves with more data\nCreates unique experiences\n\n\n\n\n\n\nAnticipates needs\n\nForecasts events\nSuggests actions\n\n\n\n\n\n\n\n\n\nAutomates routine tasks\n\nProvides quick answers\nReduces decision time\n\n\n\n\n\n\nMore informed choices\n\nPersonalized recommendations\nData-driven insights\n\n\n\n\n\n\nCustomized content\n\nSmoother interactions\nProactive assistance\n\n\n\n\n\n\n\n\n\nWhat data is collected\n\nHow it’s used\nStorage security\n\n\n\n\n\n\nPrivacy settings\n\nOpt-out options\nData access rights\n\n\n\n\n\n\nReview app permissions\n\nRegular privacy checks\nUnderstand data usage\n\n\n\n\n\n\n\n\n\nDeeper understanding\n\nBetter predictions\nTailored experiences\n\n\n\n\n\n\nSeamless connections\n\nCross-device harmony\nUnified experiences\n\n\n\n\n\n\nBetter data protection\n\nMore user control\nTransparent practices\n\n\n\n\n\n\n\n\n\nNotice ML in daily life\n\nUnderstand basic concepts\nStay informed of changes\n\n\n\n\n\n\nEnable helpful features\n\nMaintain privacy\nProvide feedback\n\n\n\n\n\n\nReview settings regularly\n\nUnderstand data sharing\nMake informed choices\n\n\n\n\n\n\nMachine learning is: 1. Already part of daily life 2. Making things easier 3. Constantly improving 4. Working behind the scenes\nRemember: - ML is a tool to help you - You control how to use it - Balance convenience and privacy - Stay informed about changes\n\n\n\n\nFor Learning More:\n\n“AI Basics” courses on Coursera\nYouTube channels about technology\nTech news websites\n\nFor Privacy:\n\nPrivacy setting guides\nData protection websites\nSecurity best practices\n\nFor Updates:\n\nTechnology blogs\nML news websites\nCompany update pages\n\n\nRemember: Machine learning is here to help make your life easier, but it’s important to use it wisely and stay informed about how it affects your daily activities."
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#morning-routine-with-ml",
    "href": "posts/ml-in-everyday-life/index.html#morning-routine-with-ml",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "Smart Thermostats\n\nLearn your temperature preferences\nAdjust based on time of day\nSave energy by predicting when you’re away\nExample: Nest Learning Thermostat\n\nVoice Assistants\n\nRecognize your voice commands\nLearn your accent and speaking patterns\nImprove understanding over time\nExamples: Alexa, Google Assistant, Siri\n\n\n\n\n\n\nFace Recognition\n\nUnlocks your phone securely\nAdapts to changes in appearance\nWorks in different lighting conditions\n\nKeyboard Predictions\n\nLearns your typing patterns\nSuggests words based on context\nAdapts to your vocabulary"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#during-your-commute",
    "href": "posts/ml-in-everyday-life/index.html#during-your-commute",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "Traffic Prediction\n\nAnalyzes historical traffic patterns\nPredicts delays in real-time\nSuggests faster routes\nExample: Google Maps, Waze\n\n\n\n\n\n\nPrice Optimization\n\nAdjusts prices based on demand\nPredicts busy periods\nMatches drivers efficiently\nExamples: Uber, Lyft"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#at-work",
    "href": "posts/ml-in-everyday-life/index.html#at-work",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "Spam Filtering\n\nIdentifies unwanted emails\nLearns from your actions\nAdapts to new spam patterns\n\nSmart Categorization\n\nSorts emails automatically\nPrioritizes important messages\nSuggests quick responses\n\n\n\n\n\n\nDocument Search\n\nUnderstands natural language queries\nFinds relevant files quickly\nImproves with usage\n\nMeeting Scheduling\n\nLearns preferred meeting times\nSuggests optimal slots\nConsiders participants’ schedules"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#shopping-and-entertainment",
    "href": "posts/ml-in-everyday-life/index.html#shopping-and-entertainment",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "Product Recommendations\n\nBased on your browsing history\nSimilar items you might like\nPersonalized deals\nExample: Amazon’s recommendations\n\nPrice Tracking\n\nPredicts price changes\nAlerts for best buying times\nFinds similar products\n\n\n\n\n\n\nContent Recommendations\n\nLearns your viewing preferences\nSuggests new shows/movies\nPersonalizes homepage\nExamples: Netflix, Spotify\n\n\n\n\n\n\nFeed Customization\n\nShows relevant content\nLearns from your interactions\nFilters unwanted content\nExamples: Instagram, Facebook"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#health-and-fitness",
    "href": "posts/ml-in-everyday-life/index.html#health-and-fitness",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "Activity Recognition\n\nIdentifies exercise types\nCounts steps accurately\nMonitors sleep patterns\n\nHealth Insights\n\nPredicts fitness trends\nSuggests workout improvements\nPersonalizes goals\n\n\n\n\n\n\nSymptom Checking\n\nAnalyzes symptoms\nSuggests possible causes\nRecommends actions\n\nMental Health Support\n\nMood tracking\nPersonalized recommendations\nEarly warning signs"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#financial-services",
    "href": "posts/ml-in-everyday-life/index.html#financial-services",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "Fraud Detection\n\nSpots unusual transactions\nPrevents unauthorized use\nLearns spending patterns\n\nAutomated Banking\n\nSmart ATMs\nChatbot customer service\nPersonalized financial advice\n\n\n\n\n\n\nBudget Apps\n\nCategorize expenses\nPredict future spending\nSuggest savings opportunities"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#how-ml-makes-these-possible",
    "href": "posts/ml-in-everyday-life/index.html#how-ml-makes-these-possible",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "Identifies regular behaviors\n\nSpots unusual activities\nLearns from historical data\n\n\n\n\n\n\nAdapts to individual preferences\n\nImproves with more data\nCreates unique experiences\n\n\n\n\n\n\nAnticipates needs\n\nForecasts events\nSuggests actions"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#benefits-in-daily-life",
    "href": "posts/ml-in-everyday-life/index.html#benefits-in-daily-life",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "Automates routine tasks\n\nProvides quick answers\nReduces decision time\n\n\n\n\n\n\nMore informed choices\n\nPersonalized recommendations\nData-driven insights\n\n\n\n\n\n\nCustomized content\n\nSmoother interactions\nProactive assistance"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#privacy-considerations",
    "href": "posts/ml-in-everyday-life/index.html#privacy-considerations",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "What data is collected\n\nHow it’s used\nStorage security\n\n\n\n\n\n\nPrivacy settings\n\nOpt-out options\nData access rights\n\n\n\n\n\n\nReview app permissions\n\nRegular privacy checks\nUnderstand data usage"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#future-trends",
    "href": "posts/ml-in-everyday-life/index.html#future-trends",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "Deeper understanding\n\nBetter predictions\nTailored experiences\n\n\n\n\n\n\nSeamless connections\n\nCross-device harmony\nUnified experiences\n\n\n\n\n\n\nBetter data protection\n\nMore user control\nTransparent practices"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#making-the-most-of-ml",
    "href": "posts/ml-in-everyday-life/index.html#making-the-most-of-ml",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "Notice ML in daily life\n\nUnderstand basic concepts\nStay informed of changes\n\n\n\n\n\n\nEnable helpful features\n\nMaintain privacy\nProvide feedback\n\n\n\n\n\n\nReview settings regularly\n\nUnderstand data sharing\nMake informed choices"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#conclusion",
    "href": "posts/ml-in-everyday-life/index.html#conclusion",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "Machine learning is: 1. Already part of daily life 2. Making things easier 3. Constantly improving 4. Working behind the scenes\nRemember: - ML is a tool to help you - You control how to use it - Balance convenience and privacy - Stay informed about changes"
  },
  {
    "objectID": "posts/ml-in-everyday-life/index.html#additional-resources",
    "href": "posts/ml-in-everyday-life/index.html#additional-resources",
    "title": "Machine Learning in Everyday Life: A Practical Guide",
    "section": "",
    "text": "For Learning More:\n\n“AI Basics” courses on Coursera\nYouTube channels about technology\nTech news websites\n\nFor Privacy:\n\nPrivacy setting guides\nData protection websites\nSecurity best practices\n\nFor Updates:\n\nTechnology blogs\nML news websites\nCompany update pages\n\n\nRemember: Machine learning is here to help make your life easier, but it’s important to use it wisely and stay informed about how it affects your daily activities."
  },
  {
    "objectID": "posts/ml-fundamentals-beginners/index.html",
    "href": "posts/ml-fundamentals-beginners/index.html",
    "title": "Machine Learning: A Beginner’s Guide",
    "section": "",
    "text": "What You’ll Learn\n\n\n\n\nUnderstand machine learning in simple, everyday terms\nWrite your first machine learning code (no experience needed!)\nLearn how Netflix, Spotify, and other apps use ML\nBuild real working models step by step"
  },
  {
    "objectID": "posts/ml-fundamentals-beginners/index.html#introduction-what-is-machine-learning-really",
    "href": "posts/ml-fundamentals-beginners/index.html#introduction-what-is-machine-learning-really",
    "title": "Machine Learning: A Beginner’s Guide",
    "section": "Introduction: What is Machine Learning, Really?",
    "text": "Introduction: What is Machine Learning, Really?\nImagine teaching a child to recognize a cat: - You don’t give them a mathematical formula for “cat-ness”\n\nYou don’t list out exact measurements for ears, whiskers, and tail\nInstead, you show them lots of cat pictures\n\nThis is exactly how machine learning works! Instead of writing strict rules, we show computers lots of examples and let them learn patterns.\n\n\n\n\n\n\nQuick Examples You Already Know\n\n\n\n\n📧 Gmail knowing which emails are spam\n🎵 Spotify suggesting songs you might like\n📱 Face ID unlocking your phone\n🛒 Amazon recommending products\n\nAll of these use machine learning!"
  },
  {
    "objectID": "posts/ml-fundamentals-beginners/index.html#prerequisites-what-you-need-to-know",
    "href": "posts/ml-fundamentals-beginners/index.html#prerequisites-what-you-need-to-know",
    "title": "Machine Learning: A Beginner’s Guide",
    "section": "Prerequisites: What You Need to Know",
    "text": "Prerequisites: What You Need to Know\nDon’t worry if you’re new to programming! We’ll explain everything step by step. You’ll need:\n# These are the tools we'll use - think of them as our ML workshop tools\nimport numpy as np        # For working with numbers\nimport pandas as pd      # For organizing data\nimport matplotlib.pyplot as plt  # For making charts\nfrom sklearn.model_selection import train_test_split  # For splitting our data\nfrom sklearn.linear_model import LinearRegression    # Our first ML model!\n\n# Optional: Make our charts look nice\nplt.style.use('seaborn')\n\n\n\n\n\n\nUnderstanding the Tools\n\n\n\n\nnumpy: Like a super calculator\npandas: Like Excel, but more powerful\nmatplotlib: For making charts and graphs\nsklearn: Our machine learning toolkit"
  },
  {
    "objectID": "posts/ml-fundamentals-beginners/index.html#part-1-your-first-machine-learning-project",
    "href": "posts/ml-fundamentals-beginners/index.html#part-1-your-first-machine-learning-project",
    "title": "Machine Learning: A Beginner’s Guide",
    "section": "Part 1: Your First Machine Learning Project",
    "text": "Part 1: Your First Machine Learning Project\nLet’s start with something everyone understands: house prices!\n\n\n\n\n\n\nWhy Houses?\n\n\n\n\nEveryone knows bigger houses usually cost more\nIt’s easy to visualize\nThe relationship is fairly simple\nIt’s a real-world problem\n\n\n\n\nStep 1: Creating Our Data\n# Create some pretend house data\nnp.random.seed(42)  # This makes our random numbers predictable\n\n# Create 100 house sizes between 1000 and 5000 square feet\nhouse_sizes = np.linspace(1000, 5000, 100)\n\n# Create prices: base price + size factor + some randomness\nbase_price = 200  # Starting at $200K\nsize_factor = 0.3  # Each square foot adds $0.3K\nnoise = np.random.normal(0, 50, 100)  # Random variation\n\nhouse_prices = base_price + size_factor * house_sizes + noise\n\n# Let's look at our data!\nplt.figure(figsize=(10, 6))\nplt.scatter(house_sizes, house_prices, alpha=0.5)\nplt.xlabel('House Size (square feet)')\nplt.ylabel('Price ($K)')\nplt.title('House Prices vs Size')\n\n# Add a grid to make it easier to read\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\n\n\nUnderstanding the Code Above\n\n\n\n\nnp.linspace(1000, 5000, 100): Creates 100 evenly spaced numbers between 1000 and 5000\nbase_price + size_factor * house_sizes: Basic price calculation\n\nExample: A 2000 sq ft house would be: $200K + (0.3 * 2000) = $800K\n\nnoise: Adds random variation, just like real house prices aren’t perfectly predictable\n\n\n\n\n\nStep 2: Training Our First Model\nNow comes the fun part - teaching our computer to predict house prices!\n# Step 1: Prepare the data\nX = house_sizes.reshape(-1, 1)  # Reshape data for scikit-learn\ny = house_prices\n\n# Step 2: Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.2,      # Use 20% for testing\n    random_state=42     # For reproducible results\n)\n\n# Step 3: Create and train the model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)  # The actual learning happens here!\n\n# Step 4: Make predictions\ny_pred = model.predict(X_test)\n\n# Let's visualize what the model learned\nplt.figure(figsize=(12, 7))\n\n# Plot training data\nplt.scatter(X_train, y_train, color='blue', alpha=0.5, label='Training Data')\n\n# Plot testing data\nplt.scatter(X_test, y_test, color='green', alpha=0.5, label='Testing Data')\n\n# Plot the model's predictions\nplt.plot(X_test, y_pred, color='red', linewidth=2, label='Model Predictions')\n\nplt.xlabel('House Size (square feet)')\nplt.ylabel('Price ($K)')\nplt.title('House Price Predictor in Action!')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n# Let's test it out!\ntest_sizes = [1500, 2500, 3500]\nprint(\"\\nLet's predict some house prices:\")\nprint(\"-\" * 40)\nfor size in test_sizes:\n    predicted_price = model.predict([[size]])[0]\n    print(f\"A {size} sq ft house should cost: ${predicted_price:,.2f}K\")\n\n\n\n\n\n\nWhat Just Happened?\n\n\n\n\nWe split our data into two parts:\n\nTraining data (80%): Like studying for a test\nTesting data (20%): Like taking the actual test\n\nThe model learned the relationship between size and price\nThe red line shows what the model learned\nBlue dots are training data, green dots are testing data"
  },
  {
    "objectID": "posts/ml-fundamentals-beginners/index.html#part-2-types-of-machine-learning-with-real-examples",
    "href": "posts/ml-fundamentals-beginners/index.html#part-2-types-of-machine-learning-with-real-examples",
    "title": "Machine Learning: A Beginner’s Guide",
    "section": "Part 2: Types of Machine Learning (With Real Examples!)",
    "text": "Part 2: Types of Machine Learning (With Real Examples!)\n\n1. Supervised Learning: Learning from Examples\nThis is like learning with a teacher who gives you questions AND answers.\n\n\n\n\n\n\nReal-World Examples\n\n\n\n\n📧 Gmail’s Spam Filter\n\nInput: Email content\nOutput: Spam or Not Spam\n\n🏠 Our House Price Predictor\n\nInput: House size\nOutput: Price\n\n📱 Face Recognition\n\nInput: Photo\nOutput: Person’s name\n\n\n\n\nLet’s build another supervised learning example - a simple age classifier:\nfrom sklearn.tree import DecisionTreeClassifier\nimport seaborn as sns\n\n# Create example data\nnp.random.seed(42)\n\n# Generate data for different age groups\nyoung = np.random.normal(25, 5, 50)  # Young people\nmiddle = np.random.normal(45, 5, 50)  # Middle-aged\nsenior = np.random.normal(65, 5, 50)  # Seniors\n\n# Features: Age and Activity Level\nyoung_activity = np.random.normal(8, 1, 50)   # Higher activity\nmiddle_activity = np.random.normal(6, 1, 50)  # Medium activity\nsenior_activity = np.random.normal(4, 1, 50)  # Lower activity\n\n# Combine data\nX = np.vstack([\n    np.column_stack([young, young_activity]),\n    np.column_stack([middle, middle_activity]),\n    np.column_stack([senior, senior_activity])\n])\n\n# Create labels: 0 for young, 1 for middle, 2 for senior\ny = np.array([0]*50 + [1]*50 + [2]*50)\n\n# Train the model\nclf = DecisionTreeClassifier(max_depth=3)  # Simple decision tree\nclf.fit(X, y)\n\n# Create a grid to visualize the decision boundaries\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n                     np.arange(y_min, y_max, 0.1))\n\n# Make predictions for each point in the grid\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n# Plot the results\nplt.figure(figsize=(12, 8))\nplt.contourf(xx, yy, Z, alpha=0.4)\nplt.scatter(X[:, 0], X[:, 1], c=y, alpha=0.8)\nplt.xlabel('Age')\nplt.ylabel('Activity Level (hours/week)')\nplt.title('Age Group Classification')\nplt.colorbar(label='Age Group (0: Young, 1: Middle, 2: Senior)')\nplt.show()\n\n\n\n\n\n\nUnderstanding the Age Classifier\n\n\n\n\nWe created fake data about people’s age and activity levels\nThe model learns to group people into three categories:\n\nYoung (around 25 years)\nMiddle-aged (around 45 years)\nSenior (around 65 years)\n\nThe colored regions show how the model makes decisions\nEach dot represents one person\n\n\n\n\n\n2. Unsupervised Learning: Finding Hidden Patterns\nThis is like organizing your closet - you group similar items together naturally.\nLet’s build a simple customer segmentation system:\nfrom sklearn.cluster import KMeans\n\n# Create customer purchase data\nnp.random.seed(42)\n\n# Generate three types of customers\nbudget_shoppers = np.random.normal(loc=[20, 20], scale=5, size=(100, 2))\nregular_shoppers = np.random.normal(loc=[50, 50], scale=10, size=(100, 2))\nluxury_shoppers = np.random.normal(loc=[80, 80], scale=15, size=(100, 2))\n\n# Combine all customers\ncustomer_data = np.vstack([budget_shoppers, regular_shoppers, luxury_shoppers])\n\n# Find natural groups\nkmeans = KMeans(n_clusters=3, random_state=42)\nclusters = kmeans.fit_predict(customer_data)\n\n# Visualize the customer segments\nplt.figure(figsize=(12, 8))\nscatter = plt.scatter(customer_data[:, 0], customer_data[:, 1], \n                     c=clusters, cmap='viridis', alpha=0.6)\nplt.xlabel('Average Purchase Amount ($)')\nplt.ylabel('Shopping Frequency (visits/month)')\nplt.title('Customer Segments')\nplt.colorbar(scatter, label='Customer Segment')\n\n# Add cluster centers\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='red', marker='x', \n           s=200, linewidth=3, label='Segment Centers')\nplt.legend()\nplt.show()\n\n# Print insights about each segment\nfor i, center in enumerate(centers):\n    print(f\"\\nCustomer Segment {i + 1}:\")\n    print(f\"- Average Purchase: ${center[0]:.2f}\")\n    print(f\"- Shopping Frequency: {center[1]:.1f} visits/month\")\n\n\n\n\n\n\nReal-World Applications of Unsupervised Learning\n\n\n\n\n🎵 Spotify Groups Similar Songs\n\nCreates playlists automatically\nSuggests new music you might like\n\n📺 Netflix Categories\n\nGroups similar movies/shows\nCreates those oddly specific categories you see\n\n🛒 Amazon Customer Segments\n\nGroups shoppers by behavior\nPersonalizes recommendations"
  },
  {
    "objectID": "posts/ml-fundamentals-beginners/index.html#part-3-making-your-models-better",
    "href": "posts/ml-fundamentals-beginners/index.html#part-3-making-your-models-better",
    "title": "Machine Learning: A Beginner’s Guide",
    "section": "Part 3: Making Your Models Better",
    "text": "Part 3: Making Your Models Better\n\n1. Data Preparation\nAlways clean your data first! Here’s a simple example:\n# Create a messy dataset\ndata = pd.DataFrame({\n    'age': [25, 30, None, 40, 35, 28, None],\n    'income': [50000, 60000, 75000, None, 65000, 55000, 80000],\n    'purchase': ['yes', 'no', 'yes', 'no', 'yes', None, 'no']\n})\n\nprint(\"Original Data:\")\nprint(data)\nprint(\"\\nMissing Values:\")\nprint(data.isnull().sum())\n\n# Clean the data\ncleaned_data = data.copy()\n# Fill missing ages with median\ncleaned_data['age'] = cleaned_data['age'].fillna(cleaned_data['age'].median())\n# Fill missing income with mean\ncleaned_data['income'] = cleaned_data['income'].fillna(cleaned_data['income'].mean())\n# Fill missing purchase with mode (most common value)\ncleaned_data['purchase'] = cleaned_data['purchase'].fillna(cleaned_data['purchase'].mode()[0])\n\nprint(\"\\nCleaned Data:\")\nprint(cleaned_data)\n\n\n2. Feature Scaling\nMake sure your features are on the same scale:\nfrom sklearn.preprocessing import StandardScaler\n\n# Create example data\ndata = pd.DataFrame({\n    'age': np.random.normal(35, 10, 1000),          # Ages around 35\n    'income': np.random.normal(50000, 20000, 1000), # Incomes around 50k\n})\n\n# Scale the features\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data)\nscaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n\n# Visualize before and after\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n\n# Before scaling\ndata.boxplot(ax=ax1)\nax1.set_title('Before Scaling')\nax1.set_ylabel('Original Values')\n\n# After scaling\nscaled_df.boxplot(ax=ax2)\nax2.set_title('After Scaling')\nax2.set_ylabel('Scaled Values')\n\nplt.show()\n\n\n\n\n\n\nCommon Beginner Mistakes to Avoid\n\n\n\n\nNot Splitting Data\n\nAlways split into training and testing sets\nDon’t test on your training data!\n\nNot Scaling Features\n\nDifferent scales can confuse the model\nExample: Age (0-100) vs. Income (0-1,000,000)\n\nOverfitting\n\nModel memorizes instead of learning\nLike memorizing test answers without understanding\n\nUsing Complex Models Too Soon\n\nStart simple!\nAdd complexity only when needed"
  },
  {
    "objectID": "posts/ml-fundamentals-beginners/index.html#your-next-steps",
    "href": "posts/ml-fundamentals-beginners/index.html#your-next-steps",
    "title": "Machine Learning: A Beginner’s Guide",
    "section": "Your Next Steps",
    "text": "Your Next Steps\n\nPractice Projects:\n\nPredict student grades based on study hours\nClassify emails as urgent or non-urgent\nGroup movies by their descriptions\n\nResources:\n\n📚 Kaggle.com (free datasets and competitions)\n📺 Google Colab (free Python environment)\n🎓 scikit-learn tutorials\n\nAdvanced Topics to Explore:\n\nDeep Learning\nNatural Language Processing\nComputer Vision\n\n\n\n\n\n\n\n\nRemember\n\n\n\n\nStart with simple projects\nUse real-world examples\nDon’t be afraid to make mistakes\nShare your work with others"
  },
  {
    "objectID": "posts/ml-fundamentals-beginners/index.html#quick-reference-python-for-ml",
    "href": "posts/ml-fundamentals-beginners/index.html#quick-reference-python-for-ml",
    "title": "Machine Learning: A Beginner’s Guide",
    "section": "Quick Reference: Python for ML",
    "text": "Quick Reference: Python for ML\n# Common patterns you'll use often:\n\n# 1. Load and prepare data\ndata = pd.read_csv('your_data.csv')\nX = data.drop('target_column', axis=1)\ny = data['target_column']\n\n# 2. Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# 3. Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# 4. Train model\nmodel = LinearRegression()  # or any other model\nmodel.fit(X_train_scaled, y_train)\n\n# 5. Make predictions\npredictions = model.predict(X_test_scaled)\n\n# 6. Evaluate\nfrom sklearn.metrics import accuracy_score  # for classification\naccuracy = accuracy_score(y_test, predictions)\n\n\n\n\n\n\nNeed Help?\n\n\n\n\nCheck the scikit-learn documentation\nJoin ML communities on Reddit or Discord\nShare your code on GitHub\nAsk questions on Stack Overflow"
  },
  {
    "objectID": "posts/information-theory-ml/index.html",
    "href": "posts/information-theory-ml/index.html",
    "title": "Information Theory in Machine Learning: A Practical Guide",
    "section": "",
    "text": "What You’ll Learn\n\n\n\nBy the end of this guide, you’ll understand: - How information is measured in machine learning - Why entropy matters in data science - How to use information theory for feature selection - Practical applications in deep learning"
  },
  {
    "objectID": "posts/information-theory-ml/index.html#understanding-information-theory-through-examples",
    "href": "posts/information-theory-ml/index.html#understanding-information-theory-through-examples",
    "title": "Information Theory in Machine Learning: A Practical Guide",
    "section": "Understanding Information Theory Through Examples",
    "text": "Understanding Information Theory Through Examples\nLet’s start with a practical example:\n\nCodeExplanation\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import entropy\nimport seaborn as sns\n\ndef calculate_entropy(probabilities):\n    \"\"\"Calculate Shannon entropy of a probability distribution\"\"\"\n    return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n\n# Example: Fair vs Loaded Dice\nfair_die = np.ones(6) / 6  # Fair die probabilities\nloaded_die = np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.5])  # Loaded die probabilities\n\nprint(f\"Fair Die Entropy: {calculate_entropy(fair_die):.2f} bits\")\nprint(f\"Loaded Die Entropy: {calculate_entropy(loaded_die):.2f} bits\")\n\n# Visualize probabilities and entropy\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n\n# Plot probability distributions\nx = np.arange(1, 7)\nwidth = 0.35\nax1.bar(x - width/2, fair_die, width, label='Fair Die')\nax1.bar(x + width/2, loaded_die, width, label='Loaded Die')\nax1.set_xlabel('Outcome')\nax1.set_ylabel('Probability')\nax1.set_title('Probability Distributions')\nax1.legend()\n\n# Plot entropy comparison\nentropies = [calculate_entropy(fair_die), calculate_entropy(loaded_die)]\nax2.bar(['Fair Die', 'Loaded Die'], entropies)\nax2.set_ylabel('Entropy (bits)')\nax2.set_title('Entropy Comparison')\n\nplt.tight_layout()\nplt.show()\n\n\nThis example shows how entropy measures uncertainty: - Fair die: Maximum uncertainty = Higher entropy - Loaded die: More predictable = Lower entropy - Entropy quantifies the average “surprise” in the distribution"
  },
  {
    "objectID": "posts/information-theory-ml/index.html#fundamental-concepts",
    "href": "posts/information-theory-ml/index.html#fundamental-concepts",
    "title": "Information Theory in Machine Learning: A Practical Guide",
    "section": "Fundamental Concepts",
    "text": "Fundamental Concepts\n\n1. Shannon Entropy: Measuring Uncertainty\n\n\n\n\n\n\nKey Insight\n\n\n\nEntropy measures the average amount of surprise or uncertainty in a random variable. Higher entropy means more unpredictable outcomes.\n\n\nLet’s visualize how entropy changes with probability:\ndef plot_binary_entropy():\n    \"\"\"Plot entropy of a binary event\"\"\"\n    p = np.linspace(0.01, 0.99, 100)\n    H = -(p * np.log2(p) + (1-p) * np.log2(1-p))\n    \n    plt.figure(figsize=(10, 5))\n    plt.plot(p, H)\n    plt.fill_between(p, H, alpha=0.3)\n    plt.xlabel('Probability of Event')\n    plt.ylabel('Entropy (bits)')\n    plt.title('Binary Entropy Function')\n    plt.grid(True)\n    plt.show()\n\nplot_binary_entropy()\n\n\n2. Mutual Information: Measuring Relationships\nLet’s implement a practical example of mutual information for feature selection:\n\nCodeVisualization\n\n\nfrom sklearn.datasets import make_classification\nfrom sklearn.feature_selection import mutual_info_classif\n\n# Generate synthetic dataset\nX, y = make_classification(n_samples=1000, n_features=20, n_informative=5,\n                         n_redundant=5, n_repeated=0, n_classes=2,\n                         random_state=42)\n\n# Calculate mutual information\nmi_scores = mutual_info_classif(X, y)\n\n# Plot feature importance\nplt.figure(figsize=(12, 5))\nplt.bar(range(len(mi_scores)), mi_scores)\nplt.xlabel('Feature Index')\nplt.ylabel('Mutual Information')\nplt.title('Feature Importance using Mutual Information')\nplt.show()\n\n# Select top features\ntop_features = np.argsort(mi_scores)[-5:]\nprint(\"Top 5 most informative features:\", top_features)\n\n\ndef plot_feature_relationship(X, y, feature_idx):\n    \"\"\"Visualize relationship between feature and target\"\"\"\n    plt.figure(figsize=(10, 5))\n    \n    # Plot distributions\n    for class_label in [0, 1]:\n        sns.kdeplot(X[y == class_label, feature_idx], \n                   label=f'Class {class_label}')\n    \n    plt.xlabel(f'Feature {feature_idx} Value')\n    plt.ylabel('Density')\n    plt.title(f'Feature {feature_idx} Distribution by Class')\n    plt.legend()\n    plt.show()\n\n# Visualize top feature\nplot_feature_relationship(X, y, top_features[-1])\n\n\n\n\n\n3. KL Divergence: Comparing Distributions\nLet’s visualize KL divergence between different distributions:\ndef plot_kl_divergence():\n    \"\"\"Visualize KL divergence between Gaussians\"\"\"\n    x = np.linspace(-5, 5, 1000)\n    \n    # Create two Gaussian distributions\n    mu1, sigma1 = 0, 1\n    mu2, sigma2 = 1, 1.5\n    p = np.exp(-(x - mu1)**2 / (2*sigma1**2)) / (sigma1 * np.sqrt(2*np.pi))\n    q = np.exp(-(x - mu2)**2 / (2*sigma2**2)) / (sigma2 * np.sqrt(2*np.pi))\n    \n    # Calculate KL divergence\n    kl = np.sum(p * np.log(p/q)) * (x[1] - x[0])\n    \n    # Plot\n    plt.figure(figsize=(12, 5))\n    plt.plot(x, p, label='P(x)')\n    plt.plot(x, q, label='Q(x)')\n    plt.fill_between(x, p, q, alpha=0.3)\n    plt.xlabel('x')\n    plt.ylabel('Probability Density')\n    plt.title(f'KL(P||Q) = {kl:.2f}')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\nplot_kl_divergence()"
  },
  {
    "objectID": "posts/information-theory-ml/index.html#applications-in-machine-learning",
    "href": "posts/information-theory-ml/index.html#applications-in-machine-learning",
    "title": "Information Theory in Machine Learning: A Practical Guide",
    "section": "Applications in Machine Learning",
    "text": "Applications in Machine Learning\n\n1. Information Bottleneck in Deep Learning\nLet’s visualize the information plane:\ndef plot_information_plane():\n    \"\"\"Visualize Information Bottleneck principle\"\"\"\n    # Simulate layer-wise mutual information\n    layers = np.arange(1, 6)\n    I_X = np.array([4.5, 3.8, 3.2, 2.8, 2.5])  # I(T;X)\n    I_Y = np.array([0.8, 1.5, 1.8, 1.9, 1.95])  # I(T;Y)\n    \n    plt.figure(figsize=(10, 6))\n    plt.scatter(I_X, I_Y, c=layers, cmap='viridis', s=100)\n    \n    # Add arrows to show progression\n    for i in range(len(layers)-1):\n        plt.arrow(I_X[i], I_Y[i], I_X[i+1]-I_X[i], I_Y[i+1]-I_Y[i],\n                 head_width=0.05, head_length=0.1, fc='k', ec='k')\n    \n    plt.xlabel('I(T;X) - Information about input')\n    plt.ylabel('I(T;Y) - Information about output')\n    plt.title('Information Plane Dynamics')\n    plt.colorbar(label='Layer')\n    plt.grid(True)\n    plt.show()\n\nplot_information_plane()\n\n\n2. Cross-Entropy Loss in Neural Networks\nLet’s implement and visualize cross-entropy loss:\n\nImplementationVisualization\n\n\ndef cross_entropy_loss(y_true, y_pred):\n    \"\"\"Calculate cross-entropy loss\"\"\"\n    return -np.sum(y_true * np.log(y_pred + 1e-10))\n\n# Example with binary classification\ny_true = np.array([1, 0, 1, 1, 0])\ny_pred = np.array([0.9, 0.1, 0.8, 0.7, 0.3])\n\nloss = cross_entropy_loss(y_true, y_pred)\nprint(f\"Cross-Entropy Loss: {loss:.4f}\")\n\n\ndef plot_cross_entropy():\n    \"\"\"Visualize cross-entropy loss\"\"\"\n    p = np.linspace(0.01, 0.99, 100)\n    ce_0 = -np.log(1-p)  # Loss when true label is 0\n    ce_1 = -np.log(p)    # Loss when true label is 1\n    \n    plt.figure(figsize=(10, 5))\n    plt.plot(p, ce_0, label='True Label = 0')\n    plt.plot(p, ce_1, label='True Label = 1')\n    plt.xlabel('Predicted Probability')\n    plt.ylabel('Cross-Entropy Loss')\n    plt.title('Cross-Entropy Loss vs Predicted Probability')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\nplot_cross_entropy()"
  },
  {
    "objectID": "posts/information-theory-ml/index.html#best-practices-and-common-pitfalls",
    "href": "posts/information-theory-ml/index.html#best-practices-and-common-pitfalls",
    "title": "Information Theory in Machine Learning: A Practical Guide",
    "section": "Best Practices and Common Pitfalls",
    "text": "Best Practices and Common Pitfalls\n\n\n\n\n\n\nWatch Out For\n\n\n\n\nNumerical Stability\n\nAlways add small epsilon to log\nUse stable implementations\n\nDistribution Assumptions\n\nCheck if data matches assumptions\nConsider data transformations\n\nInterpretation\n\nEntropy is relative to features\nMI doesn’t imply causation"
  },
  {
    "objectID": "posts/information-theory-ml/index.html#practical-tips",
    "href": "posts/information-theory-ml/index.html#practical-tips",
    "title": "Information Theory in Machine Learning: A Practical Guide",
    "section": "Practical Tips",
    "text": "Practical Tips\n\n\n\n\n\n\nFor Better Results\n\n\n\n\nFeature Selection\n\nUse MI for initial screening\nCombine with other methods\n\nModel Evaluation\n\nMonitor information flow\nUse cross-entropy properly\n\nDistribution Matching\n\nStart with simpler metrics\nProgress to KL/JS divergence"
  },
  {
    "objectID": "posts/information-theory-ml/index.html#further-reading",
    "href": "posts/information-theory-ml/index.html#further-reading",
    "title": "Information Theory in Machine Learning: A Practical Guide",
    "section": "Further Reading",
    "text": "Further Reading\n\nBooksOnline ResourcesTools\n\n\n\n“Elements of Information Theory” by Cover & Thomas\n“Information Theory, Inference, and Learning Algorithms” by MacKay\n“Deep Learning” by Goodfellow et al. (Chapter 3)\n\n\n\n\nInformation Theory Course (Stanford)\nDeep Learning Information Theory Blog\nPyTorch Documentation on Losses\n\n\n\n\nscipy.stats.entropy\nsklearn.feature_selection\ntensorflow.keras.losses\n\n\n\n\nRemember: Information theory provides powerful tools for understanding and improving machine learning models. Start with simple concepts and gradually build up to more complex applications!"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html",
    "href": "posts/deep-learning-beginners/index.html",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "",
    "text": "The first time I encountered deep learning, I was amazed by its ability to solve problems that seemed impossible just a few years ago. From beating world champions at complex games to generating art that could pass for human-made, deep learning has transformed the landscape of artificial intelligence. But what makes this technology so powerful, and how does it actually work?"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html#the-brain-inspired-technology",
    "href": "posts/deep-learning-beginners/index.html#the-brain-inspired-technology",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "The Brain-Inspired Technology",
    "text": "The Brain-Inspired Technology\n\n\n\n\n\n\nKey Insight\n\n\n\nDeep learning is inspired by how our brains work, but it’s a simplified model. Understanding this connection helps grasp the basic concepts more intuitively.\n\n\nThink of it like this: - Your brain has billions of neurons working together to help you recognize faces, understand speech, and make decisions\n\nEach neuron is like a tiny processor, taking in information and deciding whether to pass it on\nDeep learning creates artificial versions of these networks to solve complex problems\n\nLet’s break it down with a simple example:\n\n\n\n\n\n\nReal-World Example: Face Recognition\n\n\n\nWhen you see a friend’s face: 1. Your eyes capture the image (Input Layer) 2. Your brain processes features like eyes, nose, mouth (Hidden Layers) 3. You recognize who it is (Output Layer)\nA deep learning system works similarly!"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html#neural-networks-explained",
    "href": "posts/deep-learning-beginners/index.html#neural-networks-explained",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "Neural Networks Explained",
    "text": "Neural Networks Explained\n\n1. The Basic Building Block: Neurons\n\nConceptPython Example\n\n\nAn artificial neuron is like a simple calculator that: - Takes inputs (like numbers from 0 to 1)\n\nWeighs their importance\nMakes a decision based on the total\n\n\n\nimport numpy as np\n\ndef simple_neuron(inputs, weights):\n    # Multiply inputs by weights and sum them up\n    total = np.dot(inputs, weights)\n    \n    # Decision function (activation)\n    return 1 if total &gt; 0.5 else 0\n\n# Example usage\ninputs = np.array([0.2, 0.7, 0.1])  # Input values\nweights = np.array([0.8, 0.3, 0.5])  # How important each input is\n\nresult = simple_neuron(inputs, weights)\nprint(f\"Neuron output: {result}\")\n\n\n\n\n\n2. Layers of Neurons\n\n\n\n\n\n\nUnderstanding Network Depth\n\n\n\nThe “deep” in deep learning comes from having multiple layers. Each layer: - Learns different levels of features\n\nBuilds upon previous layers\nIncreases the network’s ability to learn complex patterns\n\n\n\nLet’s visualize it:\nInput → [Layer 1] → [Layer 2] → [Layer 3] → Output\n      ↑          ↑          ↑          ↑\nBasic     Simple     Complex    Final\nData    Patterns   Features   Decision"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html#practical-deep-learning",
    "href": "posts/deep-learning-beginners/index.html#practical-deep-learning",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "Practical Deep Learning",
    "text": "Practical Deep Learning\n\n1. Your First Neural Network\n\nCodeExplanation\n\n\nfrom tensorflow import keras\nimport numpy as np\n\n# Create a simple neural network\nmodel = keras.Sequential([\n    keras.layers.Dense(4, activation='relu', input_shape=(3,)),\n    keras.layers.Dense(2, activation='relu'),\n    keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Example data\nX = np.array([[0.1, 0.2, 0.3],\n              [0.4, 0.5, 0.6]])\ny = np.array([0, 1])\n\n# Train the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy')\nmodel.fit(X, y, epochs=10)\n\n\nThis code: 1. Creates a 3-layer neural network 2. Takes 3 numbers as input 3. Processes them through 2 hidden layers 4. Makes a yes/no prediction\n\n\n\n\n\n\n\n\n\nCommon Pitfalls\n\n\n\n\nDon’t use too many layers for simple problems\nStart with small networks and grow as needed\nAlways split your data into training and testing sets"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html#how-neural-networks-learn",
    "href": "posts/deep-learning-beginners/index.html#how-neural-networks-learn",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "How Neural Networks Learn",
    "text": "How Neural Networks Learn\n\n1. The Learning Process\nLike learning to ride a bike: 1. Try something 2. See how well it works 3. Adjust based on mistakes 4. Try again 5. Get better over time\n\n\n2. Training Steps\n\nForward Pass:\n\nData flows through the network\nNetwork makes a prediction\nLike making a guess\n\nError Calculation:\n\nCompare prediction with truth\nCalculate how wrong it was\nLike measuring mistakes\n\nBackward Pass:\n\nAdjust weights based on errors\nLike learning from mistakes\nSmall improvements each time"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html#types-of-neural-networks",
    "href": "posts/deep-learning-beginners/index.html#types-of-neural-networks",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "Types of Neural Networks",
    "text": "Types of Neural Networks\n\n1. Feedforward Networks\nThe simplest type: - Information flows one way - Good for basic patterns - Like classifying images - Example: Identifying numbers\n\n\n2. Convolutional Networks (CNNs)\nSpecialized for images: - Look at small parts at a time - Combine information - Find patterns in images - Example: Face recognition\n\n\n3. Recurrent Networks (RNNs)\nGood for sequences: - Remember previous information - Process data over time - Good for text and speech - Example: Translation"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html#common-applications",
    "href": "posts/deep-learning-beginners/index.html#common-applications",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "Common Applications",
    "text": "Common Applications\n\n1. Computer Vision\nWhat it can do: - Recognize objects\n\nDetect faces\nRead text from images\nIdentify medical conditions\n\nReal Examples: - Face ID on phones - Medical image analysis - Self-driving cars - Security cameras\n\n\n2. Natural Language\nUnderstanding text: - Translation - Summarization - Question answering - Text generation\nReal Examples: - Google Translate - Chatbots - Voice assistants - Email filters\n\n\n3. Speech Processing\nWorking with audio: - Speech recognition - Voice synthesis - Language translation - Music generation\nReal Examples: - Siri/Alexa - Transcription services - Voice assistants - Music recommendations"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html#how-deep-learning-works",
    "href": "posts/deep-learning-beginners/index.html#how-deep-learning-works",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "How Deep Learning Works",
    "text": "How Deep Learning Works\n\n1. Feature Learning\nAutomatic pattern finding: - Low-level features (edges, colors) - Mid-level features (shapes, textures) - High-level features (objects, concepts)\nExample in Vision: 1. First layer sees edges 2. Next layer combines edges into shapes 3. Final layers recognize objects\n\n\n2. Representation Learning\nBuilding understanding: - Converts raw data to useful form - Learns important characteristics - Creates meaningful representations\nExample in Text: 1. Words to numbers 2. Understanding context 3. Capturing meaning\n\n\n3. Deep Learning vs Traditional ML\nKey differences: - Automatic feature extraction - Multiple layers of processing - Better with large datasets - More complex patterns"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html#important-concepts",
    "href": "posts/deep-learning-beginners/index.html#important-concepts",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "Important Concepts",
    "text": "Important Concepts\n\n1. Training Data\nWhat’s needed: - Large amounts of data - Good quality examples - Diverse cases - Clear labels (for supervised learning)\n\n\n2. Computing Power\nRequirements: - Powerful processors (GPUs) - Lots of memory - Long training times - Efficient algorithms\n\n\n3. Model Architecture\nDesign choices: - Number of layers - Types of layers - Connection patterns - Activation functions"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html#common-challenges",
    "href": "posts/deep-learning-beginners/index.html#common-challenges",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "Common Challenges",
    "text": "Common Challenges\n\n1. Data Issues\nCommon problems: - Not enough data - Poor quality data - Biased data - Inconsistent labels\n\n\n2. Training Problems\nTypical issues: - Long training times - Unstable training - Overfitting - Resource limitations\n\n\n3. Deployment Challenges\nReal-world issues: - Model size - Computation needs - Integration - Maintenance"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html#best-practices",
    "href": "posts/deep-learning-beginners/index.html#best-practices",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "Best Practices",
    "text": "Best Practices\n\n1. Start Simple\nBasic approach: - Use proven architectures - Start with small models - Understand the basics - Build complexity gradually\n\n\n2. Data Preparation\nKey steps: - Clean your data - Normalize inputs - Handle missing values - Balance datasets\n\n\n3. Model Development\nGood habits: - Start with baselines - Experiment systematically - Document everything - Test thoroughly"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html#getting-started",
    "href": "posts/deep-learning-beginners/index.html#getting-started",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "Getting Started",
    "text": "Getting Started\n\n1. Prerequisites\nWhat you need: - Python programming - Basic math - Machine learning basics - Development tools\n\n\n2. Learning Path\nSteps to follow: 1. Learn Python 2. Study ML basics 3. Understand neural networks 4. Practice with frameworks\n\n\n3. Tools and Frameworks\nPopular options: - PyTorch - TensorFlow - Keras - Fast.ai"
  },
  {
    "objectID": "posts/deep-learning-beginners/index.html#projects-to-try",
    "href": "posts/deep-learning-beginners/index.html#projects-to-try",
    "title": "Deep Learning: The Technology Behind AI’s Recent Breakthroughs",
    "section": "Projects to Try",
    "text": "Projects to Try\n\n\n\n\n\n\nHands-On Learning\n\n\n\nStart with these beginner-friendly projects: 1. Image Classification: Identify handwritten digits using MNIST dataset 2. Text Classification: Build a simple sentiment analyzer 3. Prediction: Create a basic price prediction model\n\n\n\nResources for Learning\n\nOnline CoursesBooksTools\n\n\n\nFast.ai - Practical Deep Learning for Coders\nCoursera - Deep Learning Specialization\nTensorFlow’s Official Tutorials\n\n\n\n\n“Deep Learning with Python” by François Chollet\n“Grokking Deep Learning” by Andrew Trask\n\n\n\n\nGoogle Colab (free GPU access)\nTensorFlow and Keras\nPyTorch\n\n\n\n\nRemember: Deep learning is powerful but requires patience to learn. Start with simple concepts, practice regularly, and gradually tackle more complex topics. Focus on understanding rather than memorizing, and always experiment with code to reinforce your learning."
  },
  {
    "objectID": "posts/bend-the-curve-intro/index.html",
    "href": "posts/bend-the-curve-intro/index.html",
    "title": "Welcome to BendTheCurve",
    "section": "",
    "text": "What is BendTheCurve?\n\n\n\nA learning platform where we break down complex data science and machine learning concepts into simple, understandable pieces. No PhD required! 🎓"
  },
  {
    "objectID": "posts/bend-the-curve-intro/index.html#why-bendthecurve",
    "href": "posts/bend-the-curve-intro/index.html#why-bendthecurve",
    "title": "Welcome to BendTheCurve",
    "section": "Why BendTheCurve?",
    "text": "Why BendTheCurve?\nHave you ever: - Wondered how Netflix knows exactly what show you’ll like? 🎬\n\nBeen curious about how self-driving cars work? 🚗\nWanted to learn data science but felt overwhelmed? 📊\n\nYou’re in the right place! BendTheCurve is designed to make these fascinating topics accessible to everyone."
  },
  {
    "objectID": "posts/bend-the-curve-intro/index.html#what-well-cover",
    "href": "posts/bend-the-curve-intro/index.html#what-well-cover",
    "title": "Welcome to BendTheCurve",
    "section": "What We’ll Cover",
    "text": "What We’ll Cover\n\n🌱 For Beginners\n\nPython Basics: Start from zero\nData Analysis: Learn to tell stories with data\nMachine Learning 101: Build your first AI models\n\n\n\n🚀 For Intermediate Learners\n\nDeep Learning: Understand neural networks\nNatural Language Processing: Make computers understand text\nComputer Vision: Teach machines to see\n\n\n\n💡 For Advanced Practitioners\n\nResearch Papers Explained: Latest developments in simple terms\nIndustry Best Practices: Real-world applications\nAdvanced Techniques: Cutting-edge methods"
  },
  {
    "objectID": "posts/bend-the-curve-intro/index.html#how-to-use-this-blog",
    "href": "posts/bend-the-curve-intro/index.html#how-to-use-this-blog",
    "title": "Welcome to BendTheCurve",
    "section": "How to Use This Blog",
    "text": "How to Use This Blog\n\n1. Start with the Fundamentals\nBegin with our beginner-friendly series: - Machine Learning Fundamentals\n\nPython for Data Science\nStatistics Made Simple\n\n\n\n2. Choose Your Path\nWe’ve organized content into clear learning paths:\n\n\n\n\n\n\nLearning Paths\n\n\n\n🔰 Beginner Path 1. Python Basics 2. Data Analysis Fundamentals 3. Intro to Machine Learning\n📚 Data Science Path 1. Statistical Methods 2. Data Visualization 3. Advanced Analytics\n🤖 Machine Learning Path 1. ML Algorithms 2. Deep Learning 3. AI Applications\n\n\n\n\n3. Practice with Real Projects\nEvery concept comes with: - 💻 Hands-on code examples - 🎯 Practice exercises - 🏗️ Project ideas"
  },
  {
    "objectID": "posts/bend-the-curve-intro/index.html#what-makes-us-different",
    "href": "posts/bend-the-curve-intro/index.html#what-makes-us-different",
    "title": "Welcome to BendTheCurve",
    "section": "What Makes Us Different",
    "text": "What Makes Us Different\n\nSimple Explanations\n\nNo unnecessary jargon\nReal-world analogies\nVisual learning aids\n\nPractical Focus\n\nIndustry-relevant skills\nReal-world examples\nReady-to-use code\n\nCommunity Support\n\nActive discussions\nQuestion & Answer sessions\nProject sharing"
  },
  {
    "objectID": "posts/bend-the-curve-intro/index.html#join-our-community",
    "href": "posts/bend-the-curve-intro/index.html#join-our-community",
    "title": "Welcome to BendTheCurve",
    "section": "Join Our Community",
    "text": "Join Our Community\n\n💬 Comment on posts\n🤝 Share your projects\n📧 Subscribe to updates\n🐦 Follow on Twitter\n\n\n\n\n\n\n\nGetting Started\n\n\n\n\nPick a learning path that matches your level\nStart with the fundamentals\nPractice with provided examples\nJoin the discussion"
  },
  {
    "objectID": "posts/bend-the-curve-intro/index.html#coming-up-next",
    "href": "posts/bend-the-curve-intro/index.html#coming-up-next",
    "title": "Welcome to BendTheCurve",
    "section": "Coming Up Next",
    "text": "Coming Up Next\nHere’s what we’re working on: - 📊 Data Visualization Masterclass - 🤖 Building Your First Neural Network - 📱 Machine Learning for Mobile Apps"
  },
  {
    "objectID": "posts/bend-the-curve-intro/index.html#resources",
    "href": "posts/bend-the-curve-intro/index.html#resources",
    "title": "Welcome to BendTheCurve",
    "section": "Resources",
    "text": "Resources\n\n🛠️ Tools We’ll Use\n\nPython\nJupyter Notebooks\nPopular ML Libraries\n\n\n\n📚 Recommended Reading\n\nFree online resources\nBook recommendations\nResearch papers explained\n\n\n\n💻 Practice Materials\n\nDatasets\nCode templates\nProject starters\n\n\n\n\n\n\n\nRemember\n\n\n\nEveryone starts somewhere! Don’t feel overwhelmed - we’ll break everything down into manageable pieces.\n\n\nLet’s start this exciting journey together! Choose your first article from the learning paths above, or check out our latest posts.\nHappy Learning! 🚀"
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "ML Journey Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nWelcome to BendTheCurve\n\n\n\n\n\n\nwelcome\n\n\nintroduction\n\n\n\nYour friendly guide to the exciting world of data science and machine learning\n\n\n\n\n\nNov 20, 2024\n\n\n3 min\n\n\n\n\n\n\n\nAdvanced Neural Network Architectures: A Technical Deep Dive\n\n\n\n\n\n\ndeep-learning\n\n\nneural-networks\n\n\narchitectures\n\n\nmathematics\n\n\n\nA comprehensive technical exploration of advanced neural network architectures, including transformers, attention mechanisms, and modern architectural patterns.\n\n\n\n\n\nMar 19, 2024\n\n\n4 min\n\n\n\n\n\n\n\nAlgorithmic Stability and Learning Theory\n\n\n\n\n\n\nmachine-learning\n\n\ntheory\n\n\nmathematics\n\n\nstability\n\n\n\nA beginner-friendly guide to algorithmic stability in machine learning, with interactive visualizations and practical examples.\n\n\n\n\n\nMar 19, 2024\n\n\n14 min\n\n\n\n\n\n\n\nCausal Inference and Structural Learning\n\n\n\n\n\n\nmachine-learning\n\n\ncausality\n\n\nstatistics\n\n\nmathematics\n\n\n\nA rigorous exploration of causal inference and structural learning, covering identification, estimation, and structural causal models.\n\n\n\n\n\nMar 19, 2024\n\n\n3 min\n\n\n\n\n\n\n\nComputational Learning Theory\n\n\n\n\n\n\nmachine-learning\n\n\ntheory\n\n\ncomplexity\n\n\nalgorithms\n\n\n\nA beginner-friendly guide to computational learning theory with interactive visualizations and practical examples.\n\n\n\n\n\nMar 19, 2024\n\n\n9 min\n\n\n\n\n\n\n\nDeep Learning: The Technology Behind AI’s Recent Breakthroughs\n\n\n\n\n\n\ndeep-learning\n\n\nneural-networks\n\n\nbeginner\n\n\n\nDiscover how deep learning is revolutionizing artificial intelligence and why it’s become the driving force behind recent AI breakthroughs.\n\n\n\n\n\nMar 19, 2024\n\n\n6 min\n\n\n\n\n\n\n\nGenerative Models: Mathematical Foundations and Architectures\n\n\n\n\n\n\nmachine-learning\n\n\ngenerative-models\n\n\ndeep-learning\n\n\nmathematics\n\n\n\nA rigorous mathematical exploration of generative models, including GANs, VAEs, and diffusion models.\n\n\n\n\n\nMar 19, 2024\n\n\n4 min\n\n\n\n\n\n\n\nInformation Theory in Machine Learning: A Practical Guide\n\n\n\n\n\n\nmachine-learning\n\n\ninformation-theory\n\n\nmathematics\n\n\ntheory\n\n\n\nA beginner-friendly guide to information theory in machine learning, with practical examples and intuitive explanations.\n\n\n\n\n\nMar 19, 2024\n\n\n7 min\n\n\n\n\n\n\n\nMachine Learning: A Beginner’s Guide\n\n\n\n\n\n\nmachine-learning\n\n\nfundamentals\n\n\npython\n\n\nhands-on\n\n\n\nA beginner-friendly guide to machine learning with clear explanations and practical examples.\n\n\n\n\n\nMar 19, 2024\n\n\n9 min\n\n\n\n\n\n\n\nML Fundamentals: Understanding the Basics\n\n\n\n\n\n\nmachine-learning\n\n\nfundamentals\n\n\ntheory\n\n\n\nA comprehensive introduction to machine learning fundamentals, core concepts, and essential terminology that every aspiring ML practitioner should know.\n\n\n\n\n\nMar 19, 2024\n\n\n4 min\n\n\n\n\n\n\n\nMachine Learning in Everyday Life: A Practical Guide\n\n\n\n\n\n\nmachine-learning\n\n\napplications\n\n\nreal-world\n\n\nbeginner\n\n\n\nDiscover how machine learning is already part of your daily life and how it makes things easier, explained in simple terms with real-world examples.\n\n\n\n\n\nMar 19, 2024\n\n\n5 min\n\n\n\n\n\n\n\nMachine Learning Theory: Mathematical Foundations Made Simple\n\n\n\n\n\n\nmachine-learning\n\n\ntheory\n\n\nmathematics\n\n\nstatistics\n\n\n\nA beginner-friendly guide to machine learning theory, with intuitive explanations and practical examples.\n\n\n\n\n\nMar 19, 2024\n\n\n6 min\n\n\n\n\n\n\n\nOnline Learning and Regret Minimization\n\n\n\n\n\n\nmachine-learning\n\n\ntheory\n\n\nmathematics\n\n\nonline-learning\n\n\n\nA rigorous exploration of online learning theory and regret minimization, covering fundamental algorithms, bounds, and applications.\n\n\n\n\n\nMar 19, 2024\n\n\n4 min\n\n\n\n\n\n\n\nOptimization Algorithms in Machine Learning: A Deep Dive\n\n\n\n\n\n\nmachine-learning\n\n\noptimization\n\n\nmathematics\n\n\nalgorithms\n\n\n\nA comprehensive technical exploration of optimization algorithms in machine learning, covering mathematical foundations and implementation details.\n\n\n\n\n\nMar 19, 2024\n\n\n4 min\n\n\n\n\n\n\n\nOptimization Theory in Machine Learning\n\n\n\n\n\n\nmachine-learning\n\n\noptimization\n\n\nmathematics\n\n\ntheory\n\n\n\nA rigorous exploration of optimization theory in machine learning, covering convex optimization, non-convex optimization, and modern algorithms.\n\n\n\n\n\nMar 19, 2024\n\n\n3 min\n\n\n\n\n\n\n\nPAC Learning Theory and VC Dimension\n\n\n\n\n\n\nmachine-learning\n\n\ntheory\n\n\nmathematics\n\n\nstatistics\n\n\n\nA beginner-friendly guide to PAC learning theory and VC dimension with interactive visualizations and practical examples.\n\n\n\n\n\nMar 19, 2024\n\n\n10 min\n\n\n\n\n\n\n\nProbabilistic Graphical Models: Mathematical Foundations\n\n\n\n\n\n\nmachine-learning\n\n\nprobabilistic-models\n\n\nmathematics\n\n\nbayesian\n\n\n\nA rigorous exploration of probabilistic graphical models, covering mathematical foundations, inference algorithms, and learning methods.\n\n\n\n\n\nMar 19, 2024\n\n\n4 min\n\n\n\n\n\n\n\nUnderstanding Reinforcement Learning: A Beginner’s Guide\n\n\n\n\n\n\nmachine-learning\n\n\nreinforcement-learning\n\n\ntheory\n\n\nbeginner\n\n\n\nA beginner-friendly introduction to reinforcement learning concepts, explained through simple analogies and real-world examples.\n\n\n\n\n\nMar 19, 2024\n\n\n6 min\n\n\n\n\n\n\n\nStatistical Learning Theory and Concentration Inequalities\n\n\n\n\n\n\nmachine-learning\n\n\ntheory\n\n\nmathematics\n\n\nstatistics\n\n\n\nA rigorous exploration of statistical learning theory and concentration inequalities, covering fundamental bounds and their applications in machine learning.\n\n\n\n\n\nMar 19, 2024\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! I’m Ram Polisetti, a passionate learner exploring the world of Machine Learning and Data Science. Through BendThe-Curve, I document my learning journey, share insights, and build a community of fellow ML enthusiasts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BendThe-Curve",
    "section": "",
    "text": "I’ve always wanted to start a blog, but something held me back. The thought of not having a fixed topic or wondering if it would be interesting enough kept me from taking that first step. As time passed, my interests evolved, and I gained more experience in different areas.\nNow, after diving deep into AI, machine learning, and data science, I’ve finally decided to take the leap. This blog isn’t just about sharing knowledge - it’s about documenting this exciting journey through the ever-evolving world of artificial intelligence and helping others who might be on a similar path.\n\n\nCheck out recent posts below. Find more in the Posts section."
  },
  {
    "objectID": "index.html#why-this-blog",
    "href": "index.html#why-this-blog",
    "title": "BendThe-Curve",
    "section": "",
    "text": "I’ve always wanted to start a blog, but something held me back. The thought of not having a fixed topic or wondering if it would be interesting enough kept me from taking that first step. As time passed, my interests evolved, and I gained more experience in different areas.\nNow, after diving deep into AI, machine learning, and data science, I’ve finally decided to take the leap. This blog isn’t just about sharing knowledge - it’s about documenting this exciting journey through the ever-evolving world of artificial intelligence and helping others who might be on a similar path.\n\n\nCheck out recent posts below. Find more in the Posts section."
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html",
    "href": "posts/advanced-neural-architectures/index.html",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "The fundamental building block of modern architectures:\n\\[\n\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n\\]\nWhere: - \\(Q \\in \\mathbb{R}^{n \\times d_k}\\) is the query matrix - \\(K \\in \\mathbb{R}^{m \\times d_k}\\) is the key matrix - \\(V \\in \\mathbb{R}^{m \\times d_v}\\) is the value matrix - \\(d_k\\) is the dimension of keys - \\(\\sqrt{d_k}\\) is the scaling factor\n\n\n\nParallel attention computations:\n\\[\n\\begin{aligned}\n\\text{MultiHead}(Q, K, V) &= \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O \\\\\n\\text{where head}_i &= \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n\\end{aligned}\n\\]\nWhere: - \\(W_i^Q \\in \\mathbb{R}^{d_{model} \\times d_k}\\) - \\(W_i^K \\in \\mathbb{R}^{d_{model} \\times d_k}\\) - \\(W_i^V \\in \\mathbb{R}^{d_{model} \\times d_v}\\) - \\(W^O \\in \\mathbb{R}^{hd_v \\times d_{model}}\\)\n\n\n\n\n\n\nComplete encoder block computation:\n\\[\n\\begin{aligned}\n\\text{MultiHeadAttn} &= \\text{LayerNorm}(x + \\text{MultiHead}(x, x, x)) \\\\\n\\text{FFN}(x) &= \\text{max}(0, xW_1 + b_1)W_2 + b_2 \\\\\n\\text{Output} &= \\text{LayerNorm}(\\text{MultiHeadAttn} + \\text{FFN}(\\text{MultiHeadAttn}))\n\\end{aligned}\n\\]\n\n\n\nSinusoidal position encoding:\n\\[\n\\begin{aligned}\nPE_{(pos,2i)} &= \\sin(pos/10000^{2i/d_{model}}) \\\\\nPE_{(pos,2i+1)} &= \\cos(pos/10000^{2i/d_{model}})\n\\end{aligned}\n\\]\nWhere: - \\(pos\\) is the position - \\(i\\) is the dimension\n\n\n\n\n\n\nResNet block formulation:\n\\[\ny = F(x, \\{W_i\\}) + x\n\\]\nWith pre-activation variant:\n\\[\n\\begin{aligned}\nh &= \\text{ReLU}(\\text{BN}(x)) \\\\\ny &= W_2\\text{ReLU}(\\text{BN}(W_1h)) + x\n\\end{aligned}\n\\]\n\n\n\nDenseNet connectivity pattern:\n\\[\nx_l = H_l([x_0, x_1, ..., x_{l-1}])\n\\]\nWhere: - \\(x_l\\) is the output of layer \\(l\\) - \\(H_l\\) is a composite function - \\([...]\\) represents concatenation\n\n\n\nChannel attention mechanism:\n\\[\n\\begin{aligned}\nz &= F_{sq}(u) = \\frac{1}{H \\times W}\\sum_{i=1}^H\\sum_{j=1}^W u_c(i,j) \\\\\ns &= F_{ex}(z) = \\sigma(W_2\\text{ReLU}(W_1z))\n\\end{aligned}\n\\]\n\n\n\n\n\n\nPosition-aware attention scoring:\n\\[\n\\text{Attention}(Q, K, V, R) = \\text{softmax}\\left(\\frac{QK^T + QR^T}{\\sqrt{d_k}}\\right)V\n\\]\nWhere: - \\(R\\) is the relative position encoding matrix\n\n\n\nEfficient attention computation:\n\\[\n\\text{LinearAttention}(Q, K, V) = \\phi(Q)(\\phi(K)^TV)\n\\]\nWhere: - \\(\\phi\\) is a feature map (e.g., elu(x) + 1)\n\n\n\nStructured sparsity pattern:\n\\[\n\\text{SparseAttention}(Q, K, V) = \\text{softmax}\\left(\\frac{M \\odot (QK^T)}{\\sqrt{d_k}}\\right)V\n\\]\nWhere: - \\(M\\) is a binary mask matrix - \\(\\odot\\) is element-wise multiplication\n\n\n\n\n\n\nComputation across features:\n\\[\n\\text{LN}(x) = \\gamma \\odot \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta\n\\]\nWhere: - \\(\\mu\\) and \\(\\sigma\\) are computed across feature dimension\n\n\n\nFeature group normalization:\n\\[\n\\text{GN}(x) = \\gamma \\odot \\frac{x - \\mu_g}{\\sqrt{\\sigma_g^2 + \\epsilon}} + \\beta\n\\]\nWhere: - \\(\\mu_g\\) and \\(\\sigma_g\\) are computed within groups\n\n\n\n\n\n\nSmooth approximation:\n\\[\n\\text{GELU}(x) = x\\Phi(x) = x \\cdot \\frac{1}{2}\\left[1 + \\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right]\n\\]\n\n\n\nSelf-gated activation:\n\\[\n\\text{Swish}(x) = x \\cdot \\sigma(\\beta x)\n\\]\nWhere: - \\(\\sigma\\) is the sigmoid function - \\(\\beta\\) is a learnable parameter\n\n\n\n\n\n\nOptimization objective:\n\\[\n\\begin{aligned}\n\\min_{\\alpha} & \\quad \\mathcal{L}_{val}(w^*(\\alpha), \\alpha) \\\\\n\\text{s.t.} & \\quad w^*(\\alpha) = \\argmin_w \\mathcal{L}_{train}(w, \\alpha)\n\\end{aligned}\n\\]\n\n\n\nRouting probability:\n\\[\np_{ij} = \\frac{\\exp(\\hat{u}_j|u_i)}{\\sum_k \\exp(\\hat{u}_k|u_i)}\n\\]\nWhere: - \\(u_i\\) is the input capsule - \\(\\hat{u}_j\\) is the prediction vector\n\n\n\n\n\n\nGradient checkpointing:\n\\[\n\\text{memory} = O(\\sqrt{N}) \\text{ instead of } O(N)\n\\]\nWhere: - \\(N\\) is the number of layers\n\n\n\nMixed precision training:\n\\[\n\\begin{aligned}\n\\text{FP16 Forward} &: y = \\text{cast}_{\\text{FP16}}(Wx) \\\\\n\\text{FP32 Master} &: w_{\\text{master}} = w_{\\text{FP32}}\n\\end{aligned}\n\\]\n\n\n\nGradient clipping with norm:\n\\[\ng = \\min\\left(1, \\frac{\\theta}{\\|g\\|}\\right)g\n\\]\nWhere: - \\(\\theta\\) is the clipping threshold - \\(g\\) is the gradient\n\n\n\n\n\n\nDistillation objective:\n\\[\n\\mathcal{L} = \\alpha T^2 \\text{KL}\\left(\\text{softmax}\\left(\\frac{z_t}{T}\\right), \\text{softmax}\\left(\\frac{z_s}{T}\\right)\\right) + (1-\\alpha)\\mathcal{L}_{\\text{CE}}\n\\]\nWhere: - \\(z_t\\) and \\(z_s\\) are teacher and student logits - \\(T\\) is temperature - \\(\\alpha\\) is balancing factor\n\n\n\nCurriculum learning schedule:\n\\[\n\\lambda(t) = \\min\\left(1, \\frac{t}{\\tau}\\right)\n\\]\nWhere: - \\(t\\) is current step - \\(\\tau\\) is ramp-up period\n\n\n\n\n\n\nAttention complexity:\n\\[\n\\begin{aligned}\n\\text{Space} &: O(n^2d) \\\\\n\\text{Time} &: O(n^2d)\n\\end{aligned}\n\\]\nWhere: - \\(n\\) is sequence length - \\(d\\) is hidden dimension\n\n\n\nMaximum path length:\n\\[\n\\text{PathLength} = \\begin{cases}\nO(1) & \\text{for transformers} \\\\\nO(n) & \\text{for RNNs}\n\\end{cases}\n\\]\n\n\n\n\n\n\n\nResidual Connections:\n\nUse in deep networks\nMaintain gradient flow\nEnable deeper architectures\n\nNormalization:\n\nPre-normalization for stability\nLayer normalization for transformers\nBatch normalization for CNNs\n\nAttention Mechanisms:\n\nMulti-head attention for diverse features\nRelative position encoding for sequences\nSparse attention for long sequences\n\n\n\n\n\n\nLearning Rate:\n\nLinear warmup\nCosine decay\nLayer-wise learning rates\n\nRegularization:\n\nDropout in attention\nWeight decay\nLabel smoothing\n\nOptimization:\n\nAdam with weight decay\nGradient clipping\nMixed precision training\n\n\n\n\n\n\n\nArchitecture:\n\n“Attention Is All You Need” by Vaswani et al.\n“Deep Residual Learning” by He et al.\n“Densely Connected Networks” by Huang et al.\n\nTraining:\n\n“On Layer Normalization in the Transformer Architecture” by Xiong et al.\n“Understanding the Difficulty of Training Deep Feedforward Neural Networks” by Glorot and Bengio\n“Mixed Precision Training” by Micikevicius et al.\n\nAnalysis:\n\n“On the Relationship between Self-Attention and Convolutional Layers” by Cordonnier et al.\n“The Transformer Family” by Tay et al.\n“What Does BERT Look At?” by Clark et al."
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html#self-attention-mechanisms",
    "href": "posts/advanced-neural-architectures/index.html#self-attention-mechanisms",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "The fundamental building block of modern architectures:\n\\[\n\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n\\]\nWhere: - \\(Q \\in \\mathbb{R}^{n \\times d_k}\\) is the query matrix - \\(K \\in \\mathbb{R}^{m \\times d_k}\\) is the key matrix - \\(V \\in \\mathbb{R}^{m \\times d_v}\\) is the value matrix - \\(d_k\\) is the dimension of keys - \\(\\sqrt{d_k}\\) is the scaling factor\n\n\n\nParallel attention computations:\n\\[\n\\begin{aligned}\n\\text{MultiHead}(Q, K, V) &= \\text{Concat}(\\text{head}_1, ..., \\text{head}_h)W^O \\\\\n\\text{where head}_i &= \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\n\\end{aligned}\n\\]\nWhere: - \\(W_i^Q \\in \\mathbb{R}^{d_{model} \\times d_k}\\) - \\(W_i^K \\in \\mathbb{R}^{d_{model} \\times d_k}\\) - \\(W_i^V \\in \\mathbb{R}^{d_{model} \\times d_v}\\) - \\(W^O \\in \\mathbb{R}^{hd_v \\times d_{model}}\\)"
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html#transformer-architecture",
    "href": "posts/advanced-neural-architectures/index.html#transformer-architecture",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "Complete encoder block computation:\n\\[\n\\begin{aligned}\n\\text{MultiHeadAttn} &= \\text{LayerNorm}(x + \\text{MultiHead}(x, x, x)) \\\\\n\\text{FFN}(x) &= \\text{max}(0, xW_1 + b_1)W_2 + b_2 \\\\\n\\text{Output} &= \\text{LayerNorm}(\\text{MultiHeadAttn} + \\text{FFN}(\\text{MultiHeadAttn}))\n\\end{aligned}\n\\]\n\n\n\nSinusoidal position encoding:\n\\[\n\\begin{aligned}\nPE_{(pos,2i)} &= \\sin(pos/10000^{2i/d_{model}}) \\\\\nPE_{(pos,2i+1)} &= \\cos(pos/10000^{2i/d_{model}})\n\\end{aligned}\n\\]\nWhere: - \\(pos\\) is the position - \\(i\\) is the dimension"
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html#modern-architectural-patterns",
    "href": "posts/advanced-neural-architectures/index.html#modern-architectural-patterns",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "ResNet block formulation:\n\\[\ny = F(x, \\{W_i\\}) + x\n\\]\nWith pre-activation variant:\n\\[\n\\begin{aligned}\nh &= \\text{ReLU}(\\text{BN}(x)) \\\\\ny &= W_2\\text{ReLU}(\\text{BN}(W_1h)) + x\n\\end{aligned}\n\\]\n\n\n\nDenseNet connectivity pattern:\n\\[\nx_l = H_l([x_0, x_1, ..., x_{l-1}])\n\\]\nWhere: - \\(x_l\\) is the output of layer \\(l\\) - \\(H_l\\) is a composite function - \\([...]\\) represents concatenation\n\n\n\nChannel attention mechanism:\n\\[\n\\begin{aligned}\nz &= F_{sq}(u) = \\frac{1}{H \\times W}\\sum_{i=1}^H\\sum_{j=1}^W u_c(i,j) \\\\\ns &= F_{ex}(z) = \\sigma(W_2\\text{ReLU}(W_1z))\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html#advanced-attention-variants",
    "href": "posts/advanced-neural-architectures/index.html#advanced-attention-variants",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "Position-aware attention scoring:\n\\[\n\\text{Attention}(Q, K, V, R) = \\text{softmax}\\left(\\frac{QK^T + QR^T}{\\sqrt{d_k}}\\right)V\n\\]\nWhere: - \\(R\\) is the relative position encoding matrix\n\n\n\nEfficient attention computation:\n\\[\n\\text{LinearAttention}(Q, K, V) = \\phi(Q)(\\phi(K)^TV)\n\\]\nWhere: - \\(\\phi\\) is a feature map (e.g., elu(x) + 1)\n\n\n\nStructured sparsity pattern:\n\\[\n\\text{SparseAttention}(Q, K, V) = \\text{softmax}\\left(\\frac{M \\odot (QK^T)}{\\sqrt{d_k}}\\right)V\n\\]\nWhere: - \\(M\\) is a binary mask matrix - \\(\\odot\\) is element-wise multiplication"
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html#advanced-normalization-techniques",
    "href": "posts/advanced-neural-architectures/index.html#advanced-normalization-techniques",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "Computation across features:\n\\[\n\\text{LN}(x) = \\gamma \\odot \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta\n\\]\nWhere: - \\(\\mu\\) and \\(\\sigma\\) are computed across feature dimension\n\n\n\nFeature group normalization:\n\\[\n\\text{GN}(x) = \\gamma \\odot \\frac{x - \\mu_g}{\\sqrt{\\sigma_g^2 + \\epsilon}} + \\beta\n\\]\nWhere: - \\(\\mu_g\\) and \\(\\sigma_g\\) are computed within groups"
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html#advanced-activation-functions",
    "href": "posts/advanced-neural-architectures/index.html#advanced-activation-functions",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "Smooth approximation:\n\\[\n\\text{GELU}(x) = x\\Phi(x) = x \\cdot \\frac{1}{2}\\left[1 + \\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right]\n\\]\n\n\n\nSelf-gated activation:\n\\[\n\\text{Swish}(x) = x \\cdot \\sigma(\\beta x)\n\\]\nWhere: - \\(\\sigma\\) is the sigmoid function - \\(\\beta\\) is a learnable parameter"
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html#architectural-optimization",
    "href": "posts/advanced-neural-architectures/index.html#architectural-optimization",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "Optimization objective:\n\\[\n\\begin{aligned}\n\\min_{\\alpha} & \\quad \\mathcal{L}_{val}(w^*(\\alpha), \\alpha) \\\\\n\\text{s.t.} & \\quad w^*(\\alpha) = \\argmin_w \\mathcal{L}_{train}(w, \\alpha)\n\\end{aligned}\n\\]\n\n\n\nRouting probability:\n\\[\np_{ij} = \\frac{\\exp(\\hat{u}_j|u_i)}{\\sum_k \\exp(\\hat{u}_k|u_i)}\n\\]\nWhere: - \\(u_i\\) is the input capsule - \\(\\hat{u}_j\\) is the prediction vector"
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html#implementation-considerations",
    "href": "posts/advanced-neural-architectures/index.html#implementation-considerations",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "Gradient checkpointing:\n\\[\n\\text{memory} = O(\\sqrt{N}) \\text{ instead of } O(N)\n\\]\nWhere: - \\(N\\) is the number of layers\n\n\n\nMixed precision training:\n\\[\n\\begin{aligned}\n\\text{FP16 Forward} &: y = \\text{cast}_{\\text{FP16}}(Wx) \\\\\n\\text{FP32 Master} &: w_{\\text{master}} = w_{\\text{FP32}}\n\\end{aligned}\n\\]\n\n\n\nGradient clipping with norm:\n\\[\ng = \\min\\left(1, \\frac{\\theta}{\\|g\\|}\\right)g\n\\]\nWhere: - \\(\\theta\\) is the clipping threshold - \\(g\\) is the gradient"
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html#advanced-training-techniques",
    "href": "posts/advanced-neural-architectures/index.html#advanced-training-techniques",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "Distillation objective:\n\\[\n\\mathcal{L} = \\alpha T^2 \\text{KL}\\left(\\text{softmax}\\left(\\frac{z_t}{T}\\right), \\text{softmax}\\left(\\frac{z_s}{T}\\right)\\right) + (1-\\alpha)\\mathcal{L}_{\\text{CE}}\n\\]\nWhere: - \\(z_t\\) and \\(z_s\\) are teacher and student logits - \\(T\\) is temperature - \\(\\alpha\\) is balancing factor\n\n\n\nCurriculum learning schedule:\n\\[\n\\lambda(t) = \\min\\left(1, \\frac{t}{\\tau}\\right)\n\\]\nWhere: - \\(t\\) is current step - \\(\\tau\\) is ramp-up period"
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html#performance-analysis",
    "href": "posts/advanced-neural-architectures/index.html#performance-analysis",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "Attention complexity:\n\\[\n\\begin{aligned}\n\\text{Space} &: O(n^2d) \\\\\n\\text{Time} &: O(n^2d)\n\\end{aligned}\n\\]\nWhere: - \\(n\\) is sequence length - \\(d\\) is hidden dimension\n\n\n\nMaximum path length:\n\\[\n\\text{PathLength} = \\begin{cases}\nO(1) & \\text{for transformers} \\\\\nO(n) & \\text{for RNNs}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html#best-practices",
    "href": "posts/advanced-neural-architectures/index.html#best-practices",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "Residual Connections:\n\nUse in deep networks\nMaintain gradient flow\nEnable deeper architectures\n\nNormalization:\n\nPre-normalization for stability\nLayer normalization for transformers\nBatch normalization for CNNs\n\nAttention Mechanisms:\n\nMulti-head attention for diverse features\nRelative position encoding for sequences\nSparse attention for long sequences\n\n\n\n\n\n\nLearning Rate:\n\nLinear warmup\nCosine decay\nLayer-wise learning rates\n\nRegularization:\n\nDropout in attention\nWeight decay\nLabel smoothing\n\nOptimization:\n\nAdam with weight decay\nGradient clipping\nMixed precision training"
  },
  {
    "objectID": "posts/advanced-neural-architectures/index.html#references",
    "href": "posts/advanced-neural-architectures/index.html#references",
    "title": "Advanced Neural Network Architectures: A Technical Deep Dive",
    "section": "",
    "text": "Architecture:\n\n“Attention Is All You Need” by Vaswani et al.\n“Deep Residual Learning” by He et al.\n“Densely Connected Networks” by Huang et al.\n\nTraining:\n\n“On Layer Normalization in the Transformer Architecture” by Xiong et al.\n“Understanding the Difficulty of Training Deep Feedforward Neural Networks” by Glorot and Bengio\n“Mixed Precision Training” by Micikevicius et al.\n\nAnalysis:\n\n“On the Relationship between Self-Attention and Convolutional Layers” by Cordonnier et al.\n“The Transformer Family” by Tay et al.\n“What Does BERT Look At?” by Clark et al."
  },
  {
    "objectID": "posts/causal-inference/index.html",
    "href": "posts/causal-inference/index.html",
    "title": "Causal Inference and Structural Learning",
    "section": "",
    "text": "Definition of SCM:\n\\[\n\\begin{aligned}\nX_i &= f_i(\\text{PA}_i, U_i) \\\\\nU_i &\\sim P(U_i)\n\\end{aligned}\n\\]\nWhere: - \\(X_i\\) are endogenous variables - \\(\\text{PA}_i\\) are parents of \\(X_i\\) - \\(U_i\\) are exogenous variables - \\(f_i\\) are structural equations\n\n\n\nDo-operator formalization:\n\\[\nP(Y|\\text{do}(X=x)) = \\sum_z P(Y|X=x,Z=z)P(Z=z)\n\\]\nBackdoor adjustment:\n\\[\nP(Y|\\text{do}(X=x)) = \\sum_z P(Y|X=x,Z=z)P(Z=z)\n\\]\nWhere Z satisfies the backdoor criterion.\n\n\n\n\n\n\nA set Z satisfies the backdoor criterion relative to (X,Y) if: 1. No node in Z is a descendant of X 2. Z blocks all backdoor paths from X to Y\nFormal criterion:\n\\[\nP(Y|\\text{do}(X)) = \\sum_z P(Y|X,Z)P(Z)\n\\]\n\n\n\nThree conditions: 1. M blocks all directed paths from X to Y 2. No unblocked backdoor path from X to M 3. All backdoor paths from M to Y are blocked by X\nFormula:\n\\[\nP(Y|\\text{do}(X)) = \\sum_m P(m|X)\\sum_{x'}P(Y|m,x')P(x')\n\\]\n\n\n\nRule 1 (Insertion/deletion of observations):\n\\[\nP(y|\\text{do}(x),z,w) = P(y|\\text{do}(x),w)\n\\]\nif (Y ⊥⊥ Z|X,W)\\(_{G_{\\overline{X}}}\\)\nRule 2 (Action/observation exchange):\n\\[\nP(y|\\text{do}(x),\\text{do}(z),w) = P(y|\\text{do}(x),z,w)\n\\]\nif (Y ⊥⊥ Z|X,W)\\(_{G_{\\overline{X}\\underline{Z}}}\\)\nRule 3 (Insertion/deletion of actions):\n\\[\nP(y|\\text{do}(x),\\text{do}(z),w) = P(y|\\text{do}(x),w)\n\\]\nif (Y ⊥⊥ Z|X,W)\\(_{G_{\\overline{X}\\overline{Z(W)}}}\\)\n\n\n\n\n\n\nPropensity score:\n\\[\ne(X) = P(T=1|X)\n\\]\nAverage Treatment Effect (ATE):\n\\[\n\\text{ATE} = \\mathbb{E}[Y(1) - Y(0)] = \\mathbb{E}\\left[\\frac{TY}{e(X)} - \\frac{(1-T)Y}{1-e(X)}\\right]\n\\]\n\n\n\nTwo-stage least squares (2SLS):\nFirst stage: \\[\nX = \\gamma_0 + \\gamma_1Z + \\eta\n\\]\nSecond stage: \\[\nY = \\beta_0 + \\beta_1\\hat{X} + \\epsilon\n\\]\n\n\n\nSharp RD estimator:\n\\[\n\\tau_{SRD} = \\lim_{x \\downarrow c} \\mathbb{E}[Y|X=x] - \\lim_{x \\uparrow c} \\mathbb{E}[Y|X=x]\n\\]\nFuzzy RD estimator:\n\\[\n\\tau_{FRD} = \\frac{\\lim_{x \\downarrow c} \\mathbb{E}[Y|X=x] - \\lim_{x \\uparrow c} \\mathbb{E}[Y|X=x]}{\\lim_{x \\downarrow c} \\mathbb{E}[D|X=x] - \\lim_{x \\uparrow c} \\mathbb{E}[D|X=x]}\n\\]\n\n\n\n\n\n\nPC Algorithm steps: 1. Start with complete undirected graph 2. Remove edges based on conditional independence 3. Orient v-structures 4. Orient remaining edges\nIndependence test statistic:\n\\[\n\\chi^2 = n\\sum_{i,j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n\\]\n\n\n\nBIC score:\n\\[\n\\text{BIC}(G) = \\ell(D|G) - \\frac{\\log n}{2}|G|\n\\]\nWhere: - \\(\\ell(D|G)\\) is log-likelihood - \\(|G|\\) is model complexity - \\(n\\) is sample size\n\n\n\nMMHC algorithm: 1. Learn skeleton using constraint-based method 2. Orient edges using score-based method\nScore function:\n\\[\n\\text{Score}(G) = \\text{BIC}(G) + \\lambda \\text{Sparsity}(G)\n\\]\n\n\n\n\n\n\nFundamental problem of causal inference:\n\\[\n\\text{ACE} = \\mathbb{E}[Y(1) - Y(0)]\n\\]\nBut we only observe:\n\\[\nY = TY(1) + (1-T)Y(0)\n\\]\n\n\n\nDirect and indirect effects:\n\\[\n\\begin{aligned}\n\\text{NDE} &= \\mathbb{E}[Y(t,M(t'))] - \\mathbb{E}[Y(t',M(t'))] \\\\\n\\text{NIE} &= \\mathbb{E}[Y(t,M(t))] - \\mathbb{E}[Y(t,M(t'))]\n\\end{aligned}\n\\]\n\n\n\nG-computation formula:\n\\[\n\\mathbb{E}[Y_{\\bar{a}}] = \\sum_{\\bar{l}} \\prod_{t=0}^K P(l_t|l_{t-1},a_{t-1})P(y|\\bar{l},\\bar{a})\n\\]\n\n\n\n\n\n\nRosenbaum bounds:\n\\[\n\\frac{1}{\\Gamma} \\leq \\frac{P(Z=1|X)P(Z=0|X')}{P(Z=0|X)P(Z=1|X')} \\leq \\Gamma\n\\]\n\n\n\nMultiple imputation:\n\\[\n\\hat{\\theta} = \\frac{1}{M}\\sum_{m=1}^M \\hat{\\theta}_m\n\\]\n\n\n\nConditional average treatment effect:\n\\[\n\\text{CATE}(x) = \\mathbb{E}[Y(1) - Y(0)|X=x]\n\\]\n\n\n\n\n\n\n\nRandomization:\n\nComplete randomization\nStratified randomization\nCluster randomization\n\nSample Size:\n\nPower analysis\nEffect size estimation\nVariance components\n\nMeasurement:\n\nReliability\nValidity\nMissing data handling\n\n\n\n\n\n\nIdentification:\n\nCheck assumptions\nSensitivity analysis\nMultiple methods\n\nEstimation:\n\nRobust methods\nBootstrap\nCross-validation\n\nInterpretation:\n\nEffect sizes\nConfidence intervals\nMultiple testing\n\n\n\n\n\n\n\n\nProgram evaluation: - Treatment effects - Policy analysis - Market interventions\n\n\n\nClinical trials: - Drug efficacy - Treatment comparison - Side effects\n\n\n\nPolicy research: - Educational interventions - Social programs - Behavioral studies\n\n\n\n\n\nTheory:\n\n“Causality” by Pearl\n“Causal Inference in Statistics” by Pearl et al.\n“Elements of Causal Inference” by Peters et al.\n\nMethods:\n\n“Mostly Harmless Econometrics” by Angrist and Pischke\n“Counterfactuals and Causal Inference” by Morgan and Winship\n“Causal Inference for Statistics” by Hernán and Robins\n\nApplications:\n\n“Causal Machine Learning” by Athey and Imbens\n“The Book of Why” by Pearl and Mackenzie\n“Observation and Experiment” by Rosenbaum"
  },
  {
    "objectID": "posts/causal-inference/index.html#structural-causal-models",
    "href": "posts/causal-inference/index.html#structural-causal-models",
    "title": "Causal Inference and Structural Learning",
    "section": "",
    "text": "Definition of SCM:\n\\[\n\\begin{aligned}\nX_i &= f_i(\\text{PA}_i, U_i) \\\\\nU_i &\\sim P(U_i)\n\\end{aligned}\n\\]\nWhere: - \\(X_i\\) are endogenous variables - \\(\\text{PA}_i\\) are parents of \\(X_i\\) - \\(U_i\\) are exogenous variables - \\(f_i\\) are structural equations\n\n\n\nDo-operator formalization:\n\\[\nP(Y|\\text{do}(X=x)) = \\sum_z P(Y|X=x,Z=z)P(Z=z)\n\\]\nBackdoor adjustment:\n\\[\nP(Y|\\text{do}(X=x)) = \\sum_z P(Y|X=x,Z=z)P(Z=z)\n\\]\nWhere Z satisfies the backdoor criterion."
  },
  {
    "objectID": "posts/causal-inference/index.html#identification-methods",
    "href": "posts/causal-inference/index.html#identification-methods",
    "title": "Causal Inference and Structural Learning",
    "section": "",
    "text": "A set Z satisfies the backdoor criterion relative to (X,Y) if: 1. No node in Z is a descendant of X 2. Z blocks all backdoor paths from X to Y\nFormal criterion:\n\\[\nP(Y|\\text{do}(X)) = \\sum_z P(Y|X,Z)P(Z)\n\\]\n\n\n\nThree conditions: 1. M blocks all directed paths from X to Y 2. No unblocked backdoor path from X to M 3. All backdoor paths from M to Y are blocked by X\nFormula:\n\\[\nP(Y|\\text{do}(X)) = \\sum_m P(m|X)\\sum_{x'}P(Y|m,x')P(x')\n\\]\n\n\n\nRule 1 (Insertion/deletion of observations):\n\\[\nP(y|\\text{do}(x),z,w) = P(y|\\text{do}(x),w)\n\\]\nif (Y ⊥⊥ Z|X,W)\\(_{G_{\\overline{X}}}\\)\nRule 2 (Action/observation exchange):\n\\[\nP(y|\\text{do}(x),\\text{do}(z),w) = P(y|\\text{do}(x),z,w)\n\\]\nif (Y ⊥⊥ Z|X,W)\\(_{G_{\\overline{X}\\underline{Z}}}\\)\nRule 3 (Insertion/deletion of actions):\n\\[\nP(y|\\text{do}(x),\\text{do}(z),w) = P(y|\\text{do}(x),w)\n\\]\nif (Y ⊥⊥ Z|X,W)\\(_{G_{\\overline{X}\\overline{Z(W)}}}\\)"
  },
  {
    "objectID": "posts/causal-inference/index.html#estimation-methods",
    "href": "posts/causal-inference/index.html#estimation-methods",
    "title": "Causal Inference and Structural Learning",
    "section": "",
    "text": "Propensity score:\n\\[\ne(X) = P(T=1|X)\n\\]\nAverage Treatment Effect (ATE):\n\\[\n\\text{ATE} = \\mathbb{E}[Y(1) - Y(0)] = \\mathbb{E}\\left[\\frac{TY}{e(X)} - \\frac{(1-T)Y}{1-e(X)}\\right]\n\\]\n\n\n\nTwo-stage least squares (2SLS):\nFirst stage: \\[\nX = \\gamma_0 + \\gamma_1Z + \\eta\n\\]\nSecond stage: \\[\nY = \\beta_0 + \\beta_1\\hat{X} + \\epsilon\n\\]\n\n\n\nSharp RD estimator:\n\\[\n\\tau_{SRD} = \\lim_{x \\downarrow c} \\mathbb{E}[Y|X=x] - \\lim_{x \\uparrow c} \\mathbb{E}[Y|X=x]\n\\]\nFuzzy RD estimator:\n\\[\n\\tau_{FRD} = \\frac{\\lim_{x \\downarrow c} \\mathbb{E}[Y|X=x] - \\lim_{x \\uparrow c} \\mathbb{E}[Y|X=x]}{\\lim_{x \\downarrow c} \\mathbb{E}[D|X=x] - \\lim_{x \\uparrow c} \\mathbb{E}[D|X=x]}\n\\]"
  },
  {
    "objectID": "posts/causal-inference/index.html#structural-learning",
    "href": "posts/causal-inference/index.html#structural-learning",
    "title": "Causal Inference and Structural Learning",
    "section": "",
    "text": "PC Algorithm steps: 1. Start with complete undirected graph 2. Remove edges based on conditional independence 3. Orient v-structures 4. Orient remaining edges\nIndependence test statistic:\n\\[\n\\chi^2 = n\\sum_{i,j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n\\]\n\n\n\nBIC score:\n\\[\n\\text{BIC}(G) = \\ell(D|G) - \\frac{\\log n}{2}|G|\n\\]\nWhere: - \\(\\ell(D|G)\\) is log-likelihood - \\(|G|\\) is model complexity - \\(n\\) is sample size\n\n\n\nMMHC algorithm: 1. Learn skeleton using constraint-based method 2. Orient edges using score-based method\nScore function:\n\\[\n\\text{Score}(G) = \\text{BIC}(G) + \\lambda \\text{Sparsity}(G)\n\\]"
  },
  {
    "objectID": "posts/causal-inference/index.html#advanced-topics",
    "href": "posts/causal-inference/index.html#advanced-topics",
    "title": "Causal Inference and Structural Learning",
    "section": "",
    "text": "Fundamental problem of causal inference:\n\\[\n\\text{ACE} = \\mathbb{E}[Y(1) - Y(0)]\n\\]\nBut we only observe:\n\\[\nY = TY(1) + (1-T)Y(0)\n\\]\n\n\n\nDirect and indirect effects:\n\\[\n\\begin{aligned}\n\\text{NDE} &= \\mathbb{E}[Y(t,M(t'))] - \\mathbb{E}[Y(t',M(t'))] \\\\\n\\text{NIE} &= \\mathbb{E}[Y(t,M(t))] - \\mathbb{E}[Y(t,M(t'))]\n\\end{aligned}\n\\]\n\n\n\nG-computation formula:\n\\[\n\\mathbb{E}[Y_{\\bar{a}}] = \\sum_{\\bar{l}} \\prod_{t=0}^K P(l_t|l_{t-1},a_{t-1})P(y|\\bar{l},\\bar{a})\n\\]"
  },
  {
    "objectID": "posts/causal-inference/index.html#implementation-considerations",
    "href": "posts/causal-inference/index.html#implementation-considerations",
    "title": "Causal Inference and Structural Learning",
    "section": "",
    "text": "Rosenbaum bounds:\n\\[\n\\frac{1}{\\Gamma} \\leq \\frac{P(Z=1|X)P(Z=0|X')}{P(Z=0|X)P(Z=1|X')} \\leq \\Gamma\n\\]\n\n\n\nMultiple imputation:\n\\[\n\\hat{\\theta} = \\frac{1}{M}\\sum_{m=1}^M \\hat{\\theta}_m\n\\]\n\n\n\nConditional average treatment effect:\n\\[\n\\text{CATE}(x) = \\mathbb{E}[Y(1) - Y(0)|X=x]\n\\]"
  },
  {
    "objectID": "posts/causal-inference/index.html#best-practices",
    "href": "posts/causal-inference/index.html#best-practices",
    "title": "Causal Inference and Structural Learning",
    "section": "",
    "text": "Randomization:\n\nComplete randomization\nStratified randomization\nCluster randomization\n\nSample Size:\n\nPower analysis\nEffect size estimation\nVariance components\n\nMeasurement:\n\nReliability\nValidity\nMissing data handling\n\n\n\n\n\n\nIdentification:\n\nCheck assumptions\nSensitivity analysis\nMultiple methods\n\nEstimation:\n\nRobust methods\nBootstrap\nCross-validation\n\nInterpretation:\n\nEffect sizes\nConfidence intervals\nMultiple testing"
  },
  {
    "objectID": "posts/causal-inference/index.html#applications",
    "href": "posts/causal-inference/index.html#applications",
    "title": "Causal Inference and Structural Learning",
    "section": "",
    "text": "Program evaluation: - Treatment effects - Policy analysis - Market interventions\n\n\n\nClinical trials: - Drug efficacy - Treatment comparison - Side effects\n\n\n\nPolicy research: - Educational interventions - Social programs - Behavioral studies"
  },
  {
    "objectID": "posts/causal-inference/index.html#references",
    "href": "posts/causal-inference/index.html#references",
    "title": "Causal Inference and Structural Learning",
    "section": "",
    "text": "Theory:\n\n“Causality” by Pearl\n“Causal Inference in Statistics” by Pearl et al.\n“Elements of Causal Inference” by Peters et al.\n\nMethods:\n\n“Mostly Harmless Econometrics” by Angrist and Pischke\n“Counterfactuals and Causal Inference” by Morgan and Winship\n“Causal Inference for Statistics” by Hernán and Robins\n\nApplications:\n\n“Causal Machine Learning” by Athey and Imbens\n“The Book of Why” by Pearl and Mackenzie\n“Observation and Experiment” by Rosenbaum"
  },
  {
    "objectID": "posts/generative-models/index.html",
    "href": "posts/generative-models/index.html",
    "title": "Generative Models: Mathematical Foundations and Architectures",
    "section": "",
    "text": "The VAE objective maximizes the ELBO:\n\\[\n\\mathcal{L}(\\theta, \\phi; x) = \\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)] - D_{KL}(q_\\phi(z|x)||p(z))\n\\]\nWhere: - \\(q_\\phi(z|x)\\) is the encoder (inference model) - \\(p_\\theta(x|z)\\) is the decoder (generative model) - \\(p(z)\\) is the prior distribution - \\(D_{KL}\\) is the Kullback-Leibler divergence\n\n\n\nEnables backpropagation through sampling:\n\\[\nz = \\mu_\\phi(x) + \\sigma_\\phi(x) \\odot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I)\n\\]\nWhere: - \\(\\mu_\\phi(x)\\) is the mean encoder network - \\(\\sigma_\\phi(x)\\) is the standard deviation encoder network - \\(\\odot\\) denotes element-wise multiplication\n\n\n\n\n\n\nThe original GAN formulation:\n\\[\n\\min_G \\max_D V(D,G) = \\mathbb{E}_{x\\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z\\sim p_z}[\\log(1-D(G(z)))]\n\\]\nWhere: - \\(G\\) is the generator - \\(D\\) is the discriminator - \\(p_{data}\\) is the real data distribution - \\(p_z\\) is the latent distribution\n\n\n\nWGAN objective using Kantorovich-Rubinstein duality:\n\\[\n\\min_G \\max_{D \\in \\mathcal{F}_L} \\mathbb{E}_{x\\sim p_{data}}[D(x)] - \\mathbb{E}_{z\\sim p_z}[D(G(z))]\n\\]\nWhere: - \\(\\mathcal{F}_L\\) is the set of 1-Lipschitz functions\n\n\n\nWGAN-GP regularization term:\n\\[\n\\lambda \\mathbb{E}_{\\hat{x}\\sim p_{\\hat{x}}}[(\\|\\nabla_{\\hat{x}}D(\\hat{x})\\|_2 - 1)^2]\n\\]\nWhere: - \\(\\hat{x}\\) is sampled along straight lines between real and generated samples - \\(\\lambda\\) is the penalty coefficient\n\n\n\n\n\n\nThe forward diffusion process:\n\\[\nq(x_t|x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1-\\beta_t}x_{t-1}, \\beta_tI)\n\\]\nWith closed form for arbitrary timestep:\n\\[\nq(x_t|x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t}x_0, (1-\\bar{\\alpha}_t)I)\n\\]\nWhere: - \\(\\beta_t\\) is the noise schedule - \\(\\alpha_t = 1-\\beta_t\\) - \\(\\bar{\\alpha}_t = \\prod_{s=1}^t \\alpha_s\\)\n\n\n\nThe reverse diffusion process:\n\\[\np_\\theta(x_{t-1}|x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t,t), \\Sigma_\\theta(x_t,t))\n\\]\nTraining objective:\n\\[\n\\mathcal{L} = \\mathbb{E}_{x_0,\\epsilon,t}\\left[\\|\\epsilon - \\epsilon_\\theta(x_t,t)\\|^2\\right]\n\\]\nWhere: - \\(\\epsilon_\\theta\\) predicts the noise component - \\(x_t = \\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\epsilon\\)\n\n\n\n\n\n\nChange of variables formula:\n\\[\n\\log p_X(x) = \\log p_Z(f^{-1}(x)) + \\log\\left|\\det\\frac{\\partial f^{-1}}{\\partial x}\\right|\n\\]\nWhere: - \\(f\\) is an invertible transformation - \\(p_Z\\) is a simple base distribution\n\n\n\nFactorized probability:\n\\[\np(x) = \\prod_{i=1}^n p(x_i|x_{&lt;i})\n\\]\nWith masked convolutions:\n\\[\ny_i = \\sum_{j \\leq i} m_{ij}(w_{ij} \\cdot x_j)\n\\]\n\n\n\nProbability density:\n\\[\np(x) = \\frac{1}{Z}e^{-E(x)}\n\\]\nWhere: - \\(E(x)\\) is the energy function - \\(Z = \\int e^{-E(x)}dx\\) is the partition function\n\n\n\n\n\n\nJensen-Shannon divergence:\n\\[\nJSD(P\\|Q) = \\frac{1}{2}D_{KL}(P\\|\\frac{P+Q}{2}) + \\frac{1}{2}D_{KL}(Q\\|\\frac{P+Q}{2})\n\\]\n\n\n\nKL-divergence analysis:\n\\[\nD_{KL}(q_\\phi(z|x)\\|p(z)) = \\frac{1}{2}\\sum_{j=1}^d(\\sigma_j^2 + \\mu_j^2 - \\log\\sigma_j^2 - 1)\n\\]\n\n\n\nDenoising score matching:\n\\[\n\\nabla_x \\log p(x) = \\mathbb{E}_{p(t|x)}[\\nabla_x \\log p(x|x_t)]\n\\]\n\n\n\n\n\n\nResolution-dependent loss:\n\\[\n\\mathcal{L}_\\text{total} = \\sum_{r} \\alpha_r \\mathcal{L}_r\n\\]\nWhere: - \\(r\\) is the resolution level - \\(\\alpha_r\\) is the weighting factor\n\n\n\nStyle transfer in latent space:\n\\[\nw = \\mathcal{M}(z) = f(z + \\Delta z)\n\\]\nWhere: - \\(\\mathcal{M}\\) is the mapping network - \\(f\\) is a non-linear transformation\n\n\n\nStyle transfer operation:\n\\[\n\\text{AdaIN}(x,y) = \\sigma(y)\\left(\\frac{x-\\mu(x)}{\\sigma(x)}\\right) + \\mu(y)\n\\]\n\n\n\n\n\n\nMeasures quality and diversity:\n\\[\nIS = \\exp(\\mathbb{E}_{x\\sim p_g}[D_{KL}(p(y|x)\\|p(y))])\n\\]\n\n\n\nDistribution similarity metric:\n\\[\nFID = \\|\\mu_r - \\mu_g\\|^2 + Tr(\\Sigma_r + \\Sigma_g - 2(\\Sigma_r\\Sigma_g)^{1/2})\n\\]\nWhere: - \\(\\mu_r, \\Sigma_r\\) are real data statistics - \\(\\mu_g, \\Sigma_g\\) are generated data statistics\n\n\n\nTwo-way evaluation:\n\\[\n\\begin{aligned}\n\\text{Precision} &= \\mathbb{E}_{x\\sim p_g}[\\max_{y\\sim p_r} s(x,y)] \\\\\n\\text{Recall} &= \\mathbb{E}_{y\\sim p_r}[\\max_{x\\sim p_g} s(x,y)]\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nGenerator Design:\n\nTransposed convolutions vs upsampling\nSkip connections\nAttention mechanisms\n\nDiscriminator Design:\n\nSpectral normalization\nResidual blocks\nMulti-scale discrimination\n\nLoss Functions:\n\nAdversarial loss\nReconstruction loss\nPerceptual loss\n\n\n\n\n\n\nGradient Penalties:\n\nR1 regularization\nPath length regularization\nConsistency regularization\n\nLearning Rate:\n\nTwo time-scale update rule\nAdaptive learning rates\nWarmup scheduling\n\nBatch Size:\n\nGradient accumulation\nMixed precision training\nMemory-efficient backprop\n\n\n\n\n\n\n\n\n\nVAEs for:\n\nStructured latent spaces\nReconstruction tasks\nInterpretable representations\n\nGANs for:\n\nHigh-quality generation\nStyle transfer\nDomain translation\n\nDiffusion Models for:\n\nHigh-fidelity generation\nControlled generation\nRobust training\n\n\n\n\n\n\nLearning Rates:\n\nGenerator: 1e-4 to 1e-3\nDiscriminator: 2e-4 to 2e-3\nVAE: 1e-3 to 1e-2\n\nBatch Sizes:\n\nGANs: 32 to 128\nVAEs: 64 to 256\nDiffusion: 32 to 64\n\nArchitecture:\n\nLayer depth\nChannel width\nAttention layers\n\n\n\n\n\n\n\nTheory:\n\n“Auto-Encoding Variational Bayes” by Kingma and Welling\n“Generative Adversarial Networks” by Goodfellow et al.\n“Denoising Diffusion Probabilistic Models” by Ho et al.\n\nArchitecture:\n\n“Progressive Growing of GANs” by Karras et al.\n“StyleGAN” by Karras et al.\n“Normalizing Flows” by Rezende and Mohamed\n\nTraining:\n\n“Improved Training of Wasserstein GANs” by Gulrajani et al.\n“Large Scale GAN Training for High Fidelity Natural Image Synthesis” by Brock et al.\n“Improved VQGAN for Image Generation” by Esser et al."
  },
  {
    "objectID": "posts/generative-models/index.html#variational-autoencoders-vaes",
    "href": "posts/generative-models/index.html#variational-autoencoders-vaes",
    "title": "Generative Models: Mathematical Foundations and Architectures",
    "section": "",
    "text": "The VAE objective maximizes the ELBO:\n\\[\n\\mathcal{L}(\\theta, \\phi; x) = \\mathbb{E}_{q_\\phi(z|x)}[\\log p_\\theta(x|z)] - D_{KL}(q_\\phi(z|x)||p(z))\n\\]\nWhere: - \\(q_\\phi(z|x)\\) is the encoder (inference model) - \\(p_\\theta(x|z)\\) is the decoder (generative model) - \\(p(z)\\) is the prior distribution - \\(D_{KL}\\) is the Kullback-Leibler divergence\n\n\n\nEnables backpropagation through sampling:\n\\[\nz = \\mu_\\phi(x) + \\sigma_\\phi(x) \\odot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I)\n\\]\nWhere: - \\(\\mu_\\phi(x)\\) is the mean encoder network - \\(\\sigma_\\phi(x)\\) is the standard deviation encoder network - \\(\\odot\\) denotes element-wise multiplication"
  },
  {
    "objectID": "posts/generative-models/index.html#generative-adversarial-networks-gans",
    "href": "posts/generative-models/index.html#generative-adversarial-networks-gans",
    "title": "Generative Models: Mathematical Foundations and Architectures",
    "section": "",
    "text": "The original GAN formulation:\n\\[\n\\min_G \\max_D V(D,G) = \\mathbb{E}_{x\\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z\\sim p_z}[\\log(1-D(G(z)))]\n\\]\nWhere: - \\(G\\) is the generator - \\(D\\) is the discriminator - \\(p_{data}\\) is the real data distribution - \\(p_z\\) is the latent distribution\n\n\n\nWGAN objective using Kantorovich-Rubinstein duality:\n\\[\n\\min_G \\max_{D \\in \\mathcal{F}_L} \\mathbb{E}_{x\\sim p_{data}}[D(x)] - \\mathbb{E}_{z\\sim p_z}[D(G(z))]\n\\]\nWhere: - \\(\\mathcal{F}_L\\) is the set of 1-Lipschitz functions\n\n\n\nWGAN-GP regularization term:\n\\[\n\\lambda \\mathbb{E}_{\\hat{x}\\sim p_{\\hat{x}}}[(\\|\\nabla_{\\hat{x}}D(\\hat{x})\\|_2 - 1)^2]\n\\]\nWhere: - \\(\\hat{x}\\) is sampled along straight lines between real and generated samples - \\(\\lambda\\) is the penalty coefficient"
  },
  {
    "objectID": "posts/generative-models/index.html#diffusion-models",
    "href": "posts/generative-models/index.html#diffusion-models",
    "title": "Generative Models: Mathematical Foundations and Architectures",
    "section": "",
    "text": "The forward diffusion process:\n\\[\nq(x_t|x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1-\\beta_t}x_{t-1}, \\beta_tI)\n\\]\nWith closed form for arbitrary timestep:\n\\[\nq(x_t|x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t}x_0, (1-\\bar{\\alpha}_t)I)\n\\]\nWhere: - \\(\\beta_t\\) is the noise schedule - \\(\\alpha_t = 1-\\beta_t\\) - \\(\\bar{\\alpha}_t = \\prod_{s=1}^t \\alpha_s\\)\n\n\n\nThe reverse diffusion process:\n\\[\np_\\theta(x_{t-1}|x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t,t), \\Sigma_\\theta(x_t,t))\n\\]\nTraining objective:\n\\[\n\\mathcal{L} = \\mathbb{E}_{x_0,\\epsilon,t}\\left[\\|\\epsilon - \\epsilon_\\theta(x_t,t)\\|^2\\right]\n\\]\nWhere: - \\(\\epsilon_\\theta\\) predicts the noise component - \\(x_t = \\sqrt{\\bar{\\alpha}_t}x_0 + \\sqrt{1-\\bar{\\alpha}_t}\\epsilon\\)"
  },
  {
    "objectID": "posts/generative-models/index.html#advanced-architectures",
    "href": "posts/generative-models/index.html#advanced-architectures",
    "title": "Generative Models: Mathematical Foundations and Architectures",
    "section": "",
    "text": "Change of variables formula:\n\\[\n\\log p_X(x) = \\log p_Z(f^{-1}(x)) + \\log\\left|\\det\\frac{\\partial f^{-1}}{\\partial x}\\right|\n\\]\nWhere: - \\(f\\) is an invertible transformation - \\(p_Z\\) is a simple base distribution\n\n\n\nFactorized probability:\n\\[\np(x) = \\prod_{i=1}^n p(x_i|x_{&lt;i})\n\\]\nWith masked convolutions:\n\\[\ny_i = \\sum_{j \\leq i} m_{ij}(w_{ij} \\cdot x_j)\n\\]\n\n\n\nProbability density:\n\\[\np(x) = \\frac{1}{Z}e^{-E(x)}\n\\]\nWhere: - \\(E(x)\\) is the energy function - \\(Z = \\int e^{-E(x)}dx\\) is the partition function"
  },
  {
    "objectID": "posts/generative-models/index.html#training-dynamics",
    "href": "posts/generative-models/index.html#training-dynamics",
    "title": "Generative Models: Mathematical Foundations and Architectures",
    "section": "",
    "text": "Jensen-Shannon divergence:\n\\[\nJSD(P\\|Q) = \\frac{1}{2}D_{KL}(P\\|\\frac{P+Q}{2}) + \\frac{1}{2}D_{KL}(Q\\|\\frac{P+Q}{2})\n\\]\n\n\n\nKL-divergence analysis:\n\\[\nD_{KL}(q_\\phi(z|x)\\|p(z)) = \\frac{1}{2}\\sum_{j=1}^d(\\sigma_j^2 + \\mu_j^2 - \\log\\sigma_j^2 - 1)\n\\]\n\n\n\nDenoising score matching:\n\\[\n\\nabla_x \\log p(x) = \\mathbb{E}_{p(t|x)}[\\nabla_x \\log p(x|x_t)]\n\\]"
  },
  {
    "objectID": "posts/generative-models/index.html#advanced-training-techniques",
    "href": "posts/generative-models/index.html#advanced-training-techniques",
    "title": "Generative Models: Mathematical Foundations and Architectures",
    "section": "",
    "text": "Resolution-dependent loss:\n\\[\n\\mathcal{L}_\\text{total} = \\sum_{r} \\alpha_r \\mathcal{L}_r\n\\]\nWhere: - \\(r\\) is the resolution level - \\(\\alpha_r\\) is the weighting factor\n\n\n\nStyle transfer in latent space:\n\\[\nw = \\mathcal{M}(z) = f(z + \\Delta z)\n\\]\nWhere: - \\(\\mathcal{M}\\) is the mapping network - \\(f\\) is a non-linear transformation\n\n\n\nStyle transfer operation:\n\\[\n\\text{AdaIN}(x,y) = \\sigma(y)\\left(\\frac{x-\\mu(x)}{\\sigma(x)}\\right) + \\mu(y)\n\\]"
  },
  {
    "objectID": "posts/generative-models/index.html#evaluation-metrics",
    "href": "posts/generative-models/index.html#evaluation-metrics",
    "title": "Generative Models: Mathematical Foundations and Architectures",
    "section": "",
    "text": "Measures quality and diversity:\n\\[\nIS = \\exp(\\mathbb{E}_{x\\sim p_g}[D_{KL}(p(y|x)\\|p(y))])\n\\]\n\n\n\nDistribution similarity metric:\n\\[\nFID = \\|\\mu_r - \\mu_g\\|^2 + Tr(\\Sigma_r + \\Sigma_g - 2(\\Sigma_r\\Sigma_g)^{1/2})\n\\]\nWhere: - \\(\\mu_r, \\Sigma_r\\) are real data statistics - \\(\\mu_g, \\Sigma_g\\) are generated data statistics\n\n\n\nTwo-way evaluation:\n\\[\n\\begin{aligned}\n\\text{Precision} &= \\mathbb{E}_{x\\sim p_g}[\\max_{y\\sim p_r} s(x,y)] \\\\\n\\text{Recall} &= \\mathbb{E}_{y\\sim p_r}[\\max_{x\\sim p_g} s(x,y)]\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/generative-models/index.html#implementation-considerations",
    "href": "posts/generative-models/index.html#implementation-considerations",
    "title": "Generative Models: Mathematical Foundations and Architectures",
    "section": "",
    "text": "Generator Design:\n\nTransposed convolutions vs upsampling\nSkip connections\nAttention mechanisms\n\nDiscriminator Design:\n\nSpectral normalization\nResidual blocks\nMulti-scale discrimination\n\nLoss Functions:\n\nAdversarial loss\nReconstruction loss\nPerceptual loss\n\n\n\n\n\n\nGradient Penalties:\n\nR1 regularization\nPath length regularization\nConsistency regularization\n\nLearning Rate:\n\nTwo time-scale update rule\nAdaptive learning rates\nWarmup scheduling\n\nBatch Size:\n\nGradient accumulation\nMixed precision training\nMemory-efficient backprop"
  },
  {
    "objectID": "posts/generative-models/index.html#best-practices",
    "href": "posts/generative-models/index.html#best-practices",
    "title": "Generative Models: Mathematical Foundations and Architectures",
    "section": "",
    "text": "VAEs for:\n\nStructured latent spaces\nReconstruction tasks\nInterpretable representations\n\nGANs for:\n\nHigh-quality generation\nStyle transfer\nDomain translation\n\nDiffusion Models for:\n\nHigh-fidelity generation\nControlled generation\nRobust training\n\n\n\n\n\n\nLearning Rates:\n\nGenerator: 1e-4 to 1e-3\nDiscriminator: 2e-4 to 2e-3\nVAE: 1e-3 to 1e-2\n\nBatch Sizes:\n\nGANs: 32 to 128\nVAEs: 64 to 256\nDiffusion: 32 to 64\n\nArchitecture:\n\nLayer depth\nChannel width\nAttention layers"
  },
  {
    "objectID": "posts/generative-models/index.html#references",
    "href": "posts/generative-models/index.html#references",
    "title": "Generative Models: Mathematical Foundations and Architectures",
    "section": "",
    "text": "Theory:\n\n“Auto-Encoding Variational Bayes” by Kingma and Welling\n“Generative Adversarial Networks” by Goodfellow et al.\n“Denoising Diffusion Probabilistic Models” by Ho et al.\n\nArchitecture:\n\n“Progressive Growing of GANs” by Karras et al.\n“StyleGAN” by Karras et al.\n“Normalizing Flows” by Rezende and Mohamed\n\nTraining:\n\n“Improved Training of Wasserstein GANs” by Gulrajani et al.\n“Large Scale GAN Training for High Fidelity Natural Image Synthesis” by Brock et al.\n“Improved VQGAN for Image Generation” by Esser et al."
  },
  {
    "objectID": "posts/machine_learning_concepts.html",
    "href": "posts/machine_learning_concepts.html",
    "title": "Machine Learning Explained: A Beginner’s Guide",
    "section": "",
    "text": "Hey there! 👋 Ever wondered how Netflix knows exactly what show you might like next? Or how your phone can recognize your face? That’s machine learning in action! Today, let’s break down this fascinating technology in simple terms."
  },
  {
    "objectID": "posts/machine_learning_concepts.html#whats-machine-learning-really",
    "href": "posts/machine_learning_concepts.html#whats-machine-learning-really",
    "title": "Machine Learning Explained: A Beginner’s Guide",
    "section": "What’s Machine Learning, Really?",
    "text": "What’s Machine Learning, Really?\nYou know how we humans learn from experience? Like how you learned to ride a bike by practicing, falling down a few times, and getting better with each try? Well, machine learning is kind of like that, but for computers!\nInstead of writing strict rules like “if this happens, do that,” we’re basically teaching computers to learn from examples and get better over time. Cool, right?"
  },
  {
    "objectID": "posts/machine_learning_concepts.html#lets-break-it-down-with-a-simple-example",
    "href": "posts/machine_learning_concepts.html#lets-break-it-down-with-a-simple-example",
    "title": "Machine Learning Explained: A Beginner’s Guide",
    "section": "Let’s Break It Down with a Simple Example",
    "text": "Let’s Break It Down with a Simple Example\nImagine you’re teaching your little sister to identify dogs and cats:\n\nFirst, you show her lots of pictures of dogs and cats\nShe might make mistakes at first (calling a dog a cat)\nBut the more pictures she sees, the better she gets at telling them apart\nEventually, she can identify animals she’s never seen before!\n\nThis is exactly how machine learning works! We show computers lots of examples, and they learn to recognize patterns, just like your sister did."
  },
  {
    "objectID": "posts/machine_learning_concepts.html#the-smart-people-who-explained-it-first",
    "href": "posts/machine_learning_concepts.html#the-smart-people-who-explained-it-first",
    "title": "Machine Learning Explained: A Beginner’s Guide",
    "section": "The Smart People Who Explained It First",
    "text": "The Smart People Who Explained It First\n\nArthur Samuel’s Take (1959)\nHe said: “Machine learning is the field of study that gives computers the ability to learn without being explicitly programmed.”\nIn everyday words: Instead of telling a computer exactly what to do (like we usually do), we let it figure things out on its own by learning from data. Just like how you learned to walk without someone programming your brain with exact instructions for each muscle movement!\n\n\nTom Mitchell’s Version (1997)\nHe got a bit more specific and said: “A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.”\nOkay, that sounds complicated! But let’s break it down with a fun example:\nImagine teaching a computer to play Mario Kart:\n\nTask (T): Playing Mario Kart\nExperience (E): Playing lots of races\nPerformance (P): How often it wins races\n\nThe more races it plays (E), the better it gets at winning (P) the game (T). Simple as that!"
  },
  {
    "objectID": "posts/machine_learning_concepts.html#where-do-we-see-machine-learning-in-real-life",
    "href": "posts/machine_learning_concepts.html#where-do-we-see-machine-learning-in-real-life",
    "title": "Machine Learning Explained: A Beginner’s Guide",
    "section": "Where Do We See Machine Learning in Real Life?",
    "text": "Where Do We See Machine Learning in Real Life?\nIt’s everywhere! Here are some cool examples:\n\n📱 Face ID on your phone\n🎵 Spotify suggesting songs you might like\n📺 Netflix recommending your next binge-worthy show\n🚗 Self-driving cars learning to navigate roads\n📧 Gmail filtering out spam"
  },
  {
    "objectID": "posts/machine_learning_concepts.html#why-should-you-care",
    "href": "posts/machine_learning_concepts.html#why-should-you-care",
    "title": "Machine Learning Explained: A Beginner’s Guide",
    "section": "Why Should You Care?",
    "text": "Why Should You Care?\nMachine learning is changing the world in amazing ways:\n\nMaking our devices smarter and more helpful\nHelping doctors diagnose diseases earlier\nCreating awesome video game experiences\nEven helping fight climate change!"
  },
  {
    "objectID": "posts/machine_learning_concepts.html#wrapping-up",
    "href": "posts/machine_learning_concepts.html#wrapping-up",
    "title": "Machine Learning Explained: A Beginner’s Guide",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nSo there you have it! Machine learning isn’t just some complicated tech jargon - it’s a way to make computers learn from experience, just like we do. And the best part? We’re just getting started with what it can do!\nRemember: Every time you use a filter on Snapchat, ask Siri a question, or get a product recommendation on Amazon, you’re interacting with machine learning. Pretty amazing, right?\nGot questions? Feel free to drop them in the comments below! Learning about machine learning is a journey, and we’re all in it together! 🚀"
  },
  {
    "objectID": "posts/ml-fundamentals/index.html",
    "href": "posts/ml-fundamentals/index.html",
    "title": "ML Fundamentals: Understanding the Basics",
    "section": "",
    "text": "Machine learning (ML) is a transformative field that enables computers to learn from data without being explicitly programmed. Before diving into specific algorithms or frameworks, it’s crucial to understand the fundamental concepts that form the foundation of machine learning.\n\n\nMachine learning is a subset of artificial intelligence that focuses on developing systems that can learn and improve from experience. Instead of following explicit instructions, ML systems identify patterns in data to make decisions or predictions.\n\n\n\nData-Driven: ML systems learn from examples rather than following predefined rules\nPattern Recognition: They identify patterns and relationships in data\nAutomation: They can automatically improve with more experience/data\nGeneralization: They can handle new, unseen data based on learned patterns\n\n\n\n\n\n\n\n\nLearning from labeled data\nExamples: Classification, Regression\nUse cases: Spam detection, Price prediction, Image recognition\n\n\n\n\n\nLearning from unlabeled data\nExamples: Clustering, Dimensionality Reduction\nUse cases: Customer segmentation, Feature learning\n\n\n\n\n\nLearning through interaction with an environment\nExamples: Game playing, Robot navigation\nUse cases: Autonomous systems, Game AI\n\n\n\n\n\nUnderstanding the ML workflow is crucial for successful implementation:\n\nProblem Definition\n\nDefine objectives\nIdentify success metrics\nUnderstand constraints\n\nData Collection\n\nGather relevant data\nEnsure data quality\nConsider data privacy and ethics\n\nData Preprocessing\n\nClean the data\nHandle missing values\nFormat data appropriately\n\nFeature Engineering\n\nSelect relevant features\nCreate new features\nTransform existing features\n\nModel Selection\n\nChoose appropriate algorithms\nConsider model complexity\nBalance bias and variance\n\nModel Training\n\nSplit data into training/validation sets\nTrain the model\nTune hyperparameters\n\nModel Evaluation\n\nAssess performance\nValidate on test data\nConsider business metrics\n\nDeployment\n\nIntegrate with systems\nMonitor performance\nMaintain and update\n\n\n\n\n\n\n\n\nFeatures: Input variables used for prediction\nLabels: Target variables we’re trying to predict\nParameters: Values learned during training\nHyperparameters: Configuration values set before training\n\n\n\n\n\nBias: Model’s tendency to consistently miss the true relationship\nVariance: Model’s sensitivity to fluctuations in the training data\nOverfitting: Model learns noise in training data\nUnderfitting: Model fails to capture underlying patterns\n\n\n\n\n\nAccuracy: Proportion of correct predictions\nPrecision: Accuracy of positive predictions\nRecall: Ability to find all positive instances\nF1 Score: Harmonic mean of precision and recall\n\n\n\n\n\n\nData Quality Issues\n\nMissing values\nNoisy data\nInconsistent formatting\n\nFeature Selection\n\nIdentifying relevant features\nHandling high dimensionality\nCreating meaningful features\n\nModel Selection\n\nChoosing appropriate algorithms\nBalancing complexity and performance\nHandling computational constraints\n\nOverfitting and Underfitting\n\nFinding the right model complexity\nGathering sufficient training data\nUsing appropriate regularization\n\n\n\n\n\n\nStart Simple\n\nBegin with basic models\nEstablish baselines\nGradually increase complexity\n\nCross-Validation\n\nUse multiple data splits\nValidate model stability\nEnsure generalization\n\nFeature Engineering\n\nCreate meaningful features\nRemove irrelevant features\nHandle categorical variables appropriately\n\nModel Evaluation\n\nUse appropriate metrics\nConsider business impact\nTest on unseen data\n\n\n\n\n\nUnderstanding these fundamentals is crucial before diving into specific algorithms or frameworks. In the next posts, we’ll explore:\n\nData Understanding and Preprocessing\nFeature Engineering and Selection\nModel Selection and Evaluation\nAdvanced Topics and Deep Learning\n\nStay tuned for more detailed explorations of each topic!\n\n\n\n\nBooks:\n\n“Introduction to Machine Learning with Python” by Andreas Müller & Sarah Guido\n“The Hundred-Page Machine Learning Book” by Andriy Burkov\n\nOnline Courses:\n\nAndrew Ng’s Machine Learning Course on Coursera\nFast.ai’s Practical Deep Learning Course\n\nWebsites:\n\nScikit-learn Documentation\nTowards Data Science\nMachine Learning Mastery\n\n\nRemember: Building a strong foundation in these fundamentals is crucial for success in machine learning. Take time to understand these concepts thoroughly before moving on to more advanced topics."
  },
  {
    "objectID": "posts/ml-fundamentals/index.html#what-is-machine-learning",
    "href": "posts/ml-fundamentals/index.html#what-is-machine-learning",
    "title": "ML Fundamentals: Understanding the Basics",
    "section": "",
    "text": "Machine learning is a subset of artificial intelligence that focuses on developing systems that can learn and improve from experience. Instead of following explicit instructions, ML systems identify patterns in data to make decisions or predictions.\n\n\n\nData-Driven: ML systems learn from examples rather than following predefined rules\nPattern Recognition: They identify patterns and relationships in data\nAutomation: They can automatically improve with more experience/data\nGeneralization: They can handle new, unseen data based on learned patterns"
  },
  {
    "objectID": "posts/ml-fundamentals/index.html#types-of-machine-learning",
    "href": "posts/ml-fundamentals/index.html#types-of-machine-learning",
    "title": "ML Fundamentals: Understanding the Basics",
    "section": "",
    "text": "Learning from labeled data\nExamples: Classification, Regression\nUse cases: Spam detection, Price prediction, Image recognition\n\n\n\n\n\nLearning from unlabeled data\nExamples: Clustering, Dimensionality Reduction\nUse cases: Customer segmentation, Feature learning\n\n\n\n\n\nLearning through interaction with an environment\nExamples: Game playing, Robot navigation\nUse cases: Autonomous systems, Game AI"
  },
  {
    "objectID": "posts/ml-fundamentals/index.html#the-machine-learning-workflow",
    "href": "posts/ml-fundamentals/index.html#the-machine-learning-workflow",
    "title": "ML Fundamentals: Understanding the Basics",
    "section": "",
    "text": "Understanding the ML workflow is crucial for successful implementation:\n\nProblem Definition\n\nDefine objectives\nIdentify success metrics\nUnderstand constraints\n\nData Collection\n\nGather relevant data\nEnsure data quality\nConsider data privacy and ethics\n\nData Preprocessing\n\nClean the data\nHandle missing values\nFormat data appropriately\n\nFeature Engineering\n\nSelect relevant features\nCreate new features\nTransform existing features\n\nModel Selection\n\nChoose appropriate algorithms\nConsider model complexity\nBalance bias and variance\n\nModel Training\n\nSplit data into training/validation sets\nTrain the model\nTune hyperparameters\n\nModel Evaluation\n\nAssess performance\nValidate on test data\nConsider business metrics\n\nDeployment\n\nIntegrate with systems\nMonitor performance\nMaintain and update"
  },
  {
    "objectID": "posts/ml-fundamentals/index.html#essential-terminology",
    "href": "posts/ml-fundamentals/index.html#essential-terminology",
    "title": "ML Fundamentals: Understanding the Basics",
    "section": "",
    "text": "Features: Input variables used for prediction\nLabels: Target variables we’re trying to predict\nParameters: Values learned during training\nHyperparameters: Configuration values set before training\n\n\n\n\n\nBias: Model’s tendency to consistently miss the true relationship\nVariance: Model’s sensitivity to fluctuations in the training data\nOverfitting: Model learns noise in training data\nUnderfitting: Model fails to capture underlying patterns\n\n\n\n\n\nAccuracy: Proportion of correct predictions\nPrecision: Accuracy of positive predictions\nRecall: Ability to find all positive instances\nF1 Score: Harmonic mean of precision and recall"
  },
  {
    "objectID": "posts/ml-fundamentals/index.html#common-challenges-in-machine-learning",
    "href": "posts/ml-fundamentals/index.html#common-challenges-in-machine-learning",
    "title": "ML Fundamentals: Understanding the Basics",
    "section": "",
    "text": "Data Quality Issues\n\nMissing values\nNoisy data\nInconsistent formatting\n\nFeature Selection\n\nIdentifying relevant features\nHandling high dimensionality\nCreating meaningful features\n\nModel Selection\n\nChoosing appropriate algorithms\nBalancing complexity and performance\nHandling computational constraints\n\nOverfitting and Underfitting\n\nFinding the right model complexity\nGathering sufficient training data\nUsing appropriate regularization"
  },
  {
    "objectID": "posts/ml-fundamentals/index.html#best-practices",
    "href": "posts/ml-fundamentals/index.html#best-practices",
    "title": "ML Fundamentals: Understanding the Basics",
    "section": "",
    "text": "Start Simple\n\nBegin with basic models\nEstablish baselines\nGradually increase complexity\n\nCross-Validation\n\nUse multiple data splits\nValidate model stability\nEnsure generalization\n\nFeature Engineering\n\nCreate meaningful features\nRemove irrelevant features\nHandle categorical variables appropriately\n\nModel Evaluation\n\nUse appropriate metrics\nConsider business impact\nTest on unseen data"
  },
  {
    "objectID": "posts/ml-fundamentals/index.html#next-steps",
    "href": "posts/ml-fundamentals/index.html#next-steps",
    "title": "ML Fundamentals: Understanding the Basics",
    "section": "",
    "text": "Understanding these fundamentals is crucial before diving into specific algorithms or frameworks. In the next posts, we’ll explore:\n\nData Understanding and Preprocessing\nFeature Engineering and Selection\nModel Selection and Evaluation\nAdvanced Topics and Deep Learning\n\nStay tuned for more detailed explorations of each topic!"
  },
  {
    "objectID": "posts/ml-fundamentals/index.html#additional-resources",
    "href": "posts/ml-fundamentals/index.html#additional-resources",
    "title": "ML Fundamentals: Understanding the Basics",
    "section": "",
    "text": "Books:\n\n“Introduction to Machine Learning with Python” by Andreas Müller & Sarah Guido\n“The Hundred-Page Machine Learning Book” by Andriy Burkov\n\nOnline Courses:\n\nAndrew Ng’s Machine Learning Course on Coursera\nFast.ai’s Practical Deep Learning Course\n\nWebsites:\n\nScikit-learn Documentation\nTowards Data Science\nMachine Learning Mastery\n\n\nRemember: Building a strong foundation in these fundamentals is crucial for success in machine learning. Take time to understand these concepts thoroughly before moving on to more advanced topics."
  },
  {
    "objectID": "posts/ml-theory-foundations/index.html",
    "href": "posts/ml-theory-foundations/index.html",
    "title": "Machine Learning Theory: Mathematical Foundations Made Simple",
    "section": "",
    "text": "What You’ll Learn\n\n\n\nThis guide will help you understand: - The mathematical foundations of machine learning\n\nWhy ML algorithms work (or fail)\nHow to choose and evaluate models\nReal-world applications of ML theory"
  },
  {
    "objectID": "posts/ml-theory-foundations/index.html#understanding-learning-theory-through-examples",
    "href": "posts/ml-theory-foundations/index.html#understanding-learning-theory-through-examples",
    "title": "Machine Learning Theory: Mathematical Foundations Made Simple",
    "section": "Understanding Learning Theory Through Examples",
    "text": "Understanding Learning Theory Through Examples\nLet’s start with a simple example that we’ll build upon:\n\nCodeExplanationTheory Connection\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Generate synthetic data\nnp.random.seed(42)\nX = np.linspace(0, 10, 100).reshape(-1, 1)\ny = 0.5 * X.ravel() + np.sin(X.ravel()) + np.random.normal(0, 0.2, 100)\n\n# Fit models of different complexity\nmodels = []\nfor degree in [1, 3, 15]:  # Different polynomial degrees\n    poly = PolynomialFeatures(degree)\n    X_poly = poly.fit_transform(X)\n    model = LinearRegression()\n    model.fit(X_poly, y)\n    models.append((degree, model, poly))\n\n# Plot results\nplt.figure(figsize=(15, 5))\nfor i, (degree, model, poly) in enumerate(models):\n    plt.subplot(1, 3, i+1)\n    plt.scatter(X, y, alpha=0.5, label='Data')\n    X_test = np.linspace(0, 10, 1000).reshape(-1, 1)\n    y_pred = model.predict(poly.transform(X_test))\n    plt.plot(X_test, y_pred, 'r-', label=f'Degree {degree}')\n    plt.title(f'Polynomial Degree {degree}')\n    plt.legend()\nplt.tight_layout()\nplt.show()\n\n\nThis example illustrates: 1. Underfitting (degree 1)\n\nGood fit (degree 3)\nOverfitting (degree 15)\n\n\n\nThis demonstrates the bias-variance tradeoff: - Low degree = high bias\n\nHigh degree = high variance"
  },
  {
    "objectID": "posts/ml-theory-foundations/index.html#statistical-learning-theory",
    "href": "posts/ml-theory-foundations/index.html#statistical-learning-theory",
    "title": "Machine Learning Theory: Mathematical Foundations Made Simple",
    "section": "Statistical Learning Theory",
    "text": "Statistical Learning Theory\n\n1. The Learning Problem\n\n\n\n\n\n\nKey Insight\n\n\n\nMachine learning is about finding patterns in data that generalize to new, unseen examples.\n\n\nThe risk (error) we want to minimize:\n\\[\nR(f) = \\mathbb{E}_{(X,Y)\\sim P}[L(f(X),Y)]\n\\]\nIn simple terms: - \\(R(f)\\) is the expected error - \\(L(f(X),Y)\\) is how wrong our prediction is - \\(P\\) is the true data distribution\ndef calculate_risk(model, X, y):\n    \"\"\"Calculate empirical risk (mean squared error)\"\"\"\n    predictions = model.predict(X)\n    return np.mean((predictions - y) ** 2)\n\n\n2. Empirical Risk Minimization\nWhat we actually minimize (because we don’t know P):\n\\[\n\\hat{R}_n(f) = \\frac{1}{n}\\sum_{i=1}^n L(f(x_i),y_i)\n\\]\n\nCode ExampleVisual Explanation\n\n\nfrom sklearn.model_selection import train_test_split\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Train model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Calculate risks\ntrain_risk = calculate_risk(model, X_train, y_train)\ntest_risk = calculate_risk(model, X_test, y_test)\n\nprint(f\"Training Risk: {train_risk:.4f}\")\nprint(f\"Test Risk: {test_risk:.4f}\")\n\n\ndef plot_risk_curves(degrees, X, y):\n    train_risks = []\n    test_risks = []\n    \n    for degree in degrees:\n        poly = PolynomialFeatures(degree)\n        X_poly = poly.fit_transform(X)\n        X_train, X_test, y_train, y_test = train_test_split(X_poly, y)\n        \n        model = LinearRegression()\n        model.fit(X_train, y_train)\n        \n        train_risks.append(calculate_risk(model, X_train, y_train))\n        test_risks.append(calculate_risk(model, X_test, y_test))\n    \n    plt.figure(figsize=(10, 5))\n    plt.plot(degrees, train_risks, 'b-', label='Training Risk')\n    plt.plot(degrees, test_risks, 'r-', label='Test Risk')\n    plt.xlabel('Model Complexity (Polynomial Degree)')\n    plt.ylabel('Risk (MSE)')\n    plt.legend()\n    plt.title('Training vs Test Risk')\n    plt.show()\n\nplot_risk_curves(range(1, 16), X, y)\n\n\n\n\n\n3. Generalization Bounds\nHoeffding’s inequality gives us confidence bounds:\n\\[\nP(|\\hat{R}_n(f) - R(f)| &gt; \\epsilon) \\leq 2\\exp(-2n\\epsilon^2)\n\\]\n\n\n\n\n\n\nPractical Interpretation\n\n\n\n\nMore data (larger n) = tighter bounds\nHigher confidence = larger epsilon\nHelps determine required dataset size"
  },
  {
    "objectID": "posts/ml-theory-foundations/index.html#model-complexity-and-overfitting",
    "href": "posts/ml-theory-foundations/index.html#model-complexity-and-overfitting",
    "title": "Machine Learning Theory: Mathematical Foundations Made Simple",
    "section": "Model Complexity and Overfitting",
    "text": "Model Complexity and Overfitting\n\n1. VC Dimension\n\nConceptVisualization\n\n\nVC dimension measures model complexity: - Higher VC dimension = more complex model - More complex ≠ better performance - Helps choose model capacity\n\n\ndef plot_vc_bound(n_samples, vc_dim):\n    \"\"\"Plot generalization bound vs sample size\"\"\"\n    epsilons = np.linspace(0.01, 1, 100)\n    bounds = []\n    \n    for eps in epsilons:\n        bound = 2 * (2 * n_samples) ** vc_dim * np.exp(-n_samples * eps**2 / 8)\n        bounds.append(bound)\n    \n    plt.figure(figsize=(10, 5))\n    plt.plot(epsilons, bounds)\n    plt.xlabel('Epsilon')\n    plt.ylabel('Probability of Large Deviation')\n    plt.title(f'VC Generalization Bound (n={n_samples}, VC-dim={vc_dim})')\n    plt.show()\n\nplot_vc_bound(1000, 10)"
  },
  {
    "objectID": "posts/ml-theory-foundations/index.html#optimization-theory",
    "href": "posts/ml-theory-foundations/index.html#optimization-theory",
    "title": "Machine Learning Theory: Mathematical Foundations Made Simple",
    "section": "Optimization Theory",
    "text": "Optimization Theory\n\n1. Gradient Descent Visualization\ndef plot_gradient_descent():\n    \"\"\"Visualize gradient descent optimization\"\"\"\n    x = np.linspace(-5, 5, 100)\n    y = np.linspace(-5, 5, 100)\n    X, Y = np.meshgrid(x, y)\n    Z = X**2 + Y**2  # Simple quadratic function\n    \n    plt.figure(figsize=(10, 8))\n    plt.contour(X, Y, Z, levels=20)\n    \n    # Simulate gradient descent\n    point = np.array([4.0, 4.0])\n    lr = 0.1\n    path = [point]\n    \n    for _ in range(20):\n        gradient = 2 * point\n        point = point - lr * gradient\n        path.append(point)\n    \n    path = np.array(path)\n    plt.plot(path[:, 0], path[:, 1], 'r.-', label='Gradient Descent Path')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title('Gradient Descent Optimization')\n    plt.legend()\n    plt.show()\n\nplot_gradient_descent()\n\n\n2. Convex Optimization\n\n\n\n\n\n\nWhy Convexity Matters\n\n\n\n\nGuarantees global minimum\nFaster convergence\nNo local minima problems"
  },
  {
    "objectID": "posts/ml-theory-foundations/index.html#practical-applications",
    "href": "posts/ml-theory-foundations/index.html#practical-applications",
    "title": "Machine Learning Theory: Mathematical Foundations Made Simple",
    "section": "Practical Applications",
    "text": "Practical Applications\n\n1. Model Selection\nfrom sklearn.model_selection import cross_val_score\n\ndef select_best_model(X, y, max_degree=15):\n    \"\"\"Select best polynomial degree using cross-validation\"\"\"\n    scores = []\n    degrees = range(1, max_degree + 1)\n    \n    for degree in degrees:\n        poly = PolynomialFeatures(degree)\n        X_poly = poly.fit_transform(X)\n        model = LinearRegression()\n        score = np.mean(cross_val_score(model, X_poly, y, cv=5))\n        scores.append(score)\n    \n    plt.figure(figsize=(10, 5))\n    plt.plot(degrees, scores, 'bo-')\n    plt.xlabel('Polynomial Degree')\n    plt.ylabel('Cross-Validation Score')\n    plt.title('Model Selection using Cross-Validation')\n    plt.show()\n    \n    best_degree = degrees[np.argmax(scores)]\n    print(f\"Best polynomial degree: {best_degree}\")\n    return best_degree\n\nbest_degree = select_best_model(X, y)"
  },
  {
    "objectID": "posts/ml-theory-foundations/index.html#common-pitfalls-and-solutions",
    "href": "posts/ml-theory-foundations/index.html#common-pitfalls-and-solutions",
    "title": "Machine Learning Theory: Mathematical Foundations Made Simple",
    "section": "Common Pitfalls and Solutions",
    "text": "Common Pitfalls and Solutions\n\n\n\n\n\n\nWatch Out For\n\n\n\n\nOverfitting\n\nSolution: Regularization, cross-validation\n\nUnderfitting\n\nSolution: Increase model complexity, feature engineering\n\nPoor Generalization\n\nSolution: More training data, simpler models"
  },
  {
    "objectID": "posts/ml-theory-foundations/index.html#further-reading",
    "href": "posts/ml-theory-foundations/index.html#further-reading",
    "title": "Machine Learning Theory: Mathematical Foundations Made Simple",
    "section": "Further Reading",
    "text": "Further Reading\n\nBooksOnline ResourcesInteractive Tools\n\n\n\n“Understanding Machine Learning” by Shai Shalev-Shwartz\n“Statistical Learning Theory” by Vladimir Vapnik\n“Foundations of Machine Learning” by Mehryar Mohri\n\n\n\n\nStanford CS229 Course Notes\n“Mathematics for Machine Learning” (free online book)\nDeep Learning Book (Goodfellow et al.)\n\n\n\n\nGoogle Colab notebooks\nTensorFlow Playground\nML Visualization Tools\n\n\n\n\nRemember: Theory provides the foundation for understanding why ML works, but always combine it with practical implementation for better learning!"
  },
  {
    "objectID": "posts/optimization-algorithms/index.html",
    "href": "posts/optimization-algorithms/index.html",
    "title": "Optimization Algorithms in Machine Learning: A Deep Dive",
    "section": "",
    "text": "The core of optimization in machine learning is minimizing (or maximizing) an objective function:\n\\[\n\\min_{\\theta} J(\\theta) = \\frac{1}{N} \\sum_{i=1}^N L(f_\\theta(x_i), y_i) + \\lambda R(\\theta)\n\\]\nWhere: - \\(J(\\theta)\\) is the objective function\n\n\\(\\theta\\) represents model parameters\n\\(L\\) is the loss function\n\\(f_\\theta\\) is the model prediction\n\\(R(\\theta)\\) is the regularization term\n\\(\\lambda\\) is the regularization strength\n\n\n\n\nThe basic update rule for gradient descent:\n\\[\n\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta J(\\theta_t)\n\\]\nWhere: - \\(\\theta_t\\) is the parameter at iteration t\n\n\\(\\eta\\) is the learning rate\n\\(\\nabla_\\theta J(\\theta_t)\\) is the gradient of the objective function\n\n\n\n\nFor convex functions, gradient descent converges at rate:\n\\[\nJ(\\theta_t) - J(\\theta^*) \\leq \\frac{\\|\\theta_0 - \\theta^*\\|^2}{2\\eta t}\n\\]\nWhere: - \\(\\theta^*\\) is the optimal parameter\n\n\\(\\theta_0\\) is the initial parameter\n\\(t\\) is the number of iterations\n\n\n\n\n\n\n\nUpdate rule:\n\\[\n\\theta_{t+1} = \\theta_t - \\eta_t \\nabla_\\theta L(f_\\theta(x_i), y_i)\n\\]\nConvergence rate for strongly convex functions:\n\\[\n\\mathbb{E}[J(\\theta_t) - J(\\theta^*)] \\leq \\frac{L}{2\\mu t}\n\\]\nWhere: - \\(L\\) is the Lipschitz constant\n\n\\(\\mu\\) is the strong convexity parameter\n\n\n\n\nIncorporates velocity in updates:\n\\[\n\\begin{aligned}\nv_{t+1} &= \\gamma v_t + \\eta \\nabla_\\theta J(\\theta_t) \\\\\n\\theta_{t+1} &= \\theta_t - v_{t+1}\n\\end{aligned}\n\\]\nWhere: - \\(v_t\\) is the velocity at time t\n\n\\(\\gamma\\) is the momentum coefficient\n\n\n\n\nLooks ahead for gradient computation:\n\\[\n\\begin{aligned}\nv_{t+1} &= \\gamma v_t + \\eta \\nabla_\\theta J(\\theta_t + \\gamma v_t) \\\\\n\\theta_{t+1} &= \\theta_t - v_{t+1}\n\\end{aligned}\n\\]\n\n\n\n\n\n\nAdapts learning rates per parameter:\n\\[\n\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} \\odot g_t\n\\]\nWhere: - \\(G_t\\) is the sum of squared gradients up to time t\n\n\\(g_t\\) is the current gradient\n\\(\\odot\\) represents element-wise multiplication\n\n\n\n\nExponentially decaying average of squared gradients:\n\\[\n\\begin{aligned}\nG_t &= \\gamma G_{t-1} + (1-\\gamma)g_t^2 \\\\\n\\theta_{t+1} &= \\theta_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} \\odot g_t\n\\end{aligned}\n\\]\n\n\n\nCombines momentum and adaptive learning rates:\n\\[\n\\begin{aligned}\nm_t &= \\beta_1 m_{t-1} + (1-\\beta_1)g_t \\\\\nv_t &= \\beta_2 v_{t-1} + (1-\\beta_2)g_t^2 \\\\\n\\hat{m}_t &= \\frac{m_t}{1-\\beta_1^t} \\\\\n\\hat{v}_t &= \\frac{v_t}{1-\\beta_2^t} \\\\\n\\theta_{t+1} &= \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\odot \\hat{m}_t\n\\end{aligned}\n\\]\n\n\n\n\n\n\nUpdate rule using Hessian:\n\\[\n\\theta_{t+1} = \\theta_t - \\eta H^{-1}\\nabla_\\theta J(\\theta_t)\n\\]\nWhere: - \\(H\\) is the Hessian matrix of second derivatives\n\n\n\nApproximates Hessian inverse:\n\\[\n\\begin{aligned}\ns_k &= \\theta_{k+1} - \\theta_k \\\\\ny_k &= \\nabla J(\\theta_{k+1}) - \\nabla J(\\theta_k) \\\\\nB_{k+1} &= B_k + \\frac{y_ky_k^T}{y_k^Ts_k} - \\frac{B_ks_ks_k^TB_k}{s_k^TB_ks_k}\n\\end{aligned}\n\\]\n\n\n\n\n\n\nCommon schedules include:\n\nStep decay: \\[\n\\eta_t = \\eta_0 \\gamma^{\\lfloor t/k \\rfloor}\n\\]\nExponential decay: \\[\n\\eta_t = \\eta_0 e^{-kt}\n\\]\nCosine annealing: \\[\n\\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})(1 + \\cos(\\frac{t\\pi}{T}))\n\\]\n\n\n\n\nThe relationship between batch size and learning rate:\n\\[\n\\eta_{effective} = \\eta \\sqrt{\\frac{b}{b_{base}}}\n\\]\nWhere: - \\(b\\) is the current batch size\n\n\\(b_{base}\\) is the reference batch size\n\n\n\n\nFor handling exploding gradients:\n\\[\ng_t = \\begin{cases}\ng_t & \\text{if } \\|g_t\\| \\leq c \\\\\nc\\frac{g_t}{\\|g_t\\|} & \\text{otherwise}\n\\end{cases}\n\\]\n\n\n\n\n\n\nUpdate rule using Fisher Information Matrix:\n\\[\n\\theta_{t+1} = \\theta_t - \\eta F^{-1}\\nabla_\\theta J(\\theta_t)\n\\]\nWhere: - \\(F\\) is the Fisher Information Matrix\n\n\n\nFor parallel SGD with K workers:\n\\[\n\\theta_{t+1} = \\theta_t - \\frac{\\eta}{K}\\sum_{k=1}^K \\nabla_\\theta J_k(\\theta_t)\n\\]\n\n\n\nAveraging weights along the trajectory:\n\\[\n\\theta_{SWA} = \\frac{1}{n}\\sum_{i=1}^n \\theta_i\n\\]\n\n\n\n\n\n\n\nFirst try Adam with default parameters:\n\nLearning rate: \\(10^{-3}\\)\n\\(\\beta_1 = 0.9\\)\n\\(\\beta_2 = 0.999\\)\n\\(\\epsilon = 10^{-8}\\)\n\nIf training is unstable, try:\n\nReducing learning rate\nGradient clipping\nLayer normalization\n\nFor fine-tuning, consider:\n\nSGD with momentum\nCosine annealing\nSWA\n\n\n\n\n\n\nLearning rate search:\n\nStart with logarithmic grid\nUse learning rate finder algorithm\n\nBatch size selection:\n\nStart with power of 2\nConsider memory constraints\nScale learning rate accordingly\n\nMomentum tuning:\n\nDefault: 0.9\nIncrease for noisy gradients\nDecrease for stable training\n\n\n\n\n\n\n\n\nSolutions: 1. Proper initialization: \\[\nW \\sim \\mathcal{N}(0, \\sqrt{\\frac{2}{n_{in} + n_{out}}})\n\\]\n\nGradient clipping\nLayer normalization: \\[\n\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}\n\\]\n\n\n\n\nSolutions: 1. Add noise to gradients: \\[\ng_t = \\nabla_\\theta J(\\theta_t) + \\mathcal{N}(0, \\sigma^2)\n\\]\n\nUse momentum-based methods\nImplement trust region methods\n\n\n\n\nSolutions: 1. Preconditioning: \\[\n\\theta_{t+1} = \\theta_t - \\eta P^{-1}\\nabla_\\theta J(\\theta_t)\n\\]\n\nAdaptive methods (Adam, RMSprop)\nSecond-order methods when feasible\n\n\n\n\n\nKey takeaways: 1. Understanding optimization fundamentals is crucial 2. Different algorithms suit different problems 3. Practical considerations often outweigh theoretical guarantees 4. Monitoring and debugging optimization is essential\n\n\n\n\nMathematical Foundations:\n\n“Convex Optimization” by Boyd and Vandenberghe\n“Optimization Methods for Large-Scale Machine Learning” by Bottou et al.\n\nImplementation Details:\n\n“Deep Learning” by Goodfellow et al.\n“Adaptive Methods for Machine Learning” by Duchi et al.\n\nAdvanced Topics:\n\n“Natural Gradient Works Efficiently in Learning” by Amari\n“On the Convergence of Adam and Beyond” by Reddi et al."
  },
  {
    "objectID": "posts/optimization-algorithms/index.html#mathematical-foundations",
    "href": "posts/optimization-algorithms/index.html#mathematical-foundations",
    "title": "Optimization Algorithms in Machine Learning: A Deep Dive",
    "section": "",
    "text": "The core of optimization in machine learning is minimizing (or maximizing) an objective function:\n\\[\n\\min_{\\theta} J(\\theta) = \\frac{1}{N} \\sum_{i=1}^N L(f_\\theta(x_i), y_i) + \\lambda R(\\theta)\n\\]\nWhere: - \\(J(\\theta)\\) is the objective function\n\n\\(\\theta\\) represents model parameters\n\\(L\\) is the loss function\n\\(f_\\theta\\) is the model prediction\n\\(R(\\theta)\\) is the regularization term\n\\(\\lambda\\) is the regularization strength\n\n\n\n\nThe basic update rule for gradient descent:\n\\[\n\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta J(\\theta_t)\n\\]\nWhere: - \\(\\theta_t\\) is the parameter at iteration t\n\n\\(\\eta\\) is the learning rate\n\\(\\nabla_\\theta J(\\theta_t)\\) is the gradient of the objective function\n\n\n\n\nFor convex functions, gradient descent converges at rate:\n\\[\nJ(\\theta_t) - J(\\theta^*) \\leq \\frac{\\|\\theta_0 - \\theta^*\\|^2}{2\\eta t}\n\\]\nWhere: - \\(\\theta^*\\) is the optimal parameter\n\n\\(\\theta_0\\) is the initial parameter\n\\(t\\) is the number of iterations"
  },
  {
    "objectID": "posts/optimization-algorithms/index.html#first-order-methods",
    "href": "posts/optimization-algorithms/index.html#first-order-methods",
    "title": "Optimization Algorithms in Machine Learning: A Deep Dive",
    "section": "",
    "text": "Update rule:\n\\[\n\\theta_{t+1} = \\theta_t - \\eta_t \\nabla_\\theta L(f_\\theta(x_i), y_i)\n\\]\nConvergence rate for strongly convex functions:\n\\[\n\\mathbb{E}[J(\\theta_t) - J(\\theta^*)] \\leq \\frac{L}{2\\mu t}\n\\]\nWhere: - \\(L\\) is the Lipschitz constant\n\n\\(\\mu\\) is the strong convexity parameter\n\n\n\n\nIncorporates velocity in updates:\n\\[\n\\begin{aligned}\nv_{t+1} &= \\gamma v_t + \\eta \\nabla_\\theta J(\\theta_t) \\\\\n\\theta_{t+1} &= \\theta_t - v_{t+1}\n\\end{aligned}\n\\]\nWhere: - \\(v_t\\) is the velocity at time t\n\n\\(\\gamma\\) is the momentum coefficient\n\n\n\n\nLooks ahead for gradient computation:\n\\[\n\\begin{aligned}\nv_{t+1} &= \\gamma v_t + \\eta \\nabla_\\theta J(\\theta_t + \\gamma v_t) \\\\\n\\theta_{t+1} &= \\theta_t - v_{t+1}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/optimization-algorithms/index.html#adaptive-methods",
    "href": "posts/optimization-algorithms/index.html#adaptive-methods",
    "title": "Optimization Algorithms in Machine Learning: A Deep Dive",
    "section": "",
    "text": "Adapts learning rates per parameter:\n\\[\n\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} \\odot g_t\n\\]\nWhere: - \\(G_t\\) is the sum of squared gradients up to time t\n\n\\(g_t\\) is the current gradient\n\\(\\odot\\) represents element-wise multiplication\n\n\n\n\nExponentially decaying average of squared gradients:\n\\[\n\\begin{aligned}\nG_t &= \\gamma G_{t-1} + (1-\\gamma)g_t^2 \\\\\n\\theta_{t+1} &= \\theta_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} \\odot g_t\n\\end{aligned}\n\\]\n\n\n\nCombines momentum and adaptive learning rates:\n\\[\n\\begin{aligned}\nm_t &= \\beta_1 m_{t-1} + (1-\\beta_1)g_t \\\\\nv_t &= \\beta_2 v_{t-1} + (1-\\beta_2)g_t^2 \\\\\n\\hat{m}_t &= \\frac{m_t}{1-\\beta_1^t} \\\\\n\\hat{v}_t &= \\frac{v_t}{1-\\beta_2^t} \\\\\n\\theta_{t+1} &= \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\odot \\hat{m}_t\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/optimization-algorithms/index.html#second-order-methods",
    "href": "posts/optimization-algorithms/index.html#second-order-methods",
    "title": "Optimization Algorithms in Machine Learning: A Deep Dive",
    "section": "",
    "text": "Update rule using Hessian:\n\\[\n\\theta_{t+1} = \\theta_t - \\eta H^{-1}\\nabla_\\theta J(\\theta_t)\n\\]\nWhere: - \\(H\\) is the Hessian matrix of second derivatives\n\n\n\nApproximates Hessian inverse:\n\\[\n\\begin{aligned}\ns_k &= \\theta_{k+1} - \\theta_k \\\\\ny_k &= \\nabla J(\\theta_{k+1}) - \\nabla J(\\theta_k) \\\\\nB_{k+1} &= B_k + \\frac{y_ky_k^T}{y_k^Ts_k} - \\frac{B_ks_ks_k^TB_k}{s_k^TB_ks_k}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "posts/optimization-algorithms/index.html#implementation-considerations",
    "href": "posts/optimization-algorithms/index.html#implementation-considerations",
    "title": "Optimization Algorithms in Machine Learning: A Deep Dive",
    "section": "",
    "text": "Common schedules include:\n\nStep decay: \\[\n\\eta_t = \\eta_0 \\gamma^{\\lfloor t/k \\rfloor}\n\\]\nExponential decay: \\[\n\\eta_t = \\eta_0 e^{-kt}\n\\]\nCosine annealing: \\[\n\\eta_t = \\eta_{min} + \\frac{1}{2}(\\eta_{max} - \\eta_{min})(1 + \\cos(\\frac{t\\pi}{T}))\n\\]\n\n\n\n\nThe relationship between batch size and learning rate:\n\\[\n\\eta_{effective} = \\eta \\sqrt{\\frac{b}{b_{base}}}\n\\]\nWhere: - \\(b\\) is the current batch size\n\n\\(b_{base}\\) is the reference batch size\n\n\n\n\nFor handling exploding gradients:\n\\[\ng_t = \\begin{cases}\ng_t & \\text{if } \\|g_t\\| \\leq c \\\\\nc\\frac{g_t}{\\|g_t\\|} & \\text{otherwise}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "posts/optimization-algorithms/index.html#advanced-topics",
    "href": "posts/optimization-algorithms/index.html#advanced-topics",
    "title": "Optimization Algorithms in Machine Learning: A Deep Dive",
    "section": "",
    "text": "Update rule using Fisher Information Matrix:\n\\[\n\\theta_{t+1} = \\theta_t - \\eta F^{-1}\\nabla_\\theta J(\\theta_t)\n\\]\nWhere: - \\(F\\) is the Fisher Information Matrix\n\n\n\nFor parallel SGD with K workers:\n\\[\n\\theta_{t+1} = \\theta_t - \\frac{\\eta}{K}\\sum_{k=1}^K \\nabla_\\theta J_k(\\theta_t)\n\\]\n\n\n\nAveraging weights along the trajectory:\n\\[\n\\theta_{SWA} = \\frac{1}{n}\\sum_{i=1}^n \\theta_i\n\\]"
  },
  {
    "objectID": "posts/optimization-algorithms/index.html#practical-guidelines",
    "href": "posts/optimization-algorithms/index.html#practical-guidelines",
    "title": "Optimization Algorithms in Machine Learning: A Deep Dive",
    "section": "",
    "text": "First try Adam with default parameters:\n\nLearning rate: \\(10^{-3}\\)\n\\(\\beta_1 = 0.9\\)\n\\(\\beta_2 = 0.999\\)\n\\(\\epsilon = 10^{-8}\\)\n\nIf training is unstable, try:\n\nReducing learning rate\nGradient clipping\nLayer normalization\n\nFor fine-tuning, consider:\n\nSGD with momentum\nCosine annealing\nSWA\n\n\n\n\n\n\nLearning rate search:\n\nStart with logarithmic grid\nUse learning rate finder algorithm\n\nBatch size selection:\n\nStart with power of 2\nConsider memory constraints\nScale learning rate accordingly\n\nMomentum tuning:\n\nDefault: 0.9\nIncrease for noisy gradients\nDecrease for stable training"
  },
  {
    "objectID": "posts/optimization-algorithms/index.html#common-issues-and-solutions",
    "href": "posts/optimization-algorithms/index.html#common-issues-and-solutions",
    "title": "Optimization Algorithms in Machine Learning: A Deep Dive",
    "section": "",
    "text": "Solutions: 1. Proper initialization: \\[\nW \\sim \\mathcal{N}(0, \\sqrt{\\frac{2}{n_{in} + n_{out}}})\n\\]\n\nGradient clipping\nLayer normalization: \\[\n\\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}\n\\]\n\n\n\n\nSolutions: 1. Add noise to gradients: \\[\ng_t = \\nabla_\\theta J(\\theta_t) + \\mathcal{N}(0, \\sigma^2)\n\\]\n\nUse momentum-based methods\nImplement trust region methods\n\n\n\n\nSolutions: 1. Preconditioning: \\[\n\\theta_{t+1} = \\theta_t - \\eta P^{-1}\\nabla_\\theta J(\\theta_t)\n\\]\n\nAdaptive methods (Adam, RMSprop)\nSecond-order methods when feasible"
  },
  {
    "objectID": "posts/optimization-algorithms/index.html#conclusion",
    "href": "posts/optimization-algorithms/index.html#conclusion",
    "title": "Optimization Algorithms in Machine Learning: A Deep Dive",
    "section": "",
    "text": "Key takeaways: 1. Understanding optimization fundamentals is crucial 2. Different algorithms suit different problems 3. Practical considerations often outweigh theoretical guarantees 4. Monitoring and debugging optimization is essential"
  },
  {
    "objectID": "posts/optimization-algorithms/index.html#references",
    "href": "posts/optimization-algorithms/index.html#references",
    "title": "Optimization Algorithms in Machine Learning: A Deep Dive",
    "section": "",
    "text": "Mathematical Foundations:\n\n“Convex Optimization” by Boyd and Vandenberghe\n“Optimization Methods for Large-Scale Machine Learning” by Bottou et al.\n\nImplementation Details:\n\n“Deep Learning” by Goodfellow et al.\n“Adaptive Methods for Machine Learning” by Duchi et al.\n\nAdvanced Topics:\n\n“Natural Gradient Works Efficiently in Learning” by Amari\n“On the Convergence of Adam and Beyond” by Reddi et al."
  },
  {
    "objectID": "posts/probabilistic-graphical-models/index.html",
    "href": "posts/probabilistic-graphical-models/index.html",
    "title": "Probabilistic Graphical Models: Mathematical Foundations",
    "section": "",
    "text": "Joint probability factorization:\n\\[\nP(X_1, ..., X_n) = \\prod_{i=1}^n P(X_i | \\text{Pa}(X_i))\n\\]\nWhere: - \\(X_i\\) are random variables - \\(\\text{Pa}(X_i)\\) are parents of \\(X_i\\) in the graph\n\n\n\nD-separation criterion: - Two nodes are d-separated if all paths between them are blocked - A path is blocked if: * Contains a collider not in evidence * Contains a non-collider in evidence\nFormal definition:\n\\[\nX \\perp\\!\\!\\!\\perp Y | Z \\iff P(X|Y,Z) = P(X|Z)\n\\]\n\n\n\n\n\n\nJoint distribution representation:\n\\[\nP(X = x) = \\frac{1}{Z}\\exp\\left(-\\sum_{c \\in \\mathcal{C}} \\psi_c(x_c)\\right)\n\\]\nWhere: - \\(\\mathcal{C}\\) is the set of cliques - \\(\\psi_c\\) are potential functions - \\(Z\\) is the partition function:\n\\[\nZ = \\sum_x \\exp\\left(-\\sum_{c \\in \\mathcal{C}} \\psi_c(x_c)\\right)\n\\]\n\n\n\nEquivalence between positive distributions and Gibbs distributions:\n\\[\nP(X = x) &gt; 0 \\iff P(X = x) = \\frac{1}{Z}\\prod_{c \\in \\mathcal{C}} \\phi_c(x_c)\n\\]\nWhere: - \\(\\phi_c\\) are non-negative factors\n\n\n\n\n\n\nComplexity for tree-structured graphs:\n\\[\nO(n \\cdot d^{w})\n\\]\nWhere: - \\(n\\) is number of variables - \\(d\\) is domain size - \\(w\\) is tree width\nAlgorithm steps: 1. Choose elimination ordering 2. For each variable: - Multiply relevant factors - Sum out variable\n\n\n\nMessage passing equations:\n\\[\n\\begin{aligned}\n\\mu_{i \\to j}(x_j) &= \\sum_{x_i} \\phi_i(x_i)\\phi_{ij}(x_i,x_j)\\prod_{k \\in N(i)\\backslash j} \\mu_{k \\to i}(x_i) \\\\\nb_i(x_i) &\\propto \\phi_i(x_i)\\prod_{j \\in N(i)} \\mu_{j \\to i}(x_i)\n\\end{aligned}\n\\]\nWhere: - \\(\\mu_{i \\to j}\\) is message from i to j - \\(b_i\\) is belief at node i - \\(N(i)\\) is neighbors of i\n\n\n\nClique tree construction: 1. Moralize graph 2. Triangulate 3. Find maximal cliques 4. Build junction tree\nRunning intersection property:\n\\[\nS_{ij} = C_i \\cap C_j \\subseteq C_k\n\\]\nFor any cliques \\(C_i\\), \\(C_j\\), and clique \\(C_k\\) on path between them.\n\n\n\n\n\n\nObjective function:\n\\[\n\\hat{\\theta}_{MLE} = \\arg\\max_\\theta \\sum_{i=1}^N \\log P(x^{(i)}|\\theta)\n\\]\nFor complete data in Bayesian networks:\n\\[\n\\hat{\\theta}_{ijk} = \\frac{N_{ijk}}{\\sum_k N_{ijk}}\n\\]\nWhere: - \\(N_{ijk}\\) is count of \\(X_i=k\\) with parent configuration j\n\n\n\nPosterior distribution:\n\\[\nP(\\theta|D) \\propto P(D|\\theta)P(\\theta)\n\\]\nWith Dirichlet prior:\n\\[\n\\theta_{ijk} \\sim \\text{Dir}(\\alpha_{ijk})\n\\]\nPosterior parameters:\n\\[\n\\alpha_{ijk}^{\\text{post}} = \\alpha_{ijk} + N_{ijk}\n\\]\n\n\n\nScore-based learning objective:\n\\[\nG^* = \\arg\\max_G \\text{score}(G:D)\n\\]\nCommon scores: 1. BIC score:\n\\[\n\\text{BIC}(G:D) = \\ell(D|\\hat{\\theta}, G) - \\frac{\\log N}{2}|G|\n\\]\n\nBayesian score:\n\n\\[\nP(G|D) \\propto P(D|G)P(G)\n\\]\n\n\n\n\n\n\nEvidence lower bound (ELBO):\n\\[\n\\mathcal{L}(q) = \\mathbb{E}_q[\\log p(x,z)] - \\mathbb{E}_q[\\log q(z)]\n\\]\nMean field approximation:\n\\[\nq(z) = \\prod_i q_i(z_i)\n\\]\nUpdate equations:\n\\[\n\\log q_j^*(z_j) = \\mathbb{E}_{q_{-j}}[\\log p(x,z)] + \\text{const}\n\\]\n\n\n\nMetropolis-Hastings acceptance ratio:\n\\[\n\\alpha = \\min\\left(1, \\frac{p(x')q(x|x')}{p(x)q(x'|x)}\\right)\n\\]\nGibbs sampling update:\n\\[\nx_i^{(t+1)} \\sim p(x_i|x_{-i}^{(t)})\n\\]\n\n\n\nLinear-chain CRF probability:\n\\[\nP(y|x) = \\frac{1}{Z(x)}\\exp\\left(\\sum_{t=1}^T\\sum_k \\lambda_k f_k(y_t,y_{t-1},x_t)\\right)\n\\]\nWhere: - \\(f_k\\) are feature functions - \\(\\lambda_k\\) are weights - \\(Z(x)\\) is normalization factor\n\n\n\n\n\n\nLog-space computations:\n\\[\n\\log\\sum_i \\exp(x_i) = \\max_i x_i + \\log\\sum_i \\exp(x_i - \\max_i x_i)\n\\]\n\n\n\nEfficient factor operations: - Sparse matrices for CPTs - Vectorized operations - Caching intermediate results\n\n\n\nParallel message passing: - Tree-structured graphs - Junction tree clusters - Mini-batch learning\n\n\n\n\n\n\n\nNetwork Structure:\n\nExpert knowledge\nCausal relationships\nData-driven learning\n\nInference Method:\n\nExact vs approximate\nGraph structure\nDomain size\n\nLearning Approach:\n\nData completeness\nPrior knowledge\nComputational resources\n\n\n\n\n\n\nVariable Ordering:\n\nMin-fill heuristic\nMin-degree ordering\nWeighted variants\n\nMessage Scheduling:\n\nResidual belief propagation\nPriority-based updates\nAsynchronous methods\n\nMemory Management:\n\nFactor caching\nMessage memoization\nSparse representations\n\n\n\n\n\n\n\n\nNetwork structure: - Diseases as root nodes - Symptoms as leaf nodes - Test results as intermediate nodes\nInference tasks: - Diagnostic reasoning - Predictive reasoning - Intercausal reasoning\n\n\n\nMRF applications: - Image segmentation - Stereo matching - Image restoration\nEnergy function:\n\\[\nE(x) = \\sum_i \\phi_i(x_i) + \\sum_{i,j} \\phi_{ij}(x_i,x_j)\n\\]\n\n\n\nLinear-chain CRFs: - Part-of-speech tagging - Named entity recognition - Sequence labeling\nFeature templates: - Word features - Context windows - Transition features\n\n\n\n\n\nTheory:\n\n“Probabilistic Graphical Models” by Koller and Friedman\n“Pattern Recognition and Machine Learning” by Bishop\n“Information Theory, Inference, and Learning Algorithms” by MacKay\n\nAlgorithms:\n\n“Understanding Belief Propagation and its Generalizations” by Yedidia et al.\n“An Introduction to MCMC for Machine Learning” by Andrieu et al.\n“Structured Prediction for Natural Language Processing” by Smith\n\nApplications:\n\n“Medical Applications of Artificial Intelligence” by Dua and Acharya\n“Computer Vision: A Modern Approach” by Forsyth and Ponce\n“Speech and Language Processing” by Jurafsky and Martin"
  },
  {
    "objectID": "posts/probabilistic-graphical-models/index.html#bayesian-networks",
    "href": "posts/probabilistic-graphical-models/index.html#bayesian-networks",
    "title": "Probabilistic Graphical Models: Mathematical Foundations",
    "section": "",
    "text": "Joint probability factorization:\n\\[\nP(X_1, ..., X_n) = \\prod_{i=1}^n P(X_i | \\text{Pa}(X_i))\n\\]\nWhere: - \\(X_i\\) are random variables - \\(\\text{Pa}(X_i)\\) are parents of \\(X_i\\) in the graph\n\n\n\nD-separation criterion: - Two nodes are d-separated if all paths between them are blocked - A path is blocked if: * Contains a collider not in evidence * Contains a non-collider in evidence\nFormal definition:\n\\[\nX \\perp\\!\\!\\!\\perp Y | Z \\iff P(X|Y,Z) = P(X|Z)\n\\]"
  },
  {
    "objectID": "posts/probabilistic-graphical-models/index.html#markov-random-fields",
    "href": "posts/probabilistic-graphical-models/index.html#markov-random-fields",
    "title": "Probabilistic Graphical Models: Mathematical Foundations",
    "section": "",
    "text": "Joint distribution representation:\n\\[\nP(X = x) = \\frac{1}{Z}\\exp\\left(-\\sum_{c \\in \\mathcal{C}} \\psi_c(x_c)\\right)\n\\]\nWhere: - \\(\\mathcal{C}\\) is the set of cliques - \\(\\psi_c\\) are potential functions - \\(Z\\) is the partition function:\n\\[\nZ = \\sum_x \\exp\\left(-\\sum_{c \\in \\mathcal{C}} \\psi_c(x_c)\\right)\n\\]\n\n\n\nEquivalence between positive distributions and Gibbs distributions:\n\\[\nP(X = x) &gt; 0 \\iff P(X = x) = \\frac{1}{Z}\\prod_{c \\in \\mathcal{C}} \\phi_c(x_c)\n\\]\nWhere: - \\(\\phi_c\\) are non-negative factors"
  },
  {
    "objectID": "posts/probabilistic-graphical-models/index.html#inference-algorithms",
    "href": "posts/probabilistic-graphical-models/index.html#inference-algorithms",
    "title": "Probabilistic Graphical Models: Mathematical Foundations",
    "section": "",
    "text": "Complexity for tree-structured graphs:\n\\[\nO(n \\cdot d^{w})\n\\]\nWhere: - \\(n\\) is number of variables - \\(d\\) is domain size - \\(w\\) is tree width\nAlgorithm steps: 1. Choose elimination ordering 2. For each variable: - Multiply relevant factors - Sum out variable\n\n\n\nMessage passing equations:\n\\[\n\\begin{aligned}\n\\mu_{i \\to j}(x_j) &= \\sum_{x_i} \\phi_i(x_i)\\phi_{ij}(x_i,x_j)\\prod_{k \\in N(i)\\backslash j} \\mu_{k \\to i}(x_i) \\\\\nb_i(x_i) &\\propto \\phi_i(x_i)\\prod_{j \\in N(i)} \\mu_{j \\to i}(x_i)\n\\end{aligned}\n\\]\nWhere: - \\(\\mu_{i \\to j}\\) is message from i to j - \\(b_i\\) is belief at node i - \\(N(i)\\) is neighbors of i\n\n\n\nClique tree construction: 1. Moralize graph 2. Triangulate 3. Find maximal cliques 4. Build junction tree\nRunning intersection property:\n\\[\nS_{ij} = C_i \\cap C_j \\subseteq C_k\n\\]\nFor any cliques \\(C_i\\), \\(C_j\\), and clique \\(C_k\\) on path between them."
  },
  {
    "objectID": "posts/probabilistic-graphical-models/index.html#learning-methods",
    "href": "posts/probabilistic-graphical-models/index.html#learning-methods",
    "title": "Probabilistic Graphical Models: Mathematical Foundations",
    "section": "",
    "text": "Objective function:\n\\[\n\\hat{\\theta}_{MLE} = \\arg\\max_\\theta \\sum_{i=1}^N \\log P(x^{(i)}|\\theta)\n\\]\nFor complete data in Bayesian networks:\n\\[\n\\hat{\\theta}_{ijk} = \\frac{N_{ijk}}{\\sum_k N_{ijk}}\n\\]\nWhere: - \\(N_{ijk}\\) is count of \\(X_i=k\\) with parent configuration j\n\n\n\nPosterior distribution:\n\\[\nP(\\theta|D) \\propto P(D|\\theta)P(\\theta)\n\\]\nWith Dirichlet prior:\n\\[\n\\theta_{ijk} \\sim \\text{Dir}(\\alpha_{ijk})\n\\]\nPosterior parameters:\n\\[\n\\alpha_{ijk}^{\\text{post}} = \\alpha_{ijk} + N_{ijk}\n\\]\n\n\n\nScore-based learning objective:\n\\[\nG^* = \\arg\\max_G \\text{score}(G:D)\n\\]\nCommon scores: 1. BIC score:\n\\[\n\\text{BIC}(G:D) = \\ell(D|\\hat{\\theta}, G) - \\frac{\\log N}{2}|G|\n\\]\n\nBayesian score:\n\n\\[\nP(G|D) \\propto P(D|G)P(G)\n\\]"
  },
  {
    "objectID": "posts/probabilistic-graphical-models/index.html#advanced-topics",
    "href": "posts/probabilistic-graphical-models/index.html#advanced-topics",
    "title": "Probabilistic Graphical Models: Mathematical Foundations",
    "section": "",
    "text": "Evidence lower bound (ELBO):\n\\[\n\\mathcal{L}(q) = \\mathbb{E}_q[\\log p(x,z)] - \\mathbb{E}_q[\\log q(z)]\n\\]\nMean field approximation:\n\\[\nq(z) = \\prod_i q_i(z_i)\n\\]\nUpdate equations:\n\\[\n\\log q_j^*(z_j) = \\mathbb{E}_{q_{-j}}[\\log p(x,z)] + \\text{const}\n\\]\n\n\n\nMetropolis-Hastings acceptance ratio:\n\\[\n\\alpha = \\min\\left(1, \\frac{p(x')q(x|x')}{p(x)q(x'|x)}\\right)\n\\]\nGibbs sampling update:\n\\[\nx_i^{(t+1)} \\sim p(x_i|x_{-i}^{(t)})\n\\]\n\n\n\nLinear-chain CRF probability:\n\\[\nP(y|x) = \\frac{1}{Z(x)}\\exp\\left(\\sum_{t=1}^T\\sum_k \\lambda_k f_k(y_t,y_{t-1},x_t)\\right)\n\\]\nWhere: - \\(f_k\\) are feature functions - \\(\\lambda_k\\) are weights - \\(Z(x)\\) is normalization factor"
  },
  {
    "objectID": "posts/probabilistic-graphical-models/index.html#implementation-considerations",
    "href": "posts/probabilistic-graphical-models/index.html#implementation-considerations",
    "title": "Probabilistic Graphical Models: Mathematical Foundations",
    "section": "",
    "text": "Log-space computations:\n\\[\n\\log\\sum_i \\exp(x_i) = \\max_i x_i + \\log\\sum_i \\exp(x_i - \\max_i x_i)\n\\]\n\n\n\nEfficient factor operations: - Sparse matrices for CPTs - Vectorized operations - Caching intermediate results\n\n\n\nParallel message passing: - Tree-structured graphs - Junction tree clusters - Mini-batch learning"
  },
  {
    "objectID": "posts/probabilistic-graphical-models/index.html#best-practices",
    "href": "posts/probabilistic-graphical-models/index.html#best-practices",
    "title": "Probabilistic Graphical Models: Mathematical Foundations",
    "section": "",
    "text": "Network Structure:\n\nExpert knowledge\nCausal relationships\nData-driven learning\n\nInference Method:\n\nExact vs approximate\nGraph structure\nDomain size\n\nLearning Approach:\n\nData completeness\nPrior knowledge\nComputational resources\n\n\n\n\n\n\nVariable Ordering:\n\nMin-fill heuristic\nMin-degree ordering\nWeighted variants\n\nMessage Scheduling:\n\nResidual belief propagation\nPriority-based updates\nAsynchronous methods\n\nMemory Management:\n\nFactor caching\nMessage memoization\nSparse representations"
  },
  {
    "objectID": "posts/probabilistic-graphical-models/index.html#applications",
    "href": "posts/probabilistic-graphical-models/index.html#applications",
    "title": "Probabilistic Graphical Models: Mathematical Foundations",
    "section": "",
    "text": "Network structure: - Diseases as root nodes - Symptoms as leaf nodes - Test results as intermediate nodes\nInference tasks: - Diagnostic reasoning - Predictive reasoning - Intercausal reasoning\n\n\n\nMRF applications: - Image segmentation - Stereo matching - Image restoration\nEnergy function:\n\\[\nE(x) = \\sum_i \\phi_i(x_i) + \\sum_{i,j} \\phi_{ij}(x_i,x_j)\n\\]\n\n\n\nLinear-chain CRFs: - Part-of-speech tagging - Named entity recognition - Sequence labeling\nFeature templates: - Word features - Context windows - Transition features"
  },
  {
    "objectID": "posts/probabilistic-graphical-models/index.html#references",
    "href": "posts/probabilistic-graphical-models/index.html#references",
    "title": "Probabilistic Graphical Models: Mathematical Foundations",
    "section": "",
    "text": "Theory:\n\n“Probabilistic Graphical Models” by Koller and Friedman\n“Pattern Recognition and Machine Learning” by Bishop\n“Information Theory, Inference, and Learning Algorithms” by MacKay\n\nAlgorithms:\n\n“Understanding Belief Propagation and its Generalizations” by Yedidia et al.\n“An Introduction to MCMC for Machine Learning” by Andrieu et al.\n“Structured Prediction for Natural Language Processing” by Smith\n\nApplications:\n\n“Medical Applications of Artificial Intelligence” by Dua and Acharya\n“Computer Vision: A Modern Approach” by Forsyth and Ponce\n“Speech and Language Processing” by Jurafsky and Martin"
  },
  {
    "objectID": "posts/statistical-learning-theory/index.html",
    "href": "posts/statistical-learning-theory/index.html",
    "title": "Statistical Learning Theory and Concentration Inequalities",
    "section": "",
    "text": "Basic form:\n\\[\nP(X \\geq a) \\leq \\frac{\\mathbb{E}[X]}{a}\n\\]\nFor non-negative random variables.\nMoment version:\n\\[\nP(|X| \\geq a) \\leq \\frac{\\mathbb{E}[|X|^r]}{a^r}\n\\]\n\n\n\nBasic form:\n\\[\nP(|X - \\mu| \\geq t) \\leq \\frac{\\sigma^2}{t^2}\n\\]\nMoment version:\n\\[\nP(|X - \\mathbb{E}[X]| \\geq t) \\leq \\frac{\\text{Var}(X)}{t^2}\n\\]\n\n\n\nSum of bounded variables:\n\\[\nP(\\frac{1}{n}\\sum_{i=1}^n X_i - \\mathbb{E}[X] \\geq t) \\leq \\exp(-\\frac{2nt^2}{(b-a)^2})\n\\]\nMartingale version:\n\\[\nP(S_n - S_0 \\geq t) \\leq \\exp(-\\frac{2t^2}{\\sum_{i=1}^n (b_i-a_i)^2})\n\\]\n\n\n\n\n\n\nVariance-based bound:\n\\[\nP(\\frac{1}{n}\\sum_{i=1}^n (X_i - \\mathbb{E}[X_i]) \\geq t) \\leq \\exp(-\\frac{nt^2}{2\\sigma^2 + 2Mt/3})\n\\]\nWhere: - \\(|X_i| \\leq M\\) - \\(\\text{Var}(X_i) \\leq \\sigma^2\\)\n\n\n\nBounded differences:\n\\[\nP(f(X_1,...,X_n) - \\mathbb{E}[f] \\geq t) \\leq \\exp(-\\frac{2t^2}{\\sum_{i=1}^n c_i^2})\n\\]\nWhere: - \\(|f(x) - f(x')| \\leq c_i\\) when \\(x,x'\\) differ in i-th coordinate\n\n\n\nConvex distance:\n\\[\nP(|Z - M(Z)| \\geq t) \\leq 4\\exp(-\\frac{t^2}{4\\sigma^2})\n\\]\nWhere: - \\(Z\\) is supremum of empirical process - \\(M(Z)\\) is median\n\n\n\n\n\n\nFundamental theorem:\n\\[\nP(\\sup_{h \\in \\mathcal{H}}|\\hat{R}_n(h) - R(h)| &gt; \\epsilon) \\leq 8\\mathcal{N}(\\epsilon/8)\\exp(-n\\epsilon^2/128)\n\\]\nWhere: - \\(\\mathcal{N}(\\epsilon)\\) is covering number - \\(R(h)\\) is true risk - \\(\\hat{R}_n(h)\\) is empirical risk\n\n\n\nBasic inequality:\n\\[\nP(\\sup_{h \\in \\mathcal{H}}|R(h) - \\hat{R}_n(h)| &gt; 2\\epsilon) \\leq 2P(\\sup_{h \\in \\mathcal{H}}|\\hat{R}_n(h) - \\hat{R}'_n(h)| &gt; \\epsilon)\n\\]\nGhost sample technique:\n\\[\n\\mathbb{E}[\\sup_{h \\in \\mathcal{H}}|R(h) - \\hat{R}_n(h)|] \\leq 2\\mathbb{E}[\\sup_{h \\in \\mathcal{H}}|\\frac{1}{n}\\sum_{i=1}^n \\sigma_i h(X_i)|]\n\\]\n\n\n\nDefinition:\n\\[\n\\mathfrak{R}_n(\\mathcal{H}) = \\mathbb{E}_{\\sigma,S}[\\sup_{h \\in \\mathcal{H}}\\frac{1}{n}\\sum_{i=1}^n \\sigma_i h(x_i)]\n\\]\nGeneralization bound:\n\\[\nP(\\sup_{h \\in \\mathcal{H}}|R(h) - \\hat{R}_n(h)| \\leq 2\\mathfrak{R}_n(\\mathcal{H}) + \\sqrt{\\frac{\\ln(2/\\delta)}{2n}}) \\geq 1-\\delta\n\\]\n\n\n\n\n\n\nDefinition:\n\\[\n\\mathfrak{R}_n(\\mathcal{H}, r) = \\mathbb{E}_{\\sigma}[\\sup_{h \\in \\mathcal{H}: P(h-h^*)^2 \\leq r}\\frac{1}{n}\\sum_{i=1}^n \\sigma_i h(X_i)]\n\\]\nFixed point:\n\\[\nr^* = \\inf\\{r &gt; 0: \\mathfrak{R}_n(\\mathcal{H}, r) \\leq r/4\\}\n\\]\n\n\n\nBound:\n\\[\nP(\\sup_{h \\in B(h^*,r)}|R(h) - \\hat{R}_n(h)| &gt; \\epsilon) \\leq \\mathcal{N}(r,\\epsilon/4)\\exp(-n\\epsilon^2/8)\n\\]\nWhere: - \\(B(h^*,r)\\) is ball around optimal hypothesis\n\n\n\nGeometric slicing:\n\\[\nP(\\exists h: |R(h) - \\hat{R}_n(h)| &gt; \\epsilon\\sqrt{R(h)}) \\leq \\sum_{j=0}^\\infty P(\\sup_{h: R(h) \\in [2^j\\alpha,2^{j+1}\\alpha]}|R(h) - \\hat{R}_n(h)| &gt; \\epsilon\\sqrt{2^j\\alpha})\n\\]\n\n\n\n\n\n\nAlgorithmic stability:\n\\[\n|\\ell(A_S,z) - \\ell(A_{S^i},z)| \\leq \\beta\n\\]\nGeneralization bound:\n\\[\nP(|R(A_S) - \\hat{R}_n(A_S)| &gt; \\epsilon) \\leq 2\\exp(-\\frac{n\\epsilon^2}{2\\beta^2})\n\\]\n\n\n\nSample compression:\n\\[\nm \\geq k\\log\\frac{em}{k} + \\log\\frac{1}{\\delta}\n\\]\nWhere: - \\(k\\) is size of compression set - \\(m\\) is sample size\n\n\n\nKL-divergence bound:\n\\[\nR(Q) \\leq \\hat{R}_n(Q) + \\sqrt{\\frac{KL(Q\\|P) + \\ln\\frac{2\\sqrt{n}}{\\delta}}{2n}}\n\\]\n\n\n\n\n\n\nSparse recovery:\n\\[\n\\|\\hat{\\beta} - \\beta^*\\|_2 \\leq \\sqrt{\\frac{s\\log p}{n}}\n\\]\nWhere: - \\(s\\) is sparsity - \\(p\\) is dimension\n\n\n\nMatrix Bernstein:\n\\[\nP(\\|\\sum_{i=1}^n X_i\\| \\geq t) \\leq 2d\\exp(-\\frac{t^2/2}{\\sigma^2 + Mt/3})\n\\]\nWhere: - \\(\\|X_i\\| \\leq M\\) - \\(\\|\\mathbb{E}[X_iX_i^T]\\| \\leq \\sigma^2\\)\n\n\n\nMaximal inequality:\n\\[\n\\mathbb{E}[\\sup_{f \\in \\mathcal{F}}|\\sum_{i=1}^n \\epsilon_i f(X_i)|] \\leq K\\sqrt{n}\\int_0^\\infty \\sqrt{\\log N(\\epsilon,\\mathcal{F},L_2)}d\\epsilon\n\\]\n\n\n\n\n\n\n\nFixed Confidence:\n\nError tolerance\nConfidence level\nComplexity measure\n\nFixed Width:\n\nPrecision requirement\nCoverage probability\nDimension impact\n\nSequential:\n\nStopping rules\nError control\nEfficiency\n\n\n\n\n\n\nProblem Structure:\n\nIndependence\nBoundedness\nMoment conditions\n\nSample Properties:\n\nSize\nDistribution\nDependence\n\nComputational:\n\nTightness\nSimplicity\nTractability\n\n\n\n\n\n\n\n\n\nProblem Formulation:\n\nIdentify assumptions\nChoose metrics\nSet objectives\n\nBound Selection:\n\nMatch assumptions\nConsider tightness\nBalance complexity\n\nImplementation:\n\nNumerical stability\nComputational efficiency\nError handling\n\n\n\n\n\n\nSample Size:\n\nConservative estimates\nSafety margins\nPower analysis\n\nValidation:\n\nCross-validation\nBootstrap\nPermutation tests\n\nMonitoring:\n\nConvergence checks\nStability measures\nError tracking\n\n\n\n\n\n\n\nTheory:\n\n“Concentration Inequalities” by Boucheron et al.\n“Statistical Learning Theory” by Vapnik\n“High-Dimensional Probability” by Vershynin\n\nMethods:\n\n“Empirical Processes in M-Estimation” by van der Vaart and Wellner\n“Random Matrices: High Dimensional Phenomena” by Davidson and Szarek\n“Theory of Classification” by Devroye et al.\n\nApplications:\n\n“Statistical Learning Theory and Applications” by Bousquet et al.\n“High-Dimensional Statistics” by Wainwright\n“Machine Learning Theory” by Mohri et al."
  },
  {
    "objectID": "posts/statistical-learning-theory/index.html#concentration-inequalities",
    "href": "posts/statistical-learning-theory/index.html#concentration-inequalities",
    "title": "Statistical Learning Theory and Concentration Inequalities",
    "section": "",
    "text": "Basic form:\n\\[\nP(X \\geq a) \\leq \\frac{\\mathbb{E}[X]}{a}\n\\]\nFor non-negative random variables.\nMoment version:\n\\[\nP(|X| \\geq a) \\leq \\frac{\\mathbb{E}[|X|^r]}{a^r}\n\\]\n\n\n\nBasic form:\n\\[\nP(|X - \\mu| \\geq t) \\leq \\frac{\\sigma^2}{t^2}\n\\]\nMoment version:\n\\[\nP(|X - \\mathbb{E}[X]| \\geq t) \\leq \\frac{\\text{Var}(X)}{t^2}\n\\]\n\n\n\nSum of bounded variables:\n\\[\nP(\\frac{1}{n}\\sum_{i=1}^n X_i - \\mathbb{E}[X] \\geq t) \\leq \\exp(-\\frac{2nt^2}{(b-a)^2})\n\\]\nMartingale version:\n\\[\nP(S_n - S_0 \\geq t) \\leq \\exp(-\\frac{2t^2}{\\sum_{i=1}^n (b_i-a_i)^2})\n\\]"
  },
  {
    "objectID": "posts/statistical-learning-theory/index.html#advanced-concentration-results",
    "href": "posts/statistical-learning-theory/index.html#advanced-concentration-results",
    "title": "Statistical Learning Theory and Concentration Inequalities",
    "section": "",
    "text": "Variance-based bound:\n\\[\nP(\\frac{1}{n}\\sum_{i=1}^n (X_i - \\mathbb{E}[X_i]) \\geq t) \\leq \\exp(-\\frac{nt^2}{2\\sigma^2 + 2Mt/3})\n\\]\nWhere: - \\(|X_i| \\leq M\\) - \\(\\text{Var}(X_i) \\leq \\sigma^2\\)\n\n\n\nBounded differences:\n\\[\nP(f(X_1,...,X_n) - \\mathbb{E}[f] \\geq t) \\leq \\exp(-\\frac{2t^2}{\\sum_{i=1}^n c_i^2})\n\\]\nWhere: - \\(|f(x) - f(x')| \\leq c_i\\) when \\(x,x'\\) differ in i-th coordinate\n\n\n\nConvex distance:\n\\[\nP(|Z - M(Z)| \\geq t) \\leq 4\\exp(-\\frac{t^2}{4\\sigma^2})\n\\]\nWhere: - \\(Z\\) is supremum of empirical process - \\(M(Z)\\) is median"
  },
  {
    "objectID": "posts/statistical-learning-theory/index.html#statistical-learning-bounds",
    "href": "posts/statistical-learning-theory/index.html#statistical-learning-bounds",
    "title": "Statistical Learning Theory and Concentration Inequalities",
    "section": "",
    "text": "Fundamental theorem:\n\\[\nP(\\sup_{h \\in \\mathcal{H}}|\\hat{R}_n(h) - R(h)| &gt; \\epsilon) \\leq 8\\mathcal{N}(\\epsilon/8)\\exp(-n\\epsilon^2/128)\n\\]\nWhere: - \\(\\mathcal{N}(\\epsilon)\\) is covering number - \\(R(h)\\) is true risk - \\(\\hat{R}_n(h)\\) is empirical risk\n\n\n\nBasic inequality:\n\\[\nP(\\sup_{h \\in \\mathcal{H}}|R(h) - \\hat{R}_n(h)| &gt; 2\\epsilon) \\leq 2P(\\sup_{h \\in \\mathcal{H}}|\\hat{R}_n(h) - \\hat{R}'_n(h)| &gt; \\epsilon)\n\\]\nGhost sample technique:\n\\[\n\\mathbb{E}[\\sup_{h \\in \\mathcal{H}}|R(h) - \\hat{R}_n(h)|] \\leq 2\\mathbb{E}[\\sup_{h \\in \\mathcal{H}}|\\frac{1}{n}\\sum_{i=1}^n \\sigma_i h(X_i)|]\n\\]\n\n\n\nDefinition:\n\\[\n\\mathfrak{R}_n(\\mathcal{H}) = \\mathbb{E}_{\\sigma,S}[\\sup_{h \\in \\mathcal{H}}\\frac{1}{n}\\sum_{i=1}^n \\sigma_i h(x_i)]\n\\]\nGeneralization bound:\n\\[\nP(\\sup_{h \\in \\mathcal{H}}|R(h) - \\hat{R}_n(h)| \\leq 2\\mathfrak{R}_n(\\mathcal{H}) + \\sqrt{\\frac{\\ln(2/\\delta)}{2n}}) \\geq 1-\\delta\n\\]"
  },
  {
    "objectID": "posts/statistical-learning-theory/index.html#local-analysis",
    "href": "posts/statistical-learning-theory/index.html#local-analysis",
    "title": "Statistical Learning Theory and Concentration Inequalities",
    "section": "",
    "text": "Definition:\n\\[\n\\mathfrak{R}_n(\\mathcal{H}, r) = \\mathbb{E}_{\\sigma}[\\sup_{h \\in \\mathcal{H}: P(h-h^*)^2 \\leq r}\\frac{1}{n}\\sum_{i=1}^n \\sigma_i h(X_i)]\n\\]\nFixed point:\n\\[\nr^* = \\inf\\{r &gt; 0: \\mathfrak{R}_n(\\mathcal{H}, r) \\leq r/4\\}\n\\]\n\n\n\nBound:\n\\[\nP(\\sup_{h \\in B(h^*,r)}|R(h) - \\hat{R}_n(h)| &gt; \\epsilon) \\leq \\mathcal{N}(r,\\epsilon/4)\\exp(-n\\epsilon^2/8)\n\\]\nWhere: - \\(B(h^*,r)\\) is ball around optimal hypothesis\n\n\n\nGeometric slicing:\n\\[\nP(\\exists h: |R(h) - \\hat{R}_n(h)| &gt; \\epsilon\\sqrt{R(h)}) \\leq \\sum_{j=0}^\\infty P(\\sup_{h: R(h) \\in [2^j\\alpha,2^{j+1}\\alpha]}|R(h) - \\hat{R}_n(h)| &gt; \\epsilon\\sqrt{2^j\\alpha})\n\\]"
  },
  {
    "objectID": "posts/statistical-learning-theory/index.html#advanced-theory",
    "href": "posts/statistical-learning-theory/index.html#advanced-theory",
    "title": "Statistical Learning Theory and Concentration Inequalities",
    "section": "",
    "text": "Algorithmic stability:\n\\[\n|\\ell(A_S,z) - \\ell(A_{S^i},z)| \\leq \\beta\n\\]\nGeneralization bound:\n\\[\nP(|R(A_S) - \\hat{R}_n(A_S)| &gt; \\epsilon) \\leq 2\\exp(-\\frac{n\\epsilon^2}{2\\beta^2})\n\\]\n\n\n\nSample compression:\n\\[\nm \\geq k\\log\\frac{em}{k} + \\log\\frac{1}{\\delta}\n\\]\nWhere: - \\(k\\) is size of compression set - \\(m\\) is sample size\n\n\n\nKL-divergence bound:\n\\[\nR(Q) \\leq \\hat{R}_n(Q) + \\sqrt{\\frac{KL(Q\\|P) + \\ln\\frac{2\\sqrt{n}}{\\delta}}{2n}}\n\\]"
  },
  {
    "objectID": "posts/statistical-learning-theory/index.html#applications",
    "href": "posts/statistical-learning-theory/index.html#applications",
    "title": "Statistical Learning Theory and Concentration Inequalities",
    "section": "",
    "text": "Sparse recovery:\n\\[\n\\|\\hat{\\beta} - \\beta^*\\|_2 \\leq \\sqrt{\\frac{s\\log p}{n}}\n\\]\nWhere: - \\(s\\) is sparsity - \\(p\\) is dimension\n\n\n\nMatrix Bernstein:\n\\[\nP(\\|\\sum_{i=1}^n X_i\\| \\geq t) \\leq 2d\\exp(-\\frac{t^2/2}{\\sigma^2 + Mt/3})\n\\]\nWhere: - \\(\\|X_i\\| \\leq M\\) - \\(\\|\\mathbb{E}[X_iX_i^T]\\| \\leq \\sigma^2\\)\n\n\n\nMaximal inequality:\n\\[\n\\mathbb{E}[\\sup_{f \\in \\mathcal{F}}|\\sum_{i=1}^n \\epsilon_i f(X_i)|] \\leq K\\sqrt{n}\\int_0^\\infty \\sqrt{\\log N(\\epsilon,\\mathcal{F},L_2)}d\\epsilon\n\\]"
  },
  {
    "objectID": "posts/statistical-learning-theory/index.html#implementation-considerations",
    "href": "posts/statistical-learning-theory/index.html#implementation-considerations",
    "title": "Statistical Learning Theory and Concentration Inequalities",
    "section": "",
    "text": "Fixed Confidence:\n\nError tolerance\nConfidence level\nComplexity measure\n\nFixed Width:\n\nPrecision requirement\nCoverage probability\nDimension impact\n\nSequential:\n\nStopping rules\nError control\nEfficiency\n\n\n\n\n\n\nProblem Structure:\n\nIndependence\nBoundedness\nMoment conditions\n\nSample Properties:\n\nSize\nDistribution\nDependence\n\nComputational:\n\nTightness\nSimplicity\nTractability"
  },
  {
    "objectID": "posts/statistical-learning-theory/index.html#best-practices",
    "href": "posts/statistical-learning-theory/index.html#best-practices",
    "title": "Statistical Learning Theory and Concentration Inequalities",
    "section": "",
    "text": "Problem Formulation:\n\nIdentify assumptions\nChoose metrics\nSet objectives\n\nBound Selection:\n\nMatch assumptions\nConsider tightness\nBalance complexity\n\nImplementation:\n\nNumerical stability\nComputational efficiency\nError handling\n\n\n\n\n\n\nSample Size:\n\nConservative estimates\nSafety margins\nPower analysis\n\nValidation:\n\nCross-validation\nBootstrap\nPermutation tests\n\nMonitoring:\n\nConvergence checks\nStability measures\nError tracking"
  },
  {
    "objectID": "posts/statistical-learning-theory/index.html#references",
    "href": "posts/statistical-learning-theory/index.html#references",
    "title": "Statistical Learning Theory and Concentration Inequalities",
    "section": "",
    "text": "Theory:\n\n“Concentration Inequalities” by Boucheron et al.\n“Statistical Learning Theory” by Vapnik\n“High-Dimensional Probability” by Vershynin\n\nMethods:\n\n“Empirical Processes in M-Estimation” by van der Vaart and Wellner\n“Random Matrices: High Dimensional Phenomena” by Davidson and Szarek\n“Theory of Classification” by Devroye et al.\n\nApplications:\n\n“Statistical Learning Theory and Applications” by Bousquet et al.\n“High-Dimensional Statistics” by Wainwright\n“Machine Learning Theory” by Mohri et al."
  },
  {
    "objectID": "posts/computational-learning-theory/index.html",
    "href": "posts/computational-learning-theory/index.html",
    "title": "Computational Learning Theory",
    "section": "",
    "text": "PAC learning bound:\n\\[\nm \\geq \\frac{1}{\\epsilon}\\left(\\ln|\\mathcal{H}| + \\ln\\frac{1}{\\delta}\\right)\n\\]\nVC dimension bound:\n\\[\nm = O\\left(\\frac{d}{\\epsilon^2}\\ln\\frac{1}{\\epsilon} + \\frac{1}{\\epsilon^2}\\ln\\frac{1}{\\delta}\\right)\n\\]\n\n\n\nLearning algorithm runtime:\n\\[\nT(m,n,\\epsilon,\\delta) = \\text{poly}(m,n,\\frac{1}{\\epsilon},\\frac{1}{\\delta})\n\\]\nWhere: - \\(m\\) is sample size - \\(n\\) is input dimension - \\(\\epsilon\\) is accuracy - \\(\\delta\\) is confidence\n\n\n\nMemory requirements:\n\\[\nS(m,n) = O(mn)\n\\]\nStreaming bound:\n\\[\nS = O(\\log m + \\log n)\n\\]\n\n\n\n\n\n\nDefinition: - Polynomial sample complexity - Polynomial time complexity - Polynomial space complexity\nRequirements:\n\\[\n\\begin{aligned}\nm &= \\text{poly}(n,\\frac{1}{\\epsilon},\\frac{1}{\\delta}) \\\\\nT &= \\text{poly}(n,\\frac{1}{\\epsilon},\\frac{1}{\\delta}) \\\\\nS &= \\text{poly}(n,\\frac{1}{\\epsilon},\\frac{1}{\\delta})\n\\end{aligned}\n\\]\n\n\n\nCryptographic assumptions:\n\\[\nP \\neq NP \\implies \\text{Not efficiently learnable}\n\\]\nReduction techniques:\n\\[\n\\text{Problem A} \\leq_p \\text{Problem B}\n\\]\n\n\n\nExpected runtime:\n\\[\n\\mathbb{E}[T(X)] = \\sum_{x} T(x)P(x)\n\\]\nSmoothed analysis:\n\\[\n\\max_{\\text{input } I} \\mathbb{E}_{\\text{noise } \\xi}[T(I + \\xi)]\n\\]\n\n\n\n\n\n\nMembership queries:\n\\[\n\\text{MQ}(x) = c(x)\n\\]\nEquivalence queries:\n\\[\n\\text{EQ}(h) = \\begin{cases}\n\\text{Yes} & \\text{if } h \\equiv c \\\\\nx & \\text{where } h(x) \\neq c(x)\n\\end{cases}\n\\]\n\n\n\nMistake bound:\n\\[\nM \\leq \\text{poly}(n,\\text{size}(c))\n\\]\nHalving algorithm:\n\\[\n|\\mathcal{H}_t| \\leq |\\mathcal{H}_0|/2^t\n\\]\n\n\n\nLabel complexity:\n\\[\n\\Lambda(\\epsilon,\\delta) = O(\\theta d\\log(1/\\epsilon)\\log(1/\\delta))\n\\]\nWhere: - \\(\\theta\\) is disagreement coefficient - \\(d\\) is VC dimension\n\n\n\n\n\n\nAdaBoost iterations:\n\\[\nT = O\\left(\\frac{\\log(1/\\epsilon)}{\\gamma^2}\\right)\n\\]\nWhere: - \\(\\gamma\\) is edge over random\n\n\n\nKernel evaluation:\n\\[\nT = O(m^2n)\n\\]\nNyström approximation:\n\\[\n\\|K - \\tilde{K}\\|_2 \\leq \\epsilon\n\\]\n\n\n\nBackpropagation complexity:\n\\[\nT = O(mnd)\n\\]\nWhere: - \\(d\\) is network depth\n\n\n\n\n\n\nMemory-runtime relationship:\n\\[\nT \\cdot S = \\Omega(n^2)\n\\]\nStreaming algorithms:\n\\[\nS \\cdot \\text{passes} = \\Omega(n)\n\\]\n\n\n\nActive learning:\n\\[\n\\text{queries} \\cdot \\text{computation} = O(m\\log m)\n\\]\nParallel speedup:\n\\[\nT_p = \\frac{T_1}{p} + O(\\log p)\n\\]\n\n\n\nApproximation guarantee:\n\\[\nf(x) \\leq (1+\\epsilon)\\text{OPT}\n\\]\nRuntime dependency:\n\\[\nT = O(\\text{poly}(n,1/\\epsilon))\n\\]\n\n\n\n\n\n\nTwo-party protocol:\n\\[\nCC(f) = \\min_P \\max_{x,y} \\text{bits}(P(x,y))\n\\]\nLower bound:\n\\[\nCC(f) \\geq \\log_2 \\text{rank}(M_f)\n\\]\n\n\n\nBoolean circuit size:\n\\[\n\\text{size}(f) = \\min_{C: C \\text{ computes } f} \\text{gates}(C)\n\\]\nDepth bound:\n\\[\n\\text{depth}(f) \\geq \\log_2 \\text{sensitivity}(f)\n\\]\n\n\n\nInformation cost:\n\\[\nIC(P) = I(X;M|Y) + I(Y;M|X)\n\\]\nProtocol compression:\n\\[\n|P'| \\leq O(IC(P)\\log|P|)\n\\]\n\n\n\n\n\n\n\nResource Constraints:\n\nTime efficiency\nMemory usage\nCommunication cost\n\nScalability:\n\nInput size\nDimensionality\nSample complexity\n\nParallelization:\n\nTask decomposition\nCommunication overhead\nLoad balancing\n\n\n\n\n\n\nArchitecture:\n\nProcessing units\nMemory hierarchy\nNetwork topology\n\nOptimization:\n\nCaching strategies\nData structures\nAlgorithm selection\n\nTrade-offs:\n\nAccuracy vs speed\nMemory vs computation\nCommunication vs local processing\n\n\n\n\n\n\n\n\nLWE assumption:\n\\[\n(A,As+e) \\approx_c (A,u)\n\\]\nWhere: - \\(A\\) is random matrix - \\(s\\) is secret - \\(e\\) is error - \\(u\\) is uniform\n\n\n\nQuery complexity:\n\\[\n\\text{SQ-DIM}(\\mathcal{C}) = \\min_{D} \\max_{f \\in \\mathcal{C}} |\\langle f,D \\rangle|\n\\]\n\n\n\nQuery complexity:\n\\[\nQ(\\epsilon) = O(\\frac{1}{\\epsilon}\\log\\frac{1}{\\epsilon})\n\\]\nDistance measure:\n\\[\n\\text{dist}(f,g) = \\text{Pr}_{x}[f(x) \\neq g(x)]\n\\]\n\n\n\n\n\n\n\nComplexity Measures:\n\nAsymptotic bounds\nAverage case\nWorst case\n\nResource Usage:\n\nMemory footprint\nCPU utilization\nI/O operations\n\nScalability:\n\nData size\nDimensionality\nParallelization\n\n\n\n\n\n\nOptimization:\n\nAlgorithm choice\nData structures\nMemory management\n\nTrade-offs:\n\nTime vs space\nAccuracy vs speed\nCommunication vs computation\n\nEvaluation:\n\nBenchmarking\nProfiling\nPerformance analysis\n\n\n\n\n\n\n\nTheory:\n\n“Foundations of Machine Learning” by Mohri et al.\n“Understanding Machine Learning” by Shalev-Shwartz and Ben-David\n“Computational Learning Theory” by Kearns and Vazirani\n\nComplexity:\n\n“Computational Complexity” by Arora and Barak\n“Communication Complexity” by Kushilevitz and Nisan\n“The Nature of Computation” by Moore and Mertens\n\nApplications:\n\n“Algorithmic Learning Theory” by Anthony and Biggs\n“Learning with Kernels” by Schölkopf and Smola\n“Theoretical Computer Science” by Hopcroft and Ullman"
  },
  {
    "objectID": "posts/computational-learning-theory/index.html#complexity-measures",
    "href": "posts/computational-learning-theory/index.html#complexity-measures",
    "title": "Computational Learning Theory",
    "section": "",
    "text": "PAC learning bound:\n\\[\nm \\geq \\frac{1}{\\epsilon}\\left(\\ln|\\mathcal{H}| + \\ln\\frac{1}{\\delta}\\right)\n\\]\nVC dimension bound:\n\\[\nm = O\\left(\\frac{d}{\\epsilon^2}\\ln\\frac{1}{\\epsilon} + \\frac{1}{\\epsilon^2}\\ln\\frac{1}{\\delta}\\right)\n\\]\n\n\n\nLearning algorithm runtime:\n\\[\nT(m,n,\\epsilon,\\delta) = \\text{poly}(m,n,\\frac{1}{\\epsilon},\\frac{1}{\\delta})\n\\]\nWhere: - \\(m\\) is sample size - \\(n\\) is input dimension - \\(\\epsilon\\) is accuracy - \\(\\delta\\) is confidence\n\n\n\nMemory requirements:\n\\[\nS(m,n) = O(mn)\n\\]\nStreaming bound:\n\\[\nS = O(\\log m + \\log n)\n\\]"
  },
  {
    "objectID": "posts/computational-learning-theory/index.html#learnability-analysis",
    "href": "posts/computational-learning-theory/index.html#learnability-analysis",
    "title": "Computational Learning Theory",
    "section": "",
    "text": "Definition: - Polynomial sample complexity - Polynomial time complexity - Polynomial space complexity\nRequirements:\n\\[\n\\begin{aligned}\nm &= \\text{poly}(n,\\frac{1}{\\epsilon},\\frac{1}{\\delta}) \\\\\nT &= \\text{poly}(n,\\frac{1}{\\epsilon},\\frac{1}{\\delta}) \\\\\nS &= \\text{poly}(n,\\frac{1}{\\epsilon},\\frac{1}{\\delta})\n\\end{aligned}\n\\]\n\n\n\nCryptographic assumptions:\n\\[\nP \\neq NP \\implies \\text{Not efficiently learnable}\n\\]\nReduction techniques:\n\\[\n\\text{Problem A} \\leq_p \\text{Problem B}\n\\]\n\n\n\nExpected runtime:\n\\[\n\\mathbb{E}[T(X)] = \\sum_{x} T(x)P(x)\n\\]\nSmoothed analysis:\n\\[\n\\max_{\\text{input } I} \\mathbb{E}_{\\text{noise } \\xi}[T(I + \\xi)]\n\\]"
  },
  {
    "objectID": "posts/computational-learning-theory/index.html#learning-models",
    "href": "posts/computational-learning-theory/index.html#learning-models",
    "title": "Computational Learning Theory",
    "section": "",
    "text": "Membership queries:\n\\[\n\\text{MQ}(x) = c(x)\n\\]\nEquivalence queries:\n\\[\n\\text{EQ}(h) = \\begin{cases}\n\\text{Yes} & \\text{if } h \\equiv c \\\\\nx & \\text{where } h(x) \\neq c(x)\n\\end{cases}\n\\]\n\n\n\nMistake bound:\n\\[\nM \\leq \\text{poly}(n,\\text{size}(c))\n\\]\nHalving algorithm:\n\\[\n|\\mathcal{H}_t| \\leq |\\mathcal{H}_0|/2^t\n\\]\n\n\n\nLabel complexity:\n\\[\n\\Lambda(\\epsilon,\\delta) = O(\\theta d\\log(1/\\epsilon)\\log(1/\\delta))\n\\]\nWhere: - \\(\\theta\\) is disagreement coefficient - \\(d\\) is VC dimension"
  },
  {
    "objectID": "posts/computational-learning-theory/index.html#algorithmic-efficiency",
    "href": "posts/computational-learning-theory/index.html#algorithmic-efficiency",
    "title": "Computational Learning Theory",
    "section": "",
    "text": "AdaBoost iterations:\n\\[\nT = O\\left(\\frac{\\log(1/\\epsilon)}{\\gamma^2}\\right)\n\\]\nWhere: - \\(\\gamma\\) is edge over random\n\n\n\nKernel evaluation:\n\\[\nT = O(m^2n)\n\\]\nNyström approximation:\n\\[\n\\|K - \\tilde{K}\\|_2 \\leq \\epsilon\n\\]\n\n\n\nBackpropagation complexity:\n\\[\nT = O(mnd)\n\\]\nWhere: - \\(d\\) is network depth"
  },
  {
    "objectID": "posts/computational-learning-theory/index.html#computational-trade-offs",
    "href": "posts/computational-learning-theory/index.html#computational-trade-offs",
    "title": "Computational Learning Theory",
    "section": "",
    "text": "Memory-runtime relationship:\n\\[\nT \\cdot S = \\Omega(n^2)\n\\]\nStreaming algorithms:\n\\[\nS \\cdot \\text{passes} = \\Omega(n)\n\\]\n\n\n\nActive learning:\n\\[\n\\text{queries} \\cdot \\text{computation} = O(m\\log m)\n\\]\nParallel speedup:\n\\[\nT_p = \\frac{T_1}{p} + O(\\log p)\n\\]\n\n\n\nApproximation guarantee:\n\\[\nf(x) \\leq (1+\\epsilon)\\text{OPT}\n\\]\nRuntime dependency:\n\\[\nT = O(\\text{poly}(n,1/\\epsilon))\n\\]"
  },
  {
    "objectID": "posts/computational-learning-theory/index.html#advanced-topics",
    "href": "posts/computational-learning-theory/index.html#advanced-topics",
    "title": "Computational Learning Theory",
    "section": "",
    "text": "Two-party protocol:\n\\[\nCC(f) = \\min_P \\max_{x,y} \\text{bits}(P(x,y))\n\\]\nLower bound:\n\\[\nCC(f) \\geq \\log_2 \\text{rank}(M_f)\n\\]\n\n\n\nBoolean circuit size:\n\\[\n\\text{size}(f) = \\min_{C: C \\text{ computes } f} \\text{gates}(C)\n\\]\nDepth bound:\n\\[\n\\text{depth}(f) \\geq \\log_2 \\text{sensitivity}(f)\n\\]\n\n\n\nInformation cost:\n\\[\nIC(P) = I(X;M|Y) + I(Y;M|X)\n\\]\nProtocol compression:\n\\[\n|P'| \\leq O(IC(P)\\log|P|)\n\\]"
  },
  {
    "objectID": "posts/computational-learning-theory/index.html#practical-implications",
    "href": "posts/computational-learning-theory/index.html#practical-implications",
    "title": "Computational Learning Theory",
    "section": "",
    "text": "Resource Constraints:\n\nTime efficiency\nMemory usage\nCommunication cost\n\nScalability:\n\nInput size\nDimensionality\nSample complexity\n\nParallelization:\n\nTask decomposition\nCommunication overhead\nLoad balancing\n\n\n\n\n\n\nArchitecture:\n\nProcessing units\nMemory hierarchy\nNetwork topology\n\nOptimization:\n\nCaching strategies\nData structures\nAlgorithm selection\n\nTrade-offs:\n\nAccuracy vs speed\nMemory vs computation\nCommunication vs local processing"
  },
  {
    "objectID": "posts/computational-learning-theory/index.html#theoretical-frameworks",
    "href": "posts/computational-learning-theory/index.html#theoretical-frameworks",
    "title": "Computational Learning Theory",
    "section": "",
    "text": "LWE assumption:\n\\[\n(A,As+e) \\approx_c (A,u)\n\\]\nWhere: - \\(A\\) is random matrix - \\(s\\) is secret - \\(e\\) is error - \\(u\\) is uniform\n\n\n\nQuery complexity:\n\\[\n\\text{SQ-DIM}(\\mathcal{C}) = \\min_{D} \\max_{f \\in \\mathcal{C}} |\\langle f,D \\rangle|\n\\]\n\n\n\nQuery complexity:\n\\[\nQ(\\epsilon) = O(\\frac{1}{\\epsilon}\\log\\frac{1}{\\epsilon})\n\\]\nDistance measure:\n\\[\n\\text{dist}(f,g) = \\text{Pr}_{x}[f(x) \\neq g(x)]\n\\]"
  },
  {
    "objectID": "posts/computational-learning-theory/index.html#best-practices",
    "href": "posts/computational-learning-theory/index.html#best-practices",
    "title": "Computational Learning Theory",
    "section": "",
    "text": "Complexity Measures:\n\nAsymptotic bounds\nAverage case\nWorst case\n\nResource Usage:\n\nMemory footprint\nCPU utilization\nI/O operations\n\nScalability:\n\nData size\nDimensionality\nParallelization\n\n\n\n\n\n\nOptimization:\n\nAlgorithm choice\nData structures\nMemory management\n\nTrade-offs:\n\nTime vs space\nAccuracy vs speed\nCommunication vs computation\n\nEvaluation:\n\nBenchmarking\nProfiling\nPerformance analysis"
  },
  {
    "objectID": "posts/computational-learning-theory/index.html#references",
    "href": "posts/computational-learning-theory/index.html#references",
    "title": "Computational Learning Theory",
    "section": "",
    "text": "Theory:\n\n“Foundations of Machine Learning” by Mohri et al.\n“Understanding Machine Learning” by Shalev-Shwartz and Ben-David\n“Computational Learning Theory” by Kearns and Vazirani\n\nComplexity:\n\n“Computational Complexity” by Arora and Barak\n“Communication Complexity” by Kushilevitz and Nisan\n“The Nature of Computation” by Moore and Mertens\n\nApplications:\n\n“Algorithmic Learning Theory” by Anthony and Biggs\n“Learning with Kernels” by Schölkopf and Smola\n“Theoretical Computer Science” by Hopcroft and Ullman"
  }
]